{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas Necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import seaborn as sns # visualize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções Auxiliares\n",
    "\n",
    "describe_dataset() : realiza o cálculo das proporções de classes do dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataset(X, y, k):\n",
    "    # get dataset rows: instances , columns: features\n",
    "    rows, columns = X.shape\n",
    "    # get proportion from target\n",
    "    (unique, counts) = np.unique(y, return_counts=True) \n",
    "    # calculate proportion\n",
    "    prop_neg = int(counts[0]/rows*100)\n",
    "    prop_pos = int(counts[1]/rows*100)\n",
    "\n",
    "    print(\"k = {}, Dataset: {} positivas, {} negativas ({}% x {}%)\".format(k, counts[1], counts[0], prop_pos, prop_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_classes_from_index() : realiza o cálculo das proporções de classes dos folds criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_from_index(y, skf):\n",
    "    _, y_idx, y_inv = np.unique(y, return_index=True, return_inverse=True)\n",
    "    y_counts = np.bincount(y_inv)\n",
    "    _, class_perm = np.unique(y_idx, return_inverse=True)\n",
    "    y_encoded = class_perm[y_inv]\n",
    "    y_order = np.sort(y_encoded)\n",
    "    n_classes = len(y_idx)\n",
    "    allocation = np.asarray(\n",
    "            [np.bincount(y_order[i::skf.n_splits], minlength=n_classes)\n",
    "             for i in range(skf.n_splits)])\n",
    "\n",
    "    for idx, f in enumerate(allocation):\n",
    "        count_neg = int(f[0])\n",
    "        count_pos = int(f[1])\n",
    "        total = count_neg+count_pos\n",
    "        prop_temp_neg = int(count_neg/total*100)\n",
    "        prop_temp_pos = int(count_pos/total*100)\n",
    "        print(\"Fold {}: Pos: {}, Neg: {}, Total: {}, Proporção: {}% x {}%\".format(idx, count_pos, count_neg, total, prop_temp_pos, prop_temp_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função que aplica o Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold(X, y, list_c, k):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------    \n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training data, where n_samples is the number of samples\n",
    "        and n_features is the number of features.\n",
    "    y : array-like, of length n_samples\n",
    "        The target variable for supervised learning problems.\n",
    "    k : int\n",
    "        Determines the number of folds.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### Estratifica o dataset em k folds\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    describe_dataset(X, y, k)\n",
    "    get_classes_from_index(y, skf)\n",
    "    \n",
    "    \n",
    "    ### Lista para armazenar os resultados de cada valor de c\n",
    "    ### Armazena um array bidimensional, onde terá o valor do c e uma lista dos resultados de c\n",
    "    result = []\n",
    "    \n",
    "    \n",
    "    ### Executa o treino e teste para cada valor do parametro c\n",
    "    for c in list_c:\n",
    "        print(\"c =  {}\" .format(c))\n",
    "\n",
    "        ### create naive bayes classifier\n",
    "        clf = GaussianNB(var_smoothing = c)\n",
    "        \n",
    "        \n",
    "        ### Array para guardar os resultados dos testes para o parametro c\n",
    "        \"\"\"\n",
    "        Coluna 0 : Armazena o valor de c\n",
    "        Coluna 1 : Armazena o resultado \n",
    "        \"\"\"\n",
    "        result_c = []\n",
    "\n",
    "                \n",
    "        ### resultado do fold-k\n",
    "        result_k = []\n",
    "        ### Executa o treino e teste para k folds\n",
    "        fold_k = 1\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            \n",
    "            print(\"fold_k: {}\" .format(fold_k))\n",
    "            print(\"\\nTRAIN: {}  TEST: {}\".format(len(train_index), len(test_index)))\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            ### train classifier\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            ### calculate metrics\n",
    "            y_predicted = clf.predict(X_test)\n",
    "            report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
    "            report_str = metrics.classification_report(y_test, y_predicted)\n",
    "                \n",
    "            ### Armazena o resultado do test do fold-k          \n",
    "            result_k.append(report_dict)\n",
    "            print(report_str)\n",
    "            \n",
    "            fold_k = fold_k + 1\n",
    "            \n",
    "\n",
    "        ### Guarda os resultados dos k fold do parametro c\n",
    "        reports = pd.DataFrame(pd.DataFrame(result_k)['1.0'].to_list())\n",
    "        accuracy_reports = pd.DataFrame(pd.DataFrame(result_k)['accuracy'])\n",
    "        reports['accuracy'] = accuracy_reports\n",
    "        print(reports)\n",
    "        \n",
    "                \n",
    "        ### Guarda o resultado da execução para o parâmetro c\n",
    "        result_c = [c, reports]\n",
    "        result.append(result_c)\n",
    "        \n",
    "    \n",
    "    ### Retorna a lista com todos os resultado para cada c\n",
    "    return result\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função para calcular a média das medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a média das medidas de cada c\n",
    "def calcula_media(lista_result):\n",
    "    \n",
    "    mean_c = []\n",
    "    for result in lista_result:\n",
    "        \n",
    "        c = result[0]\n",
    "        result_c = result[1]\n",
    "        \n",
    "        # Calcula a média das medidas do parametro c\n",
    "        precision_mean = result_c['precision'].mean()\n",
    "        recall_mean = result_c['recall'].mean()\n",
    "        f1_score_mean = result_c['f1-score'].mean()\n",
    "        support_mean = result_c['support'].mean()\n",
    "        accuracy_mean = result_c['accuracy'].mean()\n",
    "        \n",
    "        # Armazena a média das medidas do parametro c\n",
    "        mean_c.append([c, precision_mean, recall_mean, f1_score_mean, support_mean, accuracy_mean])\n",
    "    \n",
    "    name_columns = ['c', 'precision_mean', 'recall_mean', 'f1_score_mean', 'support_mean', 'accuracy_mean']\n",
    "    mean_c = pd.DataFrame(mean_c, columns=name_columns)\n",
    "    return mean_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parâmetros de execução do Naive Bayes\n",
    "list_c : valores do parâmetro de ajuste de probabilidade \n",
    "\n",
    "k_folds : número de folds para a estratificação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_c = [0.001, 0.10, 0.25, 0.50, 0.75, 1]\n",
    "k_folds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução base: Todas as características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "c =  0.001\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.13      0.22        31\n",
      "         1.0       0.55      0.97      0.70        34\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.68      0.55      0.46        65\n",
      "weighted avg       0.67      0.57      0.47        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.40      0.51        30\n",
      "         1.0       0.62      0.86      0.72        35\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.67      0.63      0.62        65\n",
      "weighted avg       0.66      0.65      0.62        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.70      0.74        30\n",
      "         1.0       0.76      0.83      0.79        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.77      0.76      0.77        65\n",
      "weighted avg       0.77      0.77      0.77        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.53      0.60        30\n",
      "         1.0       0.67      0.80      0.73        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.63      0.68        30\n",
      "         1.0       0.72      0.80      0.76        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.72      0.72      0.72        65\n",
      "weighted avg       0.72      0.72      0.72        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.70      0.76        30\n",
      "         1.0       0.78      0.89      0.83        35\n",
      "\n",
      "    accuracy                           0.80        65\n",
      "   macro avg       0.81      0.79      0.80        65\n",
      "weighted avg       0.81      0.80      0.80        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.80      0.86        30\n",
      "         1.0       0.85      0.94      0.89        35\n",
      "\n",
      "    accuracy                           0.88        65\n",
      "   macro avg       0.88      0.87      0.87        65\n",
      "weighted avg       0.88      0.88      0.88        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.63      0.63        30\n",
      "         1.0       0.69      0.69      0.69        35\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.66      0.66      0.66        65\n",
      "weighted avg       0.66      0.66      0.66        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.93      0.73        30\n",
      "         1.0       0.89      0.46      0.60        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.74      0.70      0.67        65\n",
      "weighted avg       0.75      0.68      0.66        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.77      0.68        30\n",
      "         1.0       0.73      0.56      0.63        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.67      0.66      0.65        64\n",
      "weighted avg       0.67      0.66      0.65        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.550000  0.970588  0.702128       34  0.569231\n",
      "1   0.625000  0.857143  0.722892       35  0.646154\n",
      "2   0.763158  0.828571  0.794521       35  0.769231\n",
      "3   0.666667  0.800000  0.727273       35  0.676923\n",
      "4   0.717949  0.800000  0.756757       35  0.723077\n",
      "5   0.775000  0.885714  0.826667       35  0.800000\n",
      "6   0.846154  0.942857  0.891892       35  0.876923\n",
      "7   0.685714  0.685714  0.685714       35  0.661538\n",
      "8   0.888889  0.457143  0.603774       35  0.676923\n",
      "9   0.730769  0.558824  0.633333       34  0.656250\n",
      "c =  0.1\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.16      0.27        31\n",
      "         1.0       0.56      0.97      0.71        34\n",
      "\n",
      "    accuracy                           0.58        65\n",
      "   macro avg       0.70      0.57      0.49        65\n",
      "weighted avg       0.69      0.58      0.50        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.40      0.53        30\n",
      "         1.0       0.64      0.91      0.75        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.72      0.66      0.64        65\n",
      "weighted avg       0.71      0.68      0.65        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.67      0.71        30\n",
      "         1.0       0.74      0.83      0.78        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.76      0.75      0.75        65\n",
      "weighted avg       0.76      0.75      0.75        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.50      0.60        30\n",
      "         1.0       0.67      0.86      0.75        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.71      0.68      0.68        65\n",
      "weighted avg       0.71      0.69      0.68        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.63      0.67        30\n",
      "         1.0       0.71      0.77      0.74        35\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.71      0.70      0.70        65\n",
      "weighted avg       0.71      0.71      0.71        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.80      0.81        30\n",
      "         1.0       0.83      0.86      0.85        35\n",
      "\n",
      "    accuracy                           0.83        65\n",
      "   macro avg       0.83      0.83      0.83        65\n",
      "weighted avg       0.83      0.83      0.83        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90        30\n",
      "         1.0       0.89      0.94      0.92        35\n",
      "\n",
      "    accuracy                           0.91        65\n",
      "   macro avg       0.91      0.90      0.91        65\n",
      "weighted avg       0.91      0.91      0.91        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.70      0.68        30\n",
      "         1.0       0.73      0.69      0.71        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.69      0.69      0.69        65\n",
      "weighted avg       0.69      0.69      0.69        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.90      0.69        30\n",
      "         1.0       0.82      0.40      0.54        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.69      0.65      0.62        65\n",
      "weighted avg       0.70      0.63      0.61        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.77      0.69        30\n",
      "         1.0       0.74      0.59      0.66        34\n",
      "\n",
      "    accuracy                           0.67        64\n",
      "   macro avg       0.68      0.68      0.67        64\n",
      "weighted avg       0.68      0.67      0.67        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.559322  0.970588  0.709677       34  0.584615\n",
      "1   0.640000  0.914286  0.752941       35  0.676923\n",
      "2   0.743590  0.828571  0.783784       35  0.753846\n",
      "3   0.666667  0.857143  0.750000       35  0.692308\n",
      "4   0.710526  0.771429  0.739726       35  0.707692\n",
      "5   0.833333  0.857143  0.845070       35  0.830769\n",
      "6   0.891892  0.942857  0.916667       35  0.907692\n",
      "7   0.727273  0.685714  0.705882       35  0.692308\n",
      "8   0.823529  0.400000  0.538462       35  0.630769\n",
      "9   0.740741  0.588235  0.655738       34  0.671875\n",
      "c =  0.25\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.13      0.22        31\n",
      "         1.0       0.55      0.97      0.70        34\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.68      0.55      0.46        65\n",
      "weighted avg       0.67      0.57      0.47        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.37      0.51        30\n",
      "         1.0       0.63      0.94      0.76        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.74      0.65      0.64        65\n",
      "weighted avg       0.73      0.68      0.64        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.67      0.73        30\n",
      "         1.0       0.75      0.86      0.80        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.78      0.76      0.76        65\n",
      "weighted avg       0.77      0.77      0.77        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.50      0.60        30\n",
      "         1.0       0.67      0.86      0.75        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.71      0.68      0.68        65\n",
      "weighted avg       0.71      0.69      0.68        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.60      0.63        30\n",
      "         1.0       0.68      0.74      0.71        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.68        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.80      0.83        30\n",
      "         1.0       0.84      0.89      0.86        35\n",
      "\n",
      "    accuracy                           0.85        65\n",
      "   macro avg       0.85      0.84      0.84        65\n",
      "weighted avg       0.85      0.85      0.85        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88        30\n",
      "         1.0       0.87      0.94      0.90        35\n",
      "\n",
      "    accuracy                           0.89        65\n",
      "   macro avg       0.90      0.89      0.89        65\n",
      "weighted avg       0.89      0.89      0.89        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.67      0.69        30\n",
      "         1.0       0.73      0.77      0.75        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.72      0.72      0.72        65\n",
      "weighted avg       0.72      0.72      0.72        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.90      0.68        30\n",
      "         1.0       0.81      0.37      0.51        35\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.68      0.64      0.60        65\n",
      "weighted avg       0.69      0.62      0.59        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.73      0.67        30\n",
      "         1.0       0.71      0.59      0.65        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.67      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.550000  0.970588  0.702128       34  0.569231\n",
      "1   0.634615  0.942857  0.758621       35  0.676923\n",
      "2   0.750000  0.857143  0.800000       35  0.769231\n",
      "3   0.666667  0.857143  0.750000       35  0.692308\n",
      "4   0.684211  0.742857  0.712329       35  0.676923\n",
      "5   0.837838  0.885714  0.861111       35  0.846154\n",
      "6   0.868421  0.942857  0.904110       35  0.892308\n",
      "7   0.729730  0.771429  0.750000       35  0.723077\n",
      "8   0.812500  0.371429  0.509804       35  0.615385\n",
      "9   0.714286  0.588235  0.645161       34  0.656250\n",
      "c =  0.5\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.13      0.22        31\n",
      "         1.0       0.55      0.97      0.70        34\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.68      0.55      0.46        65\n",
      "weighted avg       0.67      0.57      0.47        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.30      0.45        30\n",
      "         1.0       0.62      0.97      0.76        35\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.76      0.64      0.60        65\n",
      "weighted avg       0.75      0.66      0.61        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.63      0.70        30\n",
      "         1.0       0.73      0.86      0.79        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.76      0.75      0.75        65\n",
      "weighted avg       0.76      0.75      0.75        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.43      0.54        30\n",
      "         1.0       0.64      0.86      0.73        35\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.68      0.65      0.64        65\n",
      "weighted avg       0.68      0.66      0.64        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.57      0.62        30\n",
      "         1.0       0.68      0.77      0.72        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.80      0.84        30\n",
      "         1.0       0.84      0.91      0.88        35\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.87      0.86      0.86        65\n",
      "weighted avg       0.86      0.86      0.86        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90        30\n",
      "         1.0       0.89      0.94      0.92        35\n",
      "\n",
      "    accuracy                           0.91        65\n",
      "   macro avg       0.91      0.90      0.91        65\n",
      "weighted avg       0.91      0.91      0.91        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.60      0.64        30\n",
      "         1.0       0.69      0.77      0.73        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.69      0.69      0.69        65\n",
      "weighted avg       0.69      0.69      0.69        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.87      0.68        30\n",
      "         1.0       0.78      0.40      0.53        35\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.67      0.63      0.60        65\n",
      "weighted avg       0.67      0.62      0.60        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.70      0.66        30\n",
      "         1.0       0.70      0.62      0.66        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.66      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.550000  0.970588  0.702128       34  0.569231\n",
      "1   0.618182  0.971429  0.755556       35  0.661538\n",
      "2   0.731707  0.857143  0.789474       35  0.753846\n",
      "3   0.638298  0.857143  0.731707       35  0.661538\n",
      "4   0.675000  0.771429  0.720000       35  0.676923\n",
      "5   0.842105  0.914286  0.876712       35  0.861538\n",
      "6   0.891892  0.942857  0.916667       35  0.907692\n",
      "7   0.692308  0.771429  0.729730       35  0.692308\n",
      "8   0.777778  0.400000  0.528302       35  0.615385\n",
      "9   0.700000  0.617647  0.656250       34  0.656250\n",
      "c =  0.75\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.13      0.22        31\n",
      "         1.0       0.55      0.97      0.70        34\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.68      0.55      0.46        65\n",
      "weighted avg       0.67      0.57      0.47        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.23      0.37        30\n",
      "         1.0       0.60      0.97      0.74        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.74      0.60      0.55        65\n",
      "weighted avg       0.73      0.63      0.57        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.63      0.70        30\n",
      "         1.0       0.73      0.86      0.79        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.76      0.75      0.75        65\n",
      "weighted avg       0.76      0.75      0.75        65\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.37      0.48        30\n",
      "         1.0       0.61      0.86      0.71        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.65      0.61      0.60        65\n",
      "weighted avg       0.65      0.63      0.61        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.57      0.62        30\n",
      "         1.0       0.68      0.77      0.72        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.80      0.87        30\n",
      "         1.0       0.85      0.97      0.91        35\n",
      "\n",
      "    accuracy                           0.89        65\n",
      "   macro avg       0.91      0.89      0.89        65\n",
      "weighted avg       0.90      0.89      0.89        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93        30\n",
      "         1.0       0.92      0.97      0.94        35\n",
      "\n",
      "    accuracy                           0.94        65\n",
      "   macro avg       0.94      0.94      0.94        65\n",
      "weighted avg       0.94      0.94      0.94        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.60      0.65        30\n",
      "         1.0       0.70      0.80      0.75        35\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.71      0.70      0.70        65\n",
      "weighted avg       0.71      0.71      0.70        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.87      0.69        30\n",
      "         1.0       0.80      0.46      0.58        35\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.69      0.66      0.64        65\n",
      "weighted avg       0.70      0.65      0.63        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.70      0.66        30\n",
      "         1.0       0.70      0.62      0.66        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.66      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.550000  0.970588  0.702128       34  0.569231\n",
      "1   0.596491  0.971429  0.739130       35  0.630769\n",
      "2   0.731707  0.857143  0.789474       35  0.753846\n",
      "3   0.612245  0.857143  0.714286       35  0.630769\n",
      "4   0.675000  0.771429  0.720000       35  0.676923\n",
      "5   0.850000  0.971429  0.906667       35  0.892308\n",
      "6   0.918919  0.971429  0.944444       35  0.938462\n",
      "7   0.700000  0.800000  0.746667       35  0.707692\n",
      "8   0.800000  0.457143  0.581818       35  0.646154\n",
      "9   0.700000  0.617647  0.656250       34  0.656250\n",
      "c =  1\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.10      0.17        31\n",
      "         1.0       0.54      0.97      0.69        34\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.65      0.53      0.43        65\n",
      "weighted avg       0.64      0.55      0.45        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.23      0.37        30\n",
      "         1.0       0.60      0.97      0.74        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.74      0.60      0.55        65\n",
      "weighted avg       0.73      0.63      0.57        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.60      0.68        30\n",
      "         1.0       0.71      0.86      0.78        35\n",
      "\n",
      "    accuracy                           0.74        65\n",
      "   macro avg       0.75      0.73      0.73        65\n",
      "weighted avg       0.75      0.74      0.73        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.33      0.44        30\n",
      "         1.0       0.60      0.86      0.71        35\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.63      0.60      0.58        65\n",
      "weighted avg       0.63      0.62      0.59        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.53      0.60        30\n",
      "         1.0       0.67      0.80      0.73        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.77      0.85        30\n",
      "         1.0       0.83      0.97      0.89        35\n",
      "\n",
      "    accuracy                           0.88        65\n",
      "   macro avg       0.89      0.87      0.87        65\n",
      "weighted avg       0.89      0.88      0.87        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.87      0.91        30\n",
      "         1.0       0.89      0.97      0.93        35\n",
      "\n",
      "    accuracy                           0.92        65\n",
      "   macro avg       0.93      0.92      0.92        65\n",
      "weighted avg       0.93      0.92      0.92        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.53      0.62        30\n",
      "         1.0       0.67      0.83      0.74        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.70      0.68      0.68        65\n",
      "weighted avg       0.70      0.69      0.68        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.87      0.72        30\n",
      "         1.0       0.83      0.54      0.66        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.72      0.70      0.69        65\n",
      "weighted avg       0.73      0.69      0.69        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.70      0.66        30\n",
      "         1.0       0.70      0.62      0.66        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.66      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.540984  0.970588  0.694737       34  0.553846\n",
      "1   0.596491  0.971429  0.739130       35  0.630769\n",
      "2   0.714286  0.857143  0.779221       35  0.738462\n",
      "3   0.600000  0.857143  0.705882       35  0.615385\n",
      "4   0.666667  0.800000  0.727273       35  0.676923\n",
      "5   0.829268  0.971429  0.894737       35  0.876923\n",
      "6   0.894737  0.971429  0.931507       35  0.923077\n",
      "7   0.674419  0.828571  0.743590       35  0.692308\n",
      "8   0.826087  0.542857  0.655172       35  0.692308\n",
      "9   0.700000  0.617647  0.656250       34  0.656250\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-normalizado.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "result_all_features = stratified_k_fold(X, y, list_c, k=k_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado dos k-fold para cada valor de c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.001,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.550000  0.970588  0.702128       34  0.569231\n",
       "  1   0.625000  0.857143  0.722892       35  0.646154\n",
       "  2   0.763158  0.828571  0.794521       35  0.769231\n",
       "  3   0.666667  0.800000  0.727273       35  0.676923\n",
       "  4   0.717949  0.800000  0.756757       35  0.723077\n",
       "  5   0.775000  0.885714  0.826667       35  0.800000\n",
       "  6   0.846154  0.942857  0.891892       35  0.876923\n",
       "  7   0.685714  0.685714  0.685714       35  0.661538\n",
       "  8   0.888889  0.457143  0.603774       35  0.676923\n",
       "  9   0.730769  0.558824  0.633333       34  0.656250],\n",
       " [0.1,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.559322  0.970588  0.709677       34  0.584615\n",
       "  1   0.640000  0.914286  0.752941       35  0.676923\n",
       "  2   0.743590  0.828571  0.783784       35  0.753846\n",
       "  3   0.666667  0.857143  0.750000       35  0.692308\n",
       "  4   0.710526  0.771429  0.739726       35  0.707692\n",
       "  5   0.833333  0.857143  0.845070       35  0.830769\n",
       "  6   0.891892  0.942857  0.916667       35  0.907692\n",
       "  7   0.727273  0.685714  0.705882       35  0.692308\n",
       "  8   0.823529  0.400000  0.538462       35  0.630769\n",
       "  9   0.740741  0.588235  0.655738       34  0.671875],\n",
       " [0.25,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.550000  0.970588  0.702128       34  0.569231\n",
       "  1   0.634615  0.942857  0.758621       35  0.676923\n",
       "  2   0.750000  0.857143  0.800000       35  0.769231\n",
       "  3   0.666667  0.857143  0.750000       35  0.692308\n",
       "  4   0.684211  0.742857  0.712329       35  0.676923\n",
       "  5   0.837838  0.885714  0.861111       35  0.846154\n",
       "  6   0.868421  0.942857  0.904110       35  0.892308\n",
       "  7   0.729730  0.771429  0.750000       35  0.723077\n",
       "  8   0.812500  0.371429  0.509804       35  0.615385\n",
       "  9   0.714286  0.588235  0.645161       34  0.656250],\n",
       " [0.5,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.550000  0.970588  0.702128       34  0.569231\n",
       "  1   0.618182  0.971429  0.755556       35  0.661538\n",
       "  2   0.731707  0.857143  0.789474       35  0.753846\n",
       "  3   0.638298  0.857143  0.731707       35  0.661538\n",
       "  4   0.675000  0.771429  0.720000       35  0.676923\n",
       "  5   0.842105  0.914286  0.876712       35  0.861538\n",
       "  6   0.891892  0.942857  0.916667       35  0.907692\n",
       "  7   0.692308  0.771429  0.729730       35  0.692308\n",
       "  8   0.777778  0.400000  0.528302       35  0.615385\n",
       "  9   0.700000  0.617647  0.656250       34  0.656250],\n",
       " [0.75,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.550000  0.970588  0.702128       34  0.569231\n",
       "  1   0.596491  0.971429  0.739130       35  0.630769\n",
       "  2   0.731707  0.857143  0.789474       35  0.753846\n",
       "  3   0.612245  0.857143  0.714286       35  0.630769\n",
       "  4   0.675000  0.771429  0.720000       35  0.676923\n",
       "  5   0.850000  0.971429  0.906667       35  0.892308\n",
       "  6   0.918919  0.971429  0.944444       35  0.938462\n",
       "  7   0.700000  0.800000  0.746667       35  0.707692\n",
       "  8   0.800000  0.457143  0.581818       35  0.646154\n",
       "  9   0.700000  0.617647  0.656250       34  0.656250],\n",
       " [1,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.540984  0.970588  0.694737       34  0.553846\n",
       "  1   0.596491  0.971429  0.739130       35  0.630769\n",
       "  2   0.714286  0.857143  0.779221       35  0.738462\n",
       "  3   0.600000  0.857143  0.705882       35  0.615385\n",
       "  4   0.666667  0.800000  0.727273       35  0.676923\n",
       "  5   0.829268  0.971429  0.894737       35  0.876923\n",
       "  6   0.894737  0.971429  0.931507       35  0.923077\n",
       "  7   0.674419  0.828571  0.743590       35  0.692308\n",
       "  8   0.826087  0.542857  0.655172       35  0.692308\n",
       "  9   0.700000  0.617647  0.656250       34  0.656250]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula a média das medidas de cada parâmetro c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_score_mean</th>\n",
       "      <th>support_mean</th>\n",
       "      <th>accuracy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.724930</td>\n",
       "      <td>0.778655</td>\n",
       "      <td>0.734495</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.705625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.733687</td>\n",
       "      <td>0.781597</td>\n",
       "      <td>0.739795</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.714880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.724827</td>\n",
       "      <td>0.793025</td>\n",
       "      <td>0.739326</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.711779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.711727</td>\n",
       "      <td>0.807395</td>\n",
       "      <td>0.740652</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.705625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.713436</td>\n",
       "      <td>0.824538</td>\n",
       "      <td>0.750086</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.710240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.704294</td>\n",
       "      <td>0.838824</td>\n",
       "      <td>0.752750</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.705625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       c  precision_mean  recall_mean  f1_score_mean  support_mean  \\\n",
       "0  0.001        0.724930     0.778655       0.734495          34.8   \n",
       "1  0.100        0.733687     0.781597       0.739795          34.8   \n",
       "2  0.250        0.724827     0.793025       0.739326          34.8   \n",
       "3  0.500        0.711727     0.807395       0.740652          34.8   \n",
       "4  0.750        0.713436     0.824538       0.750086          34.8   \n",
       "5  1.000        0.704294     0.838824       0.752750          34.8   \n",
       "\n",
       "   accuracy_mean  \n",
       "0       0.705625  \n",
       "1       0.714880  \n",
       "2       0.711779  \n",
       "3       0.705625  \n",
       "4       0.710240  \n",
       "5       0.705625  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_all_features_mean = calcula_media(result_all_features)\n",
    "result_all_features_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtém as medidas da maior média de acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_mean</th>\n",
       "      <td>0.733687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_mean</th>\n",
       "      <td>0.781597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_mean</th>\n",
       "      <td>0.739795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support_mean</th>\n",
       "      <td>34.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_mean</th>\n",
       "      <td>0.714880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                All Features\n",
       "c                   0.100000\n",
       "precision_mean      0.733687\n",
       "recall_mean         0.781597\n",
       "f1_score_mean       0.739795\n",
       "support_mean       34.800000\n",
       "accuracy_mean       0.714880"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy_all_features = pd.Series(result_all_features_mean.iloc[result_all_features_mean['accuracy_mean'].idxmax()], \n",
    "                          name='All Features')\n",
    "best_all_features = pd.DataFrame(best_accuracy_all_features)\n",
    "best_all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução Base: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "c =  0.001\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.13      0.22        31\n",
      "         1.0       0.55      0.97      0.70        34\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.68      0.55      0.46        65\n",
      "weighted avg       0.67      0.57      0.47        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.40      0.51        30\n",
      "         1.0       0.62      0.86      0.72        35\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.67      0.63      0.62        65\n",
      "weighted avg       0.66      0.65      0.62        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.70      0.74        30\n",
      "         1.0       0.76      0.83      0.79        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.77      0.76      0.77        65\n",
      "weighted avg       0.77      0.77      0.77        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.53      0.60        30\n",
      "         1.0       0.67      0.80      0.73        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.63      0.68        30\n",
      "         1.0       0.72      0.80      0.76        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.72      0.72      0.72        65\n",
      "weighted avg       0.72      0.72      0.72        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.70      0.76        30\n",
      "         1.0       0.78      0.89      0.83        35\n",
      "\n",
      "    accuracy                           0.80        65\n",
      "   macro avg       0.81      0.79      0.80        65\n",
      "weighted avg       0.81      0.80      0.80        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.80      0.86        30\n",
      "         1.0       0.85      0.94      0.89        35\n",
      "\n",
      "    accuracy                           0.88        65\n",
      "   macro avg       0.88      0.87      0.87        65\n",
      "weighted avg       0.88      0.88      0.88        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.63      0.63        30\n",
      "         1.0       0.69      0.69      0.69        35\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.66      0.66      0.66        65\n",
      "weighted avg       0.66      0.66      0.66        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.93      0.73        30\n",
      "         1.0       0.89      0.46      0.60        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.74      0.70      0.67        65\n",
      "weighted avg       0.75      0.68      0.66        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.77      0.68        30\n",
      "         1.0       0.73      0.56      0.63        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.67      0.66      0.65        64\n",
      "weighted avg       0.67      0.66      0.65        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.550000  0.970588  0.702128       34  0.569231\n",
      "1   0.625000  0.857143  0.722892       35  0.646154\n",
      "2   0.763158  0.828571  0.794521       35  0.769231\n",
      "3   0.666667  0.800000  0.727273       35  0.676923\n",
      "4   0.717949  0.800000  0.756757       35  0.723077\n",
      "5   0.775000  0.885714  0.826667       35  0.800000\n",
      "6   0.846154  0.942857  0.891892       35  0.876923\n",
      "7   0.685714  0.685714  0.685714       35  0.661538\n",
      "8   0.888889  0.457143  0.603774       35  0.676923\n",
      "9   0.730769  0.558824  0.633333       34  0.656250\n",
      "c =  0.1\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.16      0.27        31\n",
      "         1.0       0.56      0.97      0.71        34\n",
      "\n",
      "    accuracy                           0.58        65\n",
      "   macro avg       0.70      0.57      0.49        65\n",
      "weighted avg       0.69      0.58      0.50        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.40      0.53        30\n",
      "         1.0       0.64      0.91      0.75        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.72      0.66      0.64        65\n",
      "weighted avg       0.71      0.68      0.65        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.67      0.71        30\n",
      "         1.0       0.74      0.83      0.78        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.76      0.75      0.75        65\n",
      "weighted avg       0.76      0.75      0.75        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.50      0.60        30\n",
      "         1.0       0.67      0.86      0.75        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.71      0.68      0.68        65\n",
      "weighted avg       0.71      0.69      0.68        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.63      0.67        30\n",
      "         1.0       0.71      0.77      0.74        35\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.71      0.70      0.70        65\n",
      "weighted avg       0.71      0.71      0.71        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.80      0.81        30\n",
      "         1.0       0.83      0.86      0.85        35\n",
      "\n",
      "    accuracy                           0.83        65\n",
      "   macro avg       0.83      0.83      0.83        65\n",
      "weighted avg       0.83      0.83      0.83        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90        30\n",
      "         1.0       0.89      0.94      0.92        35\n",
      "\n",
      "    accuracy                           0.91        65\n",
      "   macro avg       0.91      0.90      0.91        65\n",
      "weighted avg       0.91      0.91      0.91        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.70      0.68        30\n",
      "         1.0       0.73      0.69      0.71        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.69      0.69      0.69        65\n",
      "weighted avg       0.69      0.69      0.69        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.90      0.69        30\n",
      "         1.0       0.82      0.40      0.54        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.69      0.65      0.62        65\n",
      "weighted avg       0.70      0.63      0.61        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.77      0.69        30\n",
      "         1.0       0.74      0.59      0.66        34\n",
      "\n",
      "    accuracy                           0.67        64\n",
      "   macro avg       0.68      0.68      0.67        64\n",
      "weighted avg       0.68      0.67      0.67        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.559322  0.970588  0.709677       34  0.584615\n",
      "1   0.640000  0.914286  0.752941       35  0.676923\n",
      "2   0.743590  0.828571  0.783784       35  0.753846\n",
      "3   0.666667  0.857143  0.750000       35  0.692308\n",
      "4   0.710526  0.771429  0.739726       35  0.707692\n",
      "5   0.833333  0.857143  0.845070       35  0.830769\n",
      "6   0.891892  0.942857  0.916667       35  0.907692\n",
      "7   0.727273  0.685714  0.705882       35  0.692308\n",
      "8   0.823529  0.400000  0.538462       35  0.630769\n",
      "9   0.740741  0.588235  0.655738       34  0.671875\n",
      "c =  0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.13      0.22        31\n",
      "         1.0       0.55      0.97      0.70        34\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.68      0.55      0.46        65\n",
      "weighted avg       0.67      0.57      0.47        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.37      0.51        30\n",
      "         1.0       0.63      0.94      0.76        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.74      0.65      0.64        65\n",
      "weighted avg       0.73      0.68      0.64        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.67      0.73        30\n",
      "         1.0       0.75      0.86      0.80        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.78      0.76      0.76        65\n",
      "weighted avg       0.77      0.77      0.77        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.50      0.60        30\n",
      "         1.0       0.67      0.86      0.75        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.71      0.68      0.68        65\n",
      "weighted avg       0.71      0.69      0.68        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.60      0.63        30\n",
      "         1.0       0.68      0.74      0.71        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.68        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.80      0.83        30\n",
      "         1.0       0.84      0.89      0.86        35\n",
      "\n",
      "    accuracy                           0.85        65\n",
      "   macro avg       0.85      0.84      0.84        65\n",
      "weighted avg       0.85      0.85      0.85        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88        30\n",
      "         1.0       0.87      0.94      0.90        35\n",
      "\n",
      "    accuracy                           0.89        65\n",
      "   macro avg       0.90      0.89      0.89        65\n",
      "weighted avg       0.89      0.89      0.89        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.67      0.69        30\n",
      "         1.0       0.73      0.77      0.75        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.72      0.72      0.72        65\n",
      "weighted avg       0.72      0.72      0.72        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.90      0.68        30\n",
      "         1.0       0.81      0.37      0.51        35\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.68      0.64      0.60        65\n",
      "weighted avg       0.69      0.62      0.59        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.73      0.67        30\n",
      "         1.0       0.71      0.59      0.65        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.67      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.550000  0.970588  0.702128       34  0.569231\n",
      "1   0.634615  0.942857  0.758621       35  0.676923\n",
      "2   0.750000  0.857143  0.800000       35  0.769231\n",
      "3   0.666667  0.857143  0.750000       35  0.692308\n",
      "4   0.684211  0.742857  0.712329       35  0.676923\n",
      "5   0.837838  0.885714  0.861111       35  0.846154\n",
      "6   0.868421  0.942857  0.904110       35  0.892308\n",
      "7   0.729730  0.771429  0.750000       35  0.723077\n",
      "8   0.812500  0.371429  0.509804       35  0.615385\n",
      "9   0.714286  0.588235  0.645161       34  0.656250\n",
      "c =  0.5\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.13      0.22        31\n",
      "         1.0       0.55      0.97      0.70        34\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.68      0.55      0.46        65\n",
      "weighted avg       0.67      0.57      0.47        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.30      0.45        30\n",
      "         1.0       0.62      0.97      0.76        35\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.76      0.64      0.60        65\n",
      "weighted avg       0.75      0.66      0.61        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.63      0.70        30\n",
      "         1.0       0.73      0.86      0.79        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.76      0.75      0.75        65\n",
      "weighted avg       0.76      0.75      0.75        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.43      0.54        30\n",
      "         1.0       0.64      0.86      0.73        35\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.68      0.65      0.64        65\n",
      "weighted avg       0.68      0.66      0.64        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.57      0.62        30\n",
      "         1.0       0.68      0.77      0.72        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.80      0.84        30\n",
      "         1.0       0.84      0.91      0.88        35\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.87      0.86      0.86        65\n",
      "weighted avg       0.86      0.86      0.86        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90        30\n",
      "         1.0       0.89      0.94      0.92        35\n",
      "\n",
      "    accuracy                           0.91        65\n",
      "   macro avg       0.91      0.90      0.91        65\n",
      "weighted avg       0.91      0.91      0.91        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.60      0.64        30\n",
      "         1.0       0.69      0.77      0.73        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.69      0.69      0.69        65\n",
      "weighted avg       0.69      0.69      0.69        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.87      0.68        30\n",
      "         1.0       0.78      0.40      0.53        35\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.67      0.63      0.60        65\n",
      "weighted avg       0.67      0.62      0.60        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.70      0.66        30\n",
      "         1.0       0.70      0.62      0.66        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.66      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.550000  0.970588  0.702128       34  0.569231\n",
      "1   0.618182  0.971429  0.755556       35  0.661538\n",
      "2   0.731707  0.857143  0.789474       35  0.753846\n",
      "3   0.638298  0.857143  0.731707       35  0.661538\n",
      "4   0.675000  0.771429  0.720000       35  0.676923\n",
      "5   0.842105  0.914286  0.876712       35  0.861538\n",
      "6   0.891892  0.942857  0.916667       35  0.907692\n",
      "7   0.692308  0.771429  0.729730       35  0.692308\n",
      "8   0.777778  0.400000  0.528302       35  0.615385\n",
      "9   0.700000  0.617647  0.656250       34  0.656250\n",
      "c =  0.75\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.13      0.22        31\n",
      "         1.0       0.55      0.97      0.70        34\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.68      0.55      0.46        65\n",
      "weighted avg       0.67      0.57      0.47        65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.23      0.37        30\n",
      "         1.0       0.60      0.97      0.74        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.74      0.60      0.55        65\n",
      "weighted avg       0.73      0.63      0.57        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.63      0.70        30\n",
      "         1.0       0.73      0.86      0.79        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.76      0.75      0.75        65\n",
      "weighted avg       0.76      0.75      0.75        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.37      0.48        30\n",
      "         1.0       0.61      0.86      0.71        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.65      0.61      0.60        65\n",
      "weighted avg       0.65      0.63      0.61        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.57      0.62        30\n",
      "         1.0       0.68      0.77      0.72        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.80      0.87        30\n",
      "         1.0       0.85      0.97      0.91        35\n",
      "\n",
      "    accuracy                           0.89        65\n",
      "   macro avg       0.91      0.89      0.89        65\n",
      "weighted avg       0.90      0.89      0.89        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93        30\n",
      "         1.0       0.92      0.97      0.94        35\n",
      "\n",
      "    accuracy                           0.94        65\n",
      "   macro avg       0.94      0.94      0.94        65\n",
      "weighted avg       0.94      0.94      0.94        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.60      0.65        30\n",
      "         1.0       0.70      0.80      0.75        35\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.71      0.70      0.70        65\n",
      "weighted avg       0.71      0.71      0.70        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.87      0.69        30\n",
      "         1.0       0.80      0.46      0.58        35\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.69      0.66      0.64        65\n",
      "weighted avg       0.70      0.65      0.63        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.70      0.66        30\n",
      "         1.0       0.70      0.62      0.66        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.66      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.550000  0.970588  0.702128       34  0.569231\n",
      "1   0.596491  0.971429  0.739130       35  0.630769\n",
      "2   0.731707  0.857143  0.789474       35  0.753846\n",
      "3   0.612245  0.857143  0.714286       35  0.630769\n",
      "4   0.675000  0.771429  0.720000       35  0.676923\n",
      "5   0.850000  0.971429  0.906667       35  0.892308\n",
      "6   0.918919  0.971429  0.944444       35  0.938462\n",
      "7   0.700000  0.800000  0.746667       35  0.707692\n",
      "8   0.800000  0.457143  0.581818       35  0.646154\n",
      "9   0.700000  0.617647  0.656250       34  0.656250\n",
      "c =  1\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.10      0.17        31\n",
      "         1.0       0.54      0.97      0.69        34\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.65      0.53      0.43        65\n",
      "weighted avg       0.64      0.55      0.45        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.23      0.37        30\n",
      "         1.0       0.60      0.97      0.74        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.74      0.60      0.55        65\n",
      "weighted avg       0.73      0.63      0.57        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.60      0.68        30\n",
      "         1.0       0.71      0.86      0.78        35\n",
      "\n",
      "    accuracy                           0.74        65\n",
      "   macro avg       0.75      0.73      0.73        65\n",
      "weighted avg       0.75      0.74      0.73        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.33      0.44        30\n",
      "         1.0       0.60      0.86      0.71        35\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.63      0.60      0.58        65\n",
      "weighted avg       0.63      0.62      0.59        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.53      0.60        30\n",
      "         1.0       0.67      0.80      0.73        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.77      0.85        30\n",
      "         1.0       0.83      0.97      0.89        35\n",
      "\n",
      "    accuracy                           0.88        65\n",
      "   macro avg       0.89      0.87      0.87        65\n",
      "weighted avg       0.89      0.88      0.87        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.87      0.91        30\n",
      "         1.0       0.89      0.97      0.93        35\n",
      "\n",
      "    accuracy                           0.92        65\n",
      "   macro avg       0.93      0.92      0.92        65\n",
      "weighted avg       0.93      0.92      0.92        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.53      0.62        30\n",
      "         1.0       0.67      0.83      0.74        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.70      0.68      0.68        65\n",
      "weighted avg       0.70      0.69      0.68        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.87      0.72        30\n",
      "         1.0       0.83      0.54      0.66        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.72      0.70      0.69        65\n",
      "weighted avg       0.73      0.69      0.69        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.70      0.66        30\n",
      "         1.0       0.70      0.62      0.66        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.66      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.540984  0.970588  0.694737       34  0.553846\n",
      "1   0.596491  0.971429  0.739130       35  0.630769\n",
      "2   0.714286  0.857143  0.779221       35  0.738462\n",
      "3   0.600000  0.857143  0.705882       35  0.615385\n",
      "4   0.666667  0.800000  0.727273       35  0.676923\n",
      "5   0.829268  0.971429  0.894737       35  0.876923\n",
      "6   0.894737  0.971429  0.931507       35  0.923077\n",
      "7   0.674419  0.828571  0.743590       35  0.692308\n",
      "8   0.826087  0.542857  0.655172       35  0.692308\n",
      "9   0.700000  0.617647  0.656250       34  0.656250\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-normalizado.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "result_pca = stratified_k_fold(X, y, list_c, k=k_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado dos k-fold para cada valor de c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.001,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.550000  0.970588  0.702128       34  0.569231\n",
       "  1   0.625000  0.857143  0.722892       35  0.646154\n",
       "  2   0.763158  0.828571  0.794521       35  0.769231\n",
       "  3   0.666667  0.800000  0.727273       35  0.676923\n",
       "  4   0.717949  0.800000  0.756757       35  0.723077\n",
       "  5   0.775000  0.885714  0.826667       35  0.800000\n",
       "  6   0.846154  0.942857  0.891892       35  0.876923\n",
       "  7   0.685714  0.685714  0.685714       35  0.661538\n",
       "  8   0.888889  0.457143  0.603774       35  0.676923\n",
       "  9   0.730769  0.558824  0.633333       34  0.656250],\n",
       " [0.1,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.559322  0.970588  0.709677       34  0.584615\n",
       "  1   0.640000  0.914286  0.752941       35  0.676923\n",
       "  2   0.743590  0.828571  0.783784       35  0.753846\n",
       "  3   0.666667  0.857143  0.750000       35  0.692308\n",
       "  4   0.710526  0.771429  0.739726       35  0.707692\n",
       "  5   0.833333  0.857143  0.845070       35  0.830769\n",
       "  6   0.891892  0.942857  0.916667       35  0.907692\n",
       "  7   0.727273  0.685714  0.705882       35  0.692308\n",
       "  8   0.823529  0.400000  0.538462       35  0.630769\n",
       "  9   0.740741  0.588235  0.655738       34  0.671875],\n",
       " [0.25,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.550000  0.970588  0.702128       34  0.569231\n",
       "  1   0.634615  0.942857  0.758621       35  0.676923\n",
       "  2   0.750000  0.857143  0.800000       35  0.769231\n",
       "  3   0.666667  0.857143  0.750000       35  0.692308\n",
       "  4   0.684211  0.742857  0.712329       35  0.676923\n",
       "  5   0.837838  0.885714  0.861111       35  0.846154\n",
       "  6   0.868421  0.942857  0.904110       35  0.892308\n",
       "  7   0.729730  0.771429  0.750000       35  0.723077\n",
       "  8   0.812500  0.371429  0.509804       35  0.615385\n",
       "  9   0.714286  0.588235  0.645161       34  0.656250],\n",
       " [0.5,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.550000  0.970588  0.702128       34  0.569231\n",
       "  1   0.618182  0.971429  0.755556       35  0.661538\n",
       "  2   0.731707  0.857143  0.789474       35  0.753846\n",
       "  3   0.638298  0.857143  0.731707       35  0.661538\n",
       "  4   0.675000  0.771429  0.720000       35  0.676923\n",
       "  5   0.842105  0.914286  0.876712       35  0.861538\n",
       "  6   0.891892  0.942857  0.916667       35  0.907692\n",
       "  7   0.692308  0.771429  0.729730       35  0.692308\n",
       "  8   0.777778  0.400000  0.528302       35  0.615385\n",
       "  9   0.700000  0.617647  0.656250       34  0.656250],\n",
       " [0.75,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.550000  0.970588  0.702128       34  0.569231\n",
       "  1   0.596491  0.971429  0.739130       35  0.630769\n",
       "  2   0.731707  0.857143  0.789474       35  0.753846\n",
       "  3   0.612245  0.857143  0.714286       35  0.630769\n",
       "  4   0.675000  0.771429  0.720000       35  0.676923\n",
       "  5   0.850000  0.971429  0.906667       35  0.892308\n",
       "  6   0.918919  0.971429  0.944444       35  0.938462\n",
       "  7   0.700000  0.800000  0.746667       35  0.707692\n",
       "  8   0.800000  0.457143  0.581818       35  0.646154\n",
       "  9   0.700000  0.617647  0.656250       34  0.656250],\n",
       " [1,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.540984  0.970588  0.694737       34  0.553846\n",
       "  1   0.596491  0.971429  0.739130       35  0.630769\n",
       "  2   0.714286  0.857143  0.779221       35  0.738462\n",
       "  3   0.600000  0.857143  0.705882       35  0.615385\n",
       "  4   0.666667  0.800000  0.727273       35  0.676923\n",
       "  5   0.829268  0.971429  0.894737       35  0.876923\n",
       "  6   0.894737  0.971429  0.931507       35  0.923077\n",
       "  7   0.674419  0.828571  0.743590       35  0.692308\n",
       "  8   0.826087  0.542857  0.655172       35  0.692308\n",
       "  9   0.700000  0.617647  0.656250       34  0.656250]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula a média das medidas de cada parâmetro c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_score_mean</th>\n",
       "      <th>support_mean</th>\n",
       "      <th>accuracy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.724930</td>\n",
       "      <td>0.778655</td>\n",
       "      <td>0.734495</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.705625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.733687</td>\n",
       "      <td>0.781597</td>\n",
       "      <td>0.739795</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.714880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.724827</td>\n",
       "      <td>0.793025</td>\n",
       "      <td>0.739326</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.711779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.711727</td>\n",
       "      <td>0.807395</td>\n",
       "      <td>0.740652</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.705625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.713436</td>\n",
       "      <td>0.824538</td>\n",
       "      <td>0.750086</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.710240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.704294</td>\n",
       "      <td>0.838824</td>\n",
       "      <td>0.752750</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.705625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       c  precision_mean  recall_mean  f1_score_mean  support_mean  \\\n",
       "0  0.001        0.724930     0.778655       0.734495          34.8   \n",
       "1  0.100        0.733687     0.781597       0.739795          34.8   \n",
       "2  0.250        0.724827     0.793025       0.739326          34.8   \n",
       "3  0.500        0.711727     0.807395       0.740652          34.8   \n",
       "4  0.750        0.713436     0.824538       0.750086          34.8   \n",
       "5  1.000        0.704294     0.838824       0.752750          34.8   \n",
       "\n",
       "   accuracy_mean  \n",
       "0       0.705625  \n",
       "1       0.714880  \n",
       "2       0.711779  \n",
       "3       0.705625  \n",
       "4       0.710240  \n",
       "5       0.705625  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pca_mean = calcula_media(result_pca)\n",
    "result_pca_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtém o resultado da maior média de acurácia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_mean</th>\n",
       "      <td>0.733687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_mean</th>\n",
       "      <td>0.781597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_mean</th>\n",
       "      <td>0.739795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support_mean</th>\n",
       "      <td>34.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_mean</th>\n",
       "      <td>0.714880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PCA\n",
       "c                0.100000\n",
       "precision_mean   0.733687\n",
       "recall_mean      0.781597\n",
       "f1_score_mean    0.739795\n",
       "support_mean    34.800000\n",
       "accuracy_mean    0.714880"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy_pca = pd.Series(result_pca_mean.iloc[result_pca_mean['accuracy_mean'].idxmax()], \n",
    "                          name='PCA')\n",
    "best_pca = pd.DataFrame(best_accuracy_pca)\n",
    "best_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução Base: Chi Squared (K-Best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "c =  0.001\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.16      0.27        31\n",
      "         1.0       0.56      0.97      0.71        34\n",
      "\n",
      "    accuracy                           0.58        65\n",
      "   macro avg       0.70      0.57      0.49        65\n",
      "weighted avg       0.69      0.58      0.50        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.40      0.55        30\n",
      "         1.0       0.65      0.94      0.77        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.75      0.67      0.66        65\n",
      "weighted avg       0.74      0.69      0.66        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.77      0.79        30\n",
      "         1.0       0.81      0.86      0.83        35\n",
      "\n",
      "    accuracy                           0.82        65\n",
      "   macro avg       0.82      0.81      0.81        65\n",
      "weighted avg       0.82      0.82      0.81        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.53      0.64        30\n",
      "         1.0       0.69      0.89      0.78        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.74      0.71      0.71        65\n",
      "weighted avg       0.74      0.72      0.71        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.63      0.67        30\n",
      "         1.0       0.71      0.77      0.74        35\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.71      0.70      0.70        65\n",
      "weighted avg       0.71      0.71      0.71        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.80      0.84        30\n",
      "         1.0       0.84      0.91      0.88        35\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.87      0.86      0.86        65\n",
      "weighted avg       0.86      0.86      0.86        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.83      0.89        30\n",
      "         1.0       0.87      0.97      0.92        35\n",
      "\n",
      "    accuracy                           0.91        65\n",
      "   macro avg       0.92      0.90      0.91        65\n",
      "weighted avg       0.91      0.91      0.91        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.70      0.70        30\n",
      "         1.0       0.74      0.74      0.74        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.72      0.72      0.72        65\n",
      "weighted avg       0.72      0.72      0.72        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.97      0.75        30\n",
      "         1.0       0.94      0.49      0.64        35\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.78      0.73      0.70        65\n",
      "weighted avg       0.79      0.71      0.69        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.77      0.70        30\n",
      "         1.0       0.75      0.62      0.68        34\n",
      "\n",
      "    accuracy                           0.69        64\n",
      "   macro avg       0.69      0.69      0.69        64\n",
      "weighted avg       0.70      0.69      0.69        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.559322  0.970588  0.709677       34  0.584615\n",
      "1   0.647059  0.942857  0.767442       35  0.692308\n",
      "2   0.810811  0.857143  0.833333       35  0.815385\n",
      "3   0.688889  0.885714  0.775000       35  0.723077\n",
      "4   0.710526  0.771429  0.739726       35  0.707692\n",
      "5   0.842105  0.914286  0.876712       35  0.861538\n",
      "6   0.871795  0.971429  0.918919       35  0.907692\n",
      "7   0.742857  0.742857  0.742857       35  0.723077\n",
      "8   0.944444  0.485714  0.641509       35  0.707692\n",
      "9   0.750000  0.617647  0.677419       34  0.687500\n",
      "c =  0.1\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.10      0.17        31\n",
      "         1.0       0.54      0.97      0.69        34\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.65      0.53      0.43        65\n",
      "weighted avg       0.64      0.55      0.45        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.33      0.47        30\n",
      "         1.0       0.62      0.91      0.74        35\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.69      0.62      0.60        65\n",
      "weighted avg       0.69      0.65      0.61        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.70      0.72        30\n",
      "         1.0       0.76      0.80      0.78        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.75      0.75      0.75        65\n",
      "weighted avg       0.75      0.75      0.75        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.50      0.60        30\n",
      "         1.0       0.67      0.86      0.75        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.71      0.68      0.68        65\n",
      "weighted avg       0.71      0.69      0.68        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.63      0.67        30\n",
      "         1.0       0.71      0.77      0.74        35\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.71      0.70      0.70        65\n",
      "weighted avg       0.71      0.71      0.71        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.80      0.84        30\n",
      "         1.0       0.84      0.91      0.88        35\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.87      0.86      0.86        65\n",
      "weighted avg       0.86      0.86      0.86        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97        30\n",
      "         1.0       0.97      0.97      0.97        35\n",
      "\n",
      "    accuracy                           0.97        65\n",
      "   macro avg       0.97      0.97      0.97        65\n",
      "weighted avg       0.97      0.97      0.97        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.77      0.73        30\n",
      "         1.0       0.78      0.71      0.75        35\n",
      "\n",
      "    accuracy                           0.74        65\n",
      "   macro avg       0.74      0.74      0.74        65\n",
      "weighted avg       0.74      0.74      0.74        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.97      0.73        30\n",
      "         1.0       0.94      0.43      0.59        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.76      0.70      0.66        65\n",
      "weighted avg       0.78      0.68      0.66        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.77      0.70        30\n",
      "         1.0       0.75      0.62      0.68        34\n",
      "\n",
      "    accuracy                           0.69        64\n",
      "   macro avg       0.69      0.69      0.69        64\n",
      "weighted avg       0.70      0.69      0.69        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.540984  0.970588  0.694737       34  0.553846\n",
      "1   0.615385  0.914286  0.735632       35  0.646154\n",
      "2   0.756757  0.800000  0.777778       35  0.753846\n",
      "3   0.666667  0.857143  0.750000       35  0.692308\n",
      "4   0.710526  0.771429  0.739726       35  0.707692\n",
      "5   0.842105  0.914286  0.876712       35  0.861538\n",
      "6   0.971429  0.971429  0.971429       35  0.969231\n",
      "7   0.781250  0.714286  0.746269       35  0.738462\n",
      "8   0.937500  0.428571  0.588235       35  0.676923\n",
      "9   0.750000  0.617647  0.677419       34  0.687500\n",
      "c =  0.25\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.10      0.17        31\n",
      "         1.0       0.54      0.97      0.69        34\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.65      0.53      0.43        65\n",
      "weighted avg       0.64      0.55      0.45        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.27      0.39        30\n",
      "         1.0       0.59      0.91      0.72        35\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.66      0.59      0.55        65\n",
      "weighted avg       0.65      0.62      0.57        65\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.70      0.72        30\n",
      "         1.0       0.76      0.80      0.78        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.75      0.75      0.75        65\n",
      "weighted avg       0.75      0.75      0.75        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.50      0.60        30\n",
      "         1.0       0.67      0.86      0.75        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.71      0.68      0.68        65\n",
      "weighted avg       0.71      0.69      0.68        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.63      0.67        30\n",
      "         1.0       0.71      0.77      0.74        35\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.71      0.70      0.70        65\n",
      "weighted avg       0.71      0.71      0.71        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.77      0.81        30\n",
      "         1.0       0.82      0.89      0.85        35\n",
      "\n",
      "    accuracy                           0.83        65\n",
      "   macro avg       0.83      0.83      0.83        65\n",
      "weighted avg       0.83      0.83      0.83        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97        30\n",
      "         1.0       0.97      0.97      0.97        35\n",
      "\n",
      "    accuracy                           0.97        65\n",
      "   macro avg       0.97      0.97      0.97        65\n",
      "weighted avg       0.97      0.97      0.97        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.77      0.74        30\n",
      "         1.0       0.79      0.74      0.76        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.75      0.75      0.75        65\n",
      "weighted avg       0.76      0.75      0.75        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.97      0.74        30\n",
      "         1.0       0.94      0.46      0.62        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.77      0.71      0.68        65\n",
      "weighted avg       0.79      0.69      0.67        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.73      0.67        30\n",
      "         1.0       0.71      0.59      0.65        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.67      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.540984  0.970588  0.694737       34  0.553846\n",
      "1   0.592593  0.914286  0.719101       35  0.615385\n",
      "2   0.756757  0.800000  0.777778       35  0.753846\n",
      "3   0.666667  0.857143  0.750000       35  0.692308\n",
      "4   0.710526  0.771429  0.739726       35  0.707692\n",
      "5   0.815789  0.885714  0.849315       35  0.830769\n",
      "6   0.971429  0.971429  0.971429       35  0.969231\n",
      "7   0.787879  0.742857  0.764706       35  0.753846\n",
      "8   0.941176  0.457143  0.615385       35  0.692308\n",
      "9   0.714286  0.588235  0.645161       34  0.656250\n",
      "c =  0.5\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.10      0.17        31\n",
      "         1.0       0.54      0.97      0.69        34\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.65      0.53      0.43        65\n",
      "weighted avg       0.64      0.55      0.45        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.27      0.39        30\n",
      "         1.0       0.59      0.91      0.72        35\n",
      "\n",
      "    accuracy                           0.62        65\n",
      "   macro avg       0.66      0.59      0.55        65\n",
      "weighted avg       0.65      0.62      0.57        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.67      0.71        30\n",
      "         1.0       0.74      0.83      0.78        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.76      0.75      0.75        65\n",
      "weighted avg       0.76      0.75      0.75        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.43      0.55        30\n",
      "         1.0       0.65      0.89      0.75        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.71      0.66      0.65        65\n",
      "weighted avg       0.70      0.68      0.66        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.57      0.63        30\n",
      "         1.0       0.68      0.80      0.74        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.70      0.68      0.68        65\n",
      "weighted avg       0.69      0.69      0.69        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.77      0.84        30\n",
      "         1.0       0.82      0.94      0.88        35\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.87      0.85      0.86        65\n",
      "weighted avg       0.87      0.86      0.86        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.97        30\n",
      "         1.0       0.95      1.00      0.97        35\n",
      "\n",
      "    accuracy                           0.97        65\n",
      "   macro avg       0.97      0.97      0.97        65\n",
      "weighted avg       0.97      0.97      0.97        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.80      0.77        30\n",
      "         1.0       0.82      0.77      0.79        35\n",
      "\n",
      "    accuracy                           0.78        65\n",
      "   macro avg       0.78      0.79      0.78        65\n",
      "weighted avg       0.79      0.78      0.78        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.97      0.74        30\n",
      "         1.0       0.94      0.46      0.62        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.77      0.71      0.68        65\n",
      "weighted avg       0.79      0.69      0.67        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.73      0.68        30\n",
      "         1.0       0.72      0.62      0.67        34\n",
      "\n",
      "    accuracy                           0.67        64\n",
      "   macro avg       0.68      0.68      0.67        64\n",
      "weighted avg       0.68      0.67      0.67        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.540984  0.970588  0.694737       34  0.553846\n",
      "1   0.592593  0.914286  0.719101       35  0.615385\n",
      "2   0.743590  0.828571  0.783784       35  0.753846\n",
      "3   0.645833  0.885714  0.746988       35  0.676923\n",
      "4   0.682927  0.800000  0.736842       35  0.692308\n",
      "5   0.825000  0.942857  0.880000       35  0.861538\n",
      "6   0.945946  1.000000  0.972222       35  0.969231\n",
      "7   0.818182  0.771429  0.794118       35  0.784615\n",
      "8   0.941176  0.457143  0.615385       35  0.692308\n",
      "9   0.724138  0.617647  0.666667       34  0.671875\n",
      "c =  0.75\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.10      0.17        31\n",
      "         1.0       0.54      0.97      0.69        34\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.65      0.53      0.43        65\n",
      "weighted avg       0.64      0.55      0.45        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.27      0.40        30\n",
      "         1.0       0.60      0.94      0.73        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.70      0.60      0.57        65\n",
      "weighted avg       0.69      0.63      0.58        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.63      0.69        30\n",
      "         1.0       0.72      0.83      0.77        35\n",
      "\n",
      "    accuracy                           0.74        65\n",
      "   macro avg       0.74      0.73      0.73        65\n",
      "weighted avg       0.74      0.74      0.74        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.43      0.55        30\n",
      "         1.0       0.65      0.89      0.75        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.71      0.66      0.65        65\n",
      "weighted avg       0.70      0.68      0.66        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.53      0.60        30\n",
      "         1.0       0.67      0.80      0.73        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.77      0.84        30\n",
      "         1.0       0.82      0.94      0.88        35\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.87      0.85      0.86        65\n",
      "weighted avg       0.87      0.86      0.86        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95        30\n",
      "         1.0       0.92      1.00      0.96        35\n",
      "\n",
      "    accuracy                           0.95        65\n",
      "   macro avg       0.96      0.95      0.95        65\n",
      "weighted avg       0.96      0.95      0.95        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.77      0.77        30\n",
      "         1.0       0.80      0.80      0.80        35\n",
      "\n",
      "    accuracy                           0.78        65\n",
      "   macro avg       0.78      0.78      0.78        65\n",
      "weighted avg       0.78      0.78      0.78        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.97      0.74        30\n",
      "         1.0       0.94      0.46      0.62        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.77      0.71      0.68        65\n",
      "weighted avg       0.79      0.69      0.67        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.70      0.66        30\n",
      "         1.0       0.70      0.62      0.66        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.66      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.540984  0.970588  0.694737       34  0.553846\n",
      "1   0.600000  0.942857  0.733333       35  0.630769\n",
      "2   0.725000  0.828571  0.773333       35  0.738462\n",
      "3   0.645833  0.885714  0.746988       35  0.676923\n",
      "4   0.666667  0.800000  0.727273       35  0.676923\n",
      "5   0.825000  0.942857  0.880000       35  0.861538\n",
      "6   0.921053  1.000000  0.958904       35  0.953846\n",
      "7   0.800000  0.800000  0.800000       35  0.784615\n",
      "8   0.941176  0.457143  0.615385       35  0.692308\n",
      "9   0.700000  0.617647  0.656250       34  0.656250\n",
      "c =  1\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.10      0.17        31\n",
      "         1.0       0.54      0.97      0.69        34\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.65      0.53      0.43        65\n",
      "weighted avg       0.64      0.55      0.45        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.27      0.40        30\n",
      "         1.0       0.60      0.94      0.73        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.70      0.60      0.57        65\n",
      "weighted avg       0.69      0.63      0.58        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.60      0.67        30\n",
      "         1.0       0.71      0.83      0.76        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.73      0.71      0.71        65\n",
      "weighted avg       0.73      0.72      0.72        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.37      0.49        30\n",
      "         1.0       0.62      0.89      0.73        35\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.68      0.63      0.61        65\n",
      "weighted avg       0.67      0.65      0.62        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.53      0.60        30\n",
      "         1.0       0.67      0.80      0.73        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.77      0.84        30\n",
      "         1.0       0.82      0.94      0.88        35\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.87      0.85      0.86        65\n",
      "weighted avg       0.87      0.86      0.86        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95        30\n",
      "         1.0       0.92      1.00      0.96        35\n",
      "\n",
      "    accuracy                           0.95        65\n",
      "   macro avg       0.96      0.95      0.95        65\n",
      "weighted avg       0.96      0.95      0.95        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.73      0.76        30\n",
      "         1.0       0.78      0.83      0.81        35\n",
      "\n",
      "    accuracy                           0.78        65\n",
      "   macro avg       0.78      0.78      0.78        65\n",
      "weighted avg       0.78      0.78      0.78        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.93      0.73        30\n",
      "         1.0       0.89      0.46      0.60        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.74      0.70      0.67        65\n",
      "weighted avg       0.75      0.68      0.66        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.70      0.66        30\n",
      "         1.0       0.70      0.62      0.66        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.66      0.66      0.66        64\n",
      "weighted avg       0.66      0.66      0.66        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.540984  0.970588  0.694737       34  0.553846\n",
      "1   0.600000  0.942857  0.733333       35  0.630769\n",
      "2   0.707317  0.828571  0.763158       35  0.723077\n",
      "3   0.620000  0.885714  0.729412       35  0.646154\n",
      "4   0.666667  0.800000  0.727273       35  0.676923\n",
      "5   0.825000  0.942857  0.880000       35  0.861538\n",
      "6   0.921053  1.000000  0.958904       35  0.953846\n",
      "7   0.783784  0.828571  0.805556       35  0.784615\n",
      "8   0.888889  0.457143  0.603774       35  0.676923\n",
      "9   0.700000  0.617647  0.656250       34  0.656250\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-fs-chi-squared.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "result_chi = stratified_k_fold(X, y, list_c, k=k_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado dos k-fold para cada valor de c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.001,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.559322  0.970588  0.709677       34  0.584615\n",
       "  1   0.647059  0.942857  0.767442       35  0.692308\n",
       "  2   0.810811  0.857143  0.833333       35  0.815385\n",
       "  3   0.688889  0.885714  0.775000       35  0.723077\n",
       "  4   0.710526  0.771429  0.739726       35  0.707692\n",
       "  5   0.842105  0.914286  0.876712       35  0.861538\n",
       "  6   0.871795  0.971429  0.918919       35  0.907692\n",
       "  7   0.742857  0.742857  0.742857       35  0.723077\n",
       "  8   0.944444  0.485714  0.641509       35  0.707692\n",
       "  9   0.750000  0.617647  0.677419       34  0.687500],\n",
       " [0.1,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.540984  0.970588  0.694737       34  0.553846\n",
       "  1   0.615385  0.914286  0.735632       35  0.646154\n",
       "  2   0.756757  0.800000  0.777778       35  0.753846\n",
       "  3   0.666667  0.857143  0.750000       35  0.692308\n",
       "  4   0.710526  0.771429  0.739726       35  0.707692\n",
       "  5   0.842105  0.914286  0.876712       35  0.861538\n",
       "  6   0.971429  0.971429  0.971429       35  0.969231\n",
       "  7   0.781250  0.714286  0.746269       35  0.738462\n",
       "  8   0.937500  0.428571  0.588235       35  0.676923\n",
       "  9   0.750000  0.617647  0.677419       34  0.687500],\n",
       " [0.25,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.540984  0.970588  0.694737       34  0.553846\n",
       "  1   0.592593  0.914286  0.719101       35  0.615385\n",
       "  2   0.756757  0.800000  0.777778       35  0.753846\n",
       "  3   0.666667  0.857143  0.750000       35  0.692308\n",
       "  4   0.710526  0.771429  0.739726       35  0.707692\n",
       "  5   0.815789  0.885714  0.849315       35  0.830769\n",
       "  6   0.971429  0.971429  0.971429       35  0.969231\n",
       "  7   0.787879  0.742857  0.764706       35  0.753846\n",
       "  8   0.941176  0.457143  0.615385       35  0.692308\n",
       "  9   0.714286  0.588235  0.645161       34  0.656250],\n",
       " [0.5,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.540984  0.970588  0.694737       34  0.553846\n",
       "  1   0.592593  0.914286  0.719101       35  0.615385\n",
       "  2   0.743590  0.828571  0.783784       35  0.753846\n",
       "  3   0.645833  0.885714  0.746988       35  0.676923\n",
       "  4   0.682927  0.800000  0.736842       35  0.692308\n",
       "  5   0.825000  0.942857  0.880000       35  0.861538\n",
       "  6   0.945946  1.000000  0.972222       35  0.969231\n",
       "  7   0.818182  0.771429  0.794118       35  0.784615\n",
       "  8   0.941176  0.457143  0.615385       35  0.692308\n",
       "  9   0.724138  0.617647  0.666667       34  0.671875],\n",
       " [0.75,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.540984  0.970588  0.694737       34  0.553846\n",
       "  1   0.600000  0.942857  0.733333       35  0.630769\n",
       "  2   0.725000  0.828571  0.773333       35  0.738462\n",
       "  3   0.645833  0.885714  0.746988       35  0.676923\n",
       "  4   0.666667  0.800000  0.727273       35  0.676923\n",
       "  5   0.825000  0.942857  0.880000       35  0.861538\n",
       "  6   0.921053  1.000000  0.958904       35  0.953846\n",
       "  7   0.800000  0.800000  0.800000       35  0.784615\n",
       "  8   0.941176  0.457143  0.615385       35  0.692308\n",
       "  9   0.700000  0.617647  0.656250       34  0.656250],\n",
       " [1,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.540984  0.970588  0.694737       34  0.553846\n",
       "  1   0.600000  0.942857  0.733333       35  0.630769\n",
       "  2   0.707317  0.828571  0.763158       35  0.723077\n",
       "  3   0.620000  0.885714  0.729412       35  0.646154\n",
       "  4   0.666667  0.800000  0.727273       35  0.676923\n",
       "  5   0.825000  0.942857  0.880000       35  0.861538\n",
       "  6   0.921053  1.000000  0.958904       35  0.953846\n",
       "  7   0.783784  0.828571  0.805556       35  0.784615\n",
       "  8   0.888889  0.457143  0.603774       35  0.676923\n",
       "  9   0.700000  0.617647  0.656250       34  0.656250]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula a média das medidas de cada parâmetro c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_score_mean</th>\n",
       "      <th>support_mean</th>\n",
       "      <th>accuracy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.756781</td>\n",
       "      <td>0.815966</td>\n",
       "      <td>0.768260</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.741058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.757260</td>\n",
       "      <td>0.795966</td>\n",
       "      <td>0.755794</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.728750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.749808</td>\n",
       "      <td>0.795882</td>\n",
       "      <td>0.752734</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.722548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.746037</td>\n",
       "      <td>0.818824</td>\n",
       "      <td>0.760984</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.727187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.736571</td>\n",
       "      <td>0.824538</td>\n",
       "      <td>0.758620</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.722548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.725369</td>\n",
       "      <td>0.827395</td>\n",
       "      <td>0.755240</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.716394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       c  precision_mean  recall_mean  f1_score_mean  support_mean  \\\n",
       "0  0.001        0.756781     0.815966       0.768260          34.8   \n",
       "1  0.100        0.757260     0.795966       0.755794          34.8   \n",
       "2  0.250        0.749808     0.795882       0.752734          34.8   \n",
       "3  0.500        0.746037     0.818824       0.760984          34.8   \n",
       "4  0.750        0.736571     0.824538       0.758620          34.8   \n",
       "5  1.000        0.725369     0.827395       0.755240          34.8   \n",
       "\n",
       "   accuracy_mean  \n",
       "0       0.741058  \n",
       "1       0.728750  \n",
       "2       0.722548  \n",
       "3       0.727187  \n",
       "4       0.722548  \n",
       "5       0.716394  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_chi_mean = calcula_media(result_chi)\n",
    "result_chi_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtém o resultado da maior média de acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chi Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_mean</th>\n",
       "      <td>0.756781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_mean</th>\n",
       "      <td>0.815966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_mean</th>\n",
       "      <td>0.768260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support_mean</th>\n",
       "      <td>34.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_mean</th>\n",
       "      <td>0.741058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Chi Squared\n",
       "c                  0.001000\n",
       "precision_mean     0.756781\n",
       "recall_mean        0.815966\n",
       "f1_score_mean      0.768260\n",
       "support_mean      34.800000\n",
       "accuracy_mean      0.741058"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy_chi = pd.Series(result_chi_mean.iloc[result_chi_mean['accuracy_mean'].idxmax()], \n",
    "                          name='Chi Squared')\n",
    "best_chi = pd.DataFrame(best_accuracy_chi)\n",
    "best_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução Base: recursive-feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "c =  0.001\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.13      0.23        31\n",
      "         1.0       0.56      1.00      0.72        34\n",
      "\n",
      "    accuracy                           0.58        65\n",
      "   macro avg       0.78      0.56      0.47        65\n",
      "weighted avg       0.77      0.58      0.48        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.40      0.53        30\n",
      "         1.0       0.64      0.91      0.75        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.72      0.66      0.64        65\n",
      "weighted avg       0.71      0.68      0.65        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.67      0.75        30\n",
      "         1.0       0.76      0.91      0.83        35\n",
      "\n",
      "    accuracy                           0.80        65\n",
      "   macro avg       0.82      0.79      0.79        65\n",
      "weighted avg       0.81      0.80      0.80        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.47      0.55        30\n",
      "         1.0       0.64      0.80      0.71        35\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.65      0.63      0.63        65\n",
      "weighted avg       0.65      0.65      0.64        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.60      0.71        30\n",
      "         1.0       0.73      0.91      0.81        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.79      0.76      0.76        65\n",
      "weighted avg       0.79      0.77      0.76        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.67      0.75        30\n",
      "         1.0       0.76      0.91      0.83        35\n",
      "\n",
      "    accuracy                           0.80        65\n",
      "   macro avg       0.82      0.79      0.79        65\n",
      "weighted avg       0.81      0.80      0.80        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.80      0.87        30\n",
      "         1.0       0.85      0.97      0.91        35\n",
      "\n",
      "    accuracy                           0.89        65\n",
      "   macro avg       0.91      0.89      0.89        65\n",
      "weighted avg       0.90      0.89      0.89        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.47      0.56        30\n",
      "         1.0       0.64      0.83      0.73        35\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.67      0.65      0.64        65\n",
      "weighted avg       0.67      0.66      0.65        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.87      0.78        30\n",
      "         1.0       0.86      0.69      0.76        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.78      0.78      0.77        65\n",
      "weighted avg       0.79      0.77      0.77        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.73      0.71        30\n",
      "         1.0       0.75      0.71      0.73        34\n",
      "\n",
      "    accuracy                           0.72        64\n",
      "   macro avg       0.72      0.72      0.72        64\n",
      "weighted avg       0.72      0.72      0.72        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.557377  1.000000  0.715789       34  0.584615\n",
      "1   0.640000  0.914286  0.752941       35  0.676923\n",
      "2   0.761905  0.914286  0.831169       35  0.800000\n",
      "3   0.636364  0.800000  0.708861       35  0.646154\n",
      "4   0.727273  0.914286  0.810127       35  0.769231\n",
      "5   0.761905  0.914286  0.831169       35  0.800000\n",
      "6   0.850000  0.971429  0.906667       35  0.892308\n",
      "7   0.644444  0.828571  0.725000       35  0.661538\n",
      "8   0.857143  0.685714  0.761905       35  0.769231\n",
      "9   0.750000  0.705882  0.727273       34  0.718750\n",
      "c =  0.1\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.06      0.12        31\n",
      "         1.0       0.53      0.97      0.69        34\n",
      "\n",
      "    accuracy                           0.54        65\n",
      "   macro avg       0.60      0.52      0.40        65\n",
      "weighted avg       0.60      0.54      0.42        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.33      0.49        30\n",
      "         1.0       0.63      0.97      0.76        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.77      0.65      0.63        65\n",
      "weighted avg       0.76      0.68      0.64        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.57      0.68        30\n",
      "         1.0       0.71      0.91      0.80        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.78      0.74      0.74        65\n",
      "weighted avg       0.78      0.75      0.74        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.40      0.53        30\n",
      "         1.0       0.64      0.91      0.75        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.72      0.66      0.64        65\n",
      "weighted avg       0.71      0.68      0.65        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.63      0.72        30\n",
      "         1.0       0.74      0.89      0.81        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.78      0.76      0.76        65\n",
      "weighted avg       0.78      0.77      0.76        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.67      0.78        30\n",
      "         1.0       0.77      0.97      0.86        35\n",
      "\n",
      "    accuracy                           0.83        65\n",
      "   macro avg       0.86      0.82      0.82        65\n",
      "weighted avg       0.86      0.83      0.83        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.80      0.87        30\n",
      "         1.0       0.85      0.97      0.91        35\n",
      "\n",
      "    accuracy                           0.89        65\n",
      "   macro avg       0.91      0.89      0.89        65\n",
      "weighted avg       0.90      0.89      0.89        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.47      0.57        30\n",
      "         1.0       0.65      0.86      0.74        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.69      0.66      0.66        65\n",
      "weighted avg       0.69      0.68      0.66        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.93      0.79        30\n",
      "         1.0       0.92      0.63      0.75        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.80      0.78      0.77        65\n",
      "weighted avg       0.81      0.77      0.77        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.70      0.69        30\n",
      "         1.0       0.73      0.71      0.72        34\n",
      "\n",
      "    accuracy                           0.70        64\n",
      "   macro avg       0.70      0.70      0.70        64\n",
      "weighted avg       0.70      0.70      0.70        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.532258  0.970588  0.687500       34  0.538462\n",
      "1   0.629630  0.971429  0.764045       35  0.676923\n",
      "2   0.711111  0.914286  0.800000       35  0.753846\n",
      "3   0.640000  0.914286  0.752941       35  0.676923\n",
      "4   0.738095  0.885714  0.805195       35  0.769231\n",
      "5   0.772727  0.971429  0.860759       35  0.830769\n",
      "6   0.850000  0.971429  0.906667       35  0.892308\n",
      "7   0.652174  0.857143  0.740741       35  0.676923\n",
      "8   0.916667  0.628571  0.745763       35  0.769231\n",
      "9   0.727273  0.705882  0.716418       34  0.703125\n",
      "c =  0.25\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.06      0.12        31\n",
      "         1.0       0.53      0.97      0.69        34\n",
      "\n",
      "    accuracy                           0.54        65\n",
      "   macro avg       0.60      0.52      0.40        65\n",
      "weighted avg       0.60      0.54      0.42        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.23      0.37        30\n",
      "         1.0       0.60      0.97      0.74        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.74      0.60      0.55        65\n",
      "weighted avg       0.73      0.63      0.57        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.57      0.68        30\n",
      "         1.0       0.71      0.91      0.80        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.78      0.74      0.74        65\n",
      "weighted avg       0.78      0.75      0.74        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.37      0.51        30\n",
      "         1.0       0.63      0.94      0.76        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.74      0.65      0.64        65\n",
      "weighted avg       0.73      0.68      0.64        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.57      0.68        30\n",
      "         1.0       0.71      0.91      0.80        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.78      0.74      0.74        65\n",
      "weighted avg       0.78      0.75      0.74        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.60      0.75        30\n",
      "         1.0       0.74      1.00      0.85        35\n",
      "\n",
      "    accuracy                           0.82        65\n",
      "   macro avg       0.87      0.80      0.80        65\n",
      "weighted avg       0.86      0.82      0.81        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.77      0.85        30\n",
      "         1.0       0.83      0.97      0.89        35\n",
      "\n",
      "    accuracy                           0.88        65\n",
      "   macro avg       0.89      0.87      0.87        65\n",
      "weighted avg       0.89      0.88      0.87        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.47      0.60        30\n",
      "         1.0       0.67      0.91      0.77        35\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.75      0.69      0.68        65\n",
      "weighted avg       0.74      0.71      0.69        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.90      0.78        30\n",
      "         1.0       0.88      0.66      0.75        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.79      0.78      0.77        65\n",
      "weighted avg       0.80      0.77      0.77        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.73      0.71        30\n",
      "         1.0       0.75      0.71      0.73        34\n",
      "\n",
      "    accuracy                           0.72        64\n",
      "   macro avg       0.72      0.72      0.72        64\n",
      "weighted avg       0.72      0.72      0.72        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.532258  0.970588  0.687500       34  0.538462\n",
      "1   0.596491  0.971429  0.739130       35  0.630769\n",
      "2   0.711111  0.914286  0.800000       35  0.753846\n",
      "3   0.634615  0.942857  0.758621       35  0.676923\n",
      "4   0.711111  0.914286  0.800000       35  0.753846\n",
      "5   0.744681  1.000000  0.853659       35  0.815385\n",
      "6   0.829268  0.971429  0.894737       35  0.876923\n",
      "7   0.666667  0.914286  0.771084       35  0.707692\n",
      "8   0.884615  0.657143  0.754098       35  0.769231\n",
      "9   0.750000  0.705882  0.727273       34  0.718750\n",
      "c =  0.5\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.06      0.12        31\n",
      "         1.0       0.54      1.00      0.70        34\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.77      0.53      0.41        65\n",
      "weighted avg       0.76      0.55      0.42        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.17      0.28        30\n",
      "         1.0       0.58      0.97      0.72        35\n",
      "\n",
      "    accuracy                           0.60        65\n",
      "   macro avg       0.70      0.57      0.50        65\n",
      "weighted avg       0.69      0.60      0.52        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.47      0.61        30\n",
      "         1.0       0.67      0.94      0.79        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.77      0.70      0.70        65\n",
      "weighted avg       0.77      0.72      0.70        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.30      0.44        30\n",
      "         1.0       0.61      0.94      0.74        35\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.71      0.62      0.59        65\n",
      "weighted avg       0.71      0.65      0.60        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.53      0.68        30\n",
      "         1.0       0.71      0.97      0.82        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.82      0.75      0.75        65\n",
      "weighted avg       0.82      0.77      0.76        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.60      0.75        30\n",
      "         1.0       0.74      1.00      0.85        35\n",
      "\n",
      "    accuracy                           0.82        65\n",
      "   macro avg       0.87      0.80      0.80        65\n",
      "weighted avg       0.86      0.82      0.81        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.77      0.87        30\n",
      "         1.0       0.83      1.00      0.91        35\n",
      "\n",
      "    accuracy                           0.89        65\n",
      "   macro avg       0.92      0.88      0.89        65\n",
      "weighted avg       0.91      0.89      0.89        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.47      0.60        30\n",
      "         1.0       0.67      0.91      0.77        35\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.75      0.69      0.68        65\n",
      "weighted avg       0.74      0.71      0.69        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.83      0.76        30\n",
      "         1.0       0.83      0.69      0.75        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.76      0.76      0.75        65\n",
      "weighted avg       0.77      0.75      0.75        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.70      0.69        30\n",
      "         1.0       0.73      0.71      0.72        34\n",
      "\n",
      "    accuracy                           0.70        64\n",
      "   macro avg       0.70      0.70      0.70        64\n",
      "weighted avg       0.70      0.70      0.70        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.539683  1.000000  0.701031       34  0.553846\n",
      "1   0.576271  0.971429  0.723404       35  0.600000\n",
      "2   0.673469  0.942857  0.785714       35  0.723077\n",
      "3   0.611111  0.942857  0.741573       35  0.646154\n",
      "4   0.708333  0.971429  0.819277       35  0.769231\n",
      "5   0.744681  1.000000  0.853659       35  0.815385\n",
      "6   0.833333  1.000000  0.909091       35  0.892308\n",
      "7   0.666667  0.914286  0.771084       35  0.707692\n",
      "8   0.827586  0.685714  0.750000       35  0.753846\n",
      "9   0.727273  0.705882  0.716418       34  0.703125\n",
      "c =  0.75\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.06      0.12        31\n",
      "         1.0       0.54      1.00      0.70        34\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.77      0.53      0.41        65\n",
      "weighted avg       0.76      0.55      0.42        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.17      0.28        30\n",
      "         1.0       0.58      0.97      0.72        35\n",
      "\n",
      "    accuracy                           0.60        65\n",
      "   macro avg       0.70      0.57      0.50        65\n",
      "weighted avg       0.69      0.60      0.52        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.43      0.59        30\n",
      "         1.0       0.67      0.97      0.79        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.80      0.70      0.69        65\n",
      "weighted avg       0.79      0.72      0.70        65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.30      0.44        30\n",
      "         1.0       0.61      0.94      0.74        35\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.71      0.62      0.59        65\n",
      "weighted avg       0.71      0.65      0.60        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.50      0.65        30\n",
      "         1.0       0.69      0.97      0.81        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.82      0.74      0.73        65\n",
      "weighted avg       0.81      0.75      0.74        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.57      0.72        30\n",
      "         1.0       0.73      1.00      0.84        35\n",
      "\n",
      "    accuracy                           0.80        65\n",
      "   macro avg       0.86      0.78      0.78        65\n",
      "weighted avg       0.85      0.80      0.79        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.77      0.87        30\n",
      "         1.0       0.83      1.00      0.91        35\n",
      "\n",
      "    accuracy                           0.89        65\n",
      "   macro avg       0.92      0.88      0.89        65\n",
      "weighted avg       0.91      0.89      0.89        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.43      0.57        30\n",
      "         1.0       0.65      0.91      0.76        35\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.73      0.67      0.66        65\n",
      "weighted avg       0.73      0.69      0.67        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.80      0.75        30\n",
      "         1.0       0.81      0.71      0.76        35\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.76      0.76      0.75        65\n",
      "weighted avg       0.76      0.75      0.75        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.67      0.67        30\n",
      "         1.0       0.71      0.71      0.71        34\n",
      "\n",
      "    accuracy                           0.69        64\n",
      "   macro avg       0.69      0.69      0.69        64\n",
      "weighted avg       0.69      0.69      0.69        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.539683  1.000000  0.701031       34  0.553846\n",
      "1   0.576271  0.971429  0.723404       35  0.600000\n",
      "2   0.666667  0.971429  0.790698       35  0.723077\n",
      "3   0.611111  0.942857  0.741573       35  0.646154\n",
      "4   0.693878  0.971429  0.809524       35  0.753846\n",
      "5   0.729167  1.000000  0.843373       35  0.800000\n",
      "6   0.833333  1.000000  0.909091       35  0.892308\n",
      "7   0.653061  0.914286  0.761905       35  0.692308\n",
      "8   0.806452  0.714286  0.757576       35  0.753846\n",
      "9   0.705882  0.705882  0.705882       34  0.687500\n",
      "c =  1\n",
      "fold_k: 1\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.06      0.12        31\n",
      "         1.0       0.54      1.00      0.70        34\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.77      0.53      0.41        65\n",
      "weighted avg       0.76      0.55      0.42        65\n",
      "\n",
      "fold_k: 2\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.17      0.28        30\n",
      "         1.0       0.58      0.97      0.72        35\n",
      "\n",
      "    accuracy                           0.60        65\n",
      "   macro avg       0.70      0.57      0.50        65\n",
      "weighted avg       0.69      0.60      0.52        65\n",
      "\n",
      "fold_k: 3\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.40      0.57        30\n",
      "         1.0       0.66      1.00      0.80        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.83      0.70      0.68        65\n",
      "weighted avg       0.82      0.72      0.69        65\n",
      "\n",
      "fold_k: 4\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.27      0.40        30\n",
      "         1.0       0.60      0.94      0.73        35\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.70      0.60      0.57        65\n",
      "weighted avg       0.69      0.63      0.58        65\n",
      "\n",
      "fold_k: 5\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.43      0.59        30\n",
      "         1.0       0.67      0.97      0.79        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.80      0.70      0.69        65\n",
      "weighted avg       0.79      0.72      0.70        65\n",
      "\n",
      "fold_k: 6\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.57      0.72        30\n",
      "         1.0       0.73      1.00      0.84        35\n",
      "\n",
      "    accuracy                           0.80        65\n",
      "   macro avg       0.86      0.78      0.78        65\n",
      "weighted avg       0.85      0.80      0.79        65\n",
      "\n",
      "fold_k: 7\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.73      0.85        30\n",
      "         1.0       0.81      1.00      0.90        35\n",
      "\n",
      "    accuracy                           0.88        65\n",
      "   macro avg       0.91      0.87      0.87        65\n",
      "weighted avg       0.90      0.88      0.87        65\n",
      "\n",
      "fold_k: 8\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.40      0.53        30\n",
      "         1.0       0.64      0.91      0.75        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.72      0.66      0.64        65\n",
      "weighted avg       0.71      0.68      0.65        65\n",
      "\n",
      "fold_k: 9\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.77      0.75        30\n",
      "         1.0       0.79      0.77      0.78        35\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.77      0.77      0.77        65\n",
      "weighted avg       0.77      0.77      0.77        65\n",
      "\n",
      "fold_k: 10\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.63      0.64        30\n",
      "         1.0       0.69      0.71      0.70        34\n",
      "\n",
      "    accuracy                           0.67        64\n",
      "   macro avg       0.67      0.67      0.67        64\n",
      "weighted avg       0.67      0.67      0.67        64\n",
      "\n",
      "   precision    recall  f1-score  support  accuracy\n",
      "0   0.539683  1.000000  0.701031       34  0.553846\n",
      "1   0.576271  0.971429  0.723404       35  0.600000\n",
      "2   0.660377  1.000000  0.795455       35  0.723077\n",
      "3   0.600000  0.942857  0.733333       35  0.630769\n",
      "4   0.666667  0.971429  0.790698       35  0.723077\n",
      "5   0.729167  1.000000  0.843373       35  0.800000\n",
      "6   0.813953  1.000000  0.897436       35  0.876923\n",
      "7   0.640000  0.914286  0.752941       35  0.676923\n",
      "8   0.794118  0.771429  0.782609       35  0.769231\n",
      "9   0.685714  0.705882  0.695652       34  0.671875\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-fs-recursive-feature.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "result_recursive = stratified_k_fold(X, y, list_c, k=k_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado dos k-fold para cada valor de c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.001,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.557377  1.000000  0.715789       34  0.584615\n",
       "  1   0.640000  0.914286  0.752941       35  0.676923\n",
       "  2   0.761905  0.914286  0.831169       35  0.800000\n",
       "  3   0.636364  0.800000  0.708861       35  0.646154\n",
       "  4   0.727273  0.914286  0.810127       35  0.769231\n",
       "  5   0.761905  0.914286  0.831169       35  0.800000\n",
       "  6   0.850000  0.971429  0.906667       35  0.892308\n",
       "  7   0.644444  0.828571  0.725000       35  0.661538\n",
       "  8   0.857143  0.685714  0.761905       35  0.769231\n",
       "  9   0.750000  0.705882  0.727273       34  0.718750],\n",
       " [0.1,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.532258  0.970588  0.687500       34  0.538462\n",
       "  1   0.629630  0.971429  0.764045       35  0.676923\n",
       "  2   0.711111  0.914286  0.800000       35  0.753846\n",
       "  3   0.640000  0.914286  0.752941       35  0.676923\n",
       "  4   0.738095  0.885714  0.805195       35  0.769231\n",
       "  5   0.772727  0.971429  0.860759       35  0.830769\n",
       "  6   0.850000  0.971429  0.906667       35  0.892308\n",
       "  7   0.652174  0.857143  0.740741       35  0.676923\n",
       "  8   0.916667  0.628571  0.745763       35  0.769231\n",
       "  9   0.727273  0.705882  0.716418       34  0.703125],\n",
       " [0.25,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.532258  0.970588  0.687500       34  0.538462\n",
       "  1   0.596491  0.971429  0.739130       35  0.630769\n",
       "  2   0.711111  0.914286  0.800000       35  0.753846\n",
       "  3   0.634615  0.942857  0.758621       35  0.676923\n",
       "  4   0.711111  0.914286  0.800000       35  0.753846\n",
       "  5   0.744681  1.000000  0.853659       35  0.815385\n",
       "  6   0.829268  0.971429  0.894737       35  0.876923\n",
       "  7   0.666667  0.914286  0.771084       35  0.707692\n",
       "  8   0.884615  0.657143  0.754098       35  0.769231\n",
       "  9   0.750000  0.705882  0.727273       34  0.718750],\n",
       " [0.5,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.539683  1.000000  0.701031       34  0.553846\n",
       "  1   0.576271  0.971429  0.723404       35  0.600000\n",
       "  2   0.673469  0.942857  0.785714       35  0.723077\n",
       "  3   0.611111  0.942857  0.741573       35  0.646154\n",
       "  4   0.708333  0.971429  0.819277       35  0.769231\n",
       "  5   0.744681  1.000000  0.853659       35  0.815385\n",
       "  6   0.833333  1.000000  0.909091       35  0.892308\n",
       "  7   0.666667  0.914286  0.771084       35  0.707692\n",
       "  8   0.827586  0.685714  0.750000       35  0.753846\n",
       "  9   0.727273  0.705882  0.716418       34  0.703125],\n",
       " [0.75,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.539683  1.000000  0.701031       34  0.553846\n",
       "  1   0.576271  0.971429  0.723404       35  0.600000\n",
       "  2   0.666667  0.971429  0.790698       35  0.723077\n",
       "  3   0.611111  0.942857  0.741573       35  0.646154\n",
       "  4   0.693878  0.971429  0.809524       35  0.753846\n",
       "  5   0.729167  1.000000  0.843373       35  0.800000\n",
       "  6   0.833333  1.000000  0.909091       35  0.892308\n",
       "  7   0.653061  0.914286  0.761905       35  0.692308\n",
       "  8   0.806452  0.714286  0.757576       35  0.753846\n",
       "  9   0.705882  0.705882  0.705882       34  0.687500],\n",
       " [1,\n",
       "     precision    recall  f1-score  support  accuracy\n",
       "  0   0.539683  1.000000  0.701031       34  0.553846\n",
       "  1   0.576271  0.971429  0.723404       35  0.600000\n",
       "  2   0.660377  1.000000  0.795455       35  0.723077\n",
       "  3   0.600000  0.942857  0.733333       35  0.630769\n",
       "  4   0.666667  0.971429  0.790698       35  0.723077\n",
       "  5   0.729167  1.000000  0.843373       35  0.800000\n",
       "  6   0.813953  1.000000  0.897436       35  0.876923\n",
       "  7   0.640000  0.914286  0.752941       35  0.676923\n",
       "  8   0.794118  0.771429  0.782609       35  0.769231\n",
       "  9   0.685714  0.705882  0.695652       34  0.671875]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula a média das medidas de cada parâmetro c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_score_mean</th>\n",
       "      <th>support_mean</th>\n",
       "      <th>accuracy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.718641</td>\n",
       "      <td>0.864874</td>\n",
       "      <td>0.777090</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.731875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.716993</td>\n",
       "      <td>0.879076</td>\n",
       "      <td>0.778003</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.728774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.706082</td>\n",
       "      <td>0.896218</td>\n",
       "      <td>0.778610</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.724183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.690841</td>\n",
       "      <td>0.913445</td>\n",
       "      <td>0.777125</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.716466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.681550</td>\n",
       "      <td>0.919160</td>\n",
       "      <td>0.774406</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.710288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.670595</td>\n",
       "      <td>0.927731</td>\n",
       "      <td>0.771593</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.702572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       c  precision_mean  recall_mean  f1_score_mean  support_mean  \\\n",
       "0  0.001        0.718641     0.864874       0.777090          34.8   \n",
       "1  0.100        0.716993     0.879076       0.778003          34.8   \n",
       "2  0.250        0.706082     0.896218       0.778610          34.8   \n",
       "3  0.500        0.690841     0.913445       0.777125          34.8   \n",
       "4  0.750        0.681550     0.919160       0.774406          34.8   \n",
       "5  1.000        0.670595     0.927731       0.771593          34.8   \n",
       "\n",
       "   accuracy_mean  \n",
       "0       0.731875  \n",
       "1       0.728774  \n",
       "2       0.724183  \n",
       "3       0.716466  \n",
       "4       0.710288  \n",
       "5       0.702572  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_recursive_mean = calcula_media(result_recursive)\n",
    "result_recursive_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtém o resultado da maior média de acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recursive Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_mean</th>\n",
       "      <td>0.718641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_mean</th>\n",
       "      <td>0.864874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_mean</th>\n",
       "      <td>0.777090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support_mean</th>\n",
       "      <td>34.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_mean</th>\n",
       "      <td>0.731875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Recursive Feature\n",
       "c                        0.001000\n",
       "precision_mean           0.718641\n",
       "recall_mean              0.864874\n",
       "f1_score_mean            0.777090\n",
       "support_mean            34.800000\n",
       "accuracy_mean            0.731875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy_recursive = pd.Series(result_recursive_mean.iloc[result_recursive_mean['accuracy_mean'].idxmax()], \n",
    "                          name='Recursive Feature')\n",
    "best_recursive = pd.DataFrame(best_accuracy_recursive)\n",
    "best_recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junta todos os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média das métricas geradas pelo processamento de cada dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_score_mean</th>\n",
       "      <th>support_mean</th>\n",
       "      <th>accuracy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All Features</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.733687</td>\n",
       "      <td>0.781597</td>\n",
       "      <td>0.739795</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.714880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.733687</td>\n",
       "      <td>0.781597</td>\n",
       "      <td>0.739795</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.714880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi Squared</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.756781</td>\n",
       "      <td>0.815966</td>\n",
       "      <td>0.768260</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.741058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive Feature</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.718641</td>\n",
       "      <td>0.864874</td>\n",
       "      <td>0.777090</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.731875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       c  precision_mean  recall_mean  f1_score_mean  \\\n",
       "All Features       0.100        0.733687     0.781597       0.739795   \n",
       "PCA                0.100        0.733687     0.781597       0.739795   \n",
       "Chi Squared        0.001        0.756781     0.815966       0.768260   \n",
       "Recursive Feature  0.001        0.718641     0.864874       0.777090   \n",
       "\n",
       "                   support_mean  accuracy_mean  \n",
       "All Features               34.8       0.714880  \n",
       "PCA                        34.8       0.714880  \n",
       "Chi Squared                34.8       0.741058  \n",
       "Recursive Feature          34.8       0.731875  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([best_all_features, best_pca, best_chi, best_recursive], axis=1)\n",
    "\n",
    "print(\"Média das métricas geradas pelo processamento de cada dataset\")\n",
    "result.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
