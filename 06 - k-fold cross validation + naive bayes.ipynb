{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 6 - Grupo 7G\n",
    "\n",
    "## Bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`describe_dataset()` : realiza o cálculo das proporções de classes do dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataset(X, y, k):\n",
    "    # get dataset rows: instances , columns: features\n",
    "    rows, columns = X.shape\n",
    "    # get proportion from target\n",
    "    (unique, counts) = np.unique(y, return_counts=True) \n",
    "    # calculate proportion\n",
    "    prop_neg = int(counts[0]/rows*100)\n",
    "    prop_pos = int(counts[1]/rows*100)\n",
    "\n",
    "    print(\"k = {}, Dataset: {} positivas, {} negativas ({}% x {}%)\".format(k, counts[1], counts[0], prop_pos, prop_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_classes_from_index()` : realiza o cálculo das proporções de classes dos folds criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_from_index(y, skf):\n",
    "    _, y_idx, y_inv = np.unique(y, return_index=True, return_inverse=True)\n",
    "    y_counts = np.bincount(y_inv)\n",
    "    _, class_perm = np.unique(y_idx, return_inverse=True)\n",
    "    y_encoded = class_perm[y_inv]\n",
    "    y_order = np.sort(y_encoded)\n",
    "    n_classes = len(y_idx)\n",
    "    allocation = np.asarray(\n",
    "            [np.bincount(y_order[i::skf.n_splits], minlength=n_classes)\n",
    "             for i in range(skf.n_splits)])\n",
    "\n",
    "    for idx, f in enumerate(allocation):\n",
    "        count_neg = int(f[0])\n",
    "        count_pos = int(f[1])\n",
    "        total = count_neg+count_pos\n",
    "        prop_temp_neg = int(count_neg/total*100)\n",
    "        prop_temp_pos = int(count_pos/total*100)\n",
    "        print(\"Fold {}: Pos: {}, Neg: {}, Total: {}, Proporção: {}% x {}%\".format(idx, count_pos, count_neg, total, prop_temp_pos, prop_temp_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função final - Stratified K-Folds cross-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold(X, y, k):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------    \n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training data, where n_samples is the number of samples\n",
    "        and n_features is the number of features.\n",
    "    y : array-like, of length n_samples\n",
    "        The target variable for supervised learning problems.\n",
    "    k : int\n",
    "        Determines the number of folds.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    describe_dataset(X, y, k)\n",
    "    get_classes_from_index(y, skf)\n",
    "    \n",
    "    ### create naive bayes classifier\n",
    "    clf = GaussianNB()\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print(\"\\nTRAIN: {}  TEST: {}\".format(len(train_index), len(test_index)))\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        ### train classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        ### calculate metrics\n",
    "        y_predicted = clf.predict(X_test)\n",
    "        print(metrics.classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/dataset-normalizado.csv', header = 0)\n",
    "X = df.drop('is_approved',axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.13      0.22        31\n",
      "         1.0       0.55      0.97      0.70        34\n",
      "\n",
      "    accuracy                           0.57        65\n",
      "   macro avg       0.68      0.55      0.46        65\n",
      "weighted avg       0.67      0.57      0.47        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.40      0.51        30\n",
      "         1.0       0.62      0.86      0.72        35\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.67      0.63      0.62        65\n",
      "weighted avg       0.66      0.65      0.62        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.73      0.76        30\n",
      "         1.0       0.78      0.83      0.81        35\n",
      "\n",
      "    accuracy                           0.78        65\n",
      "   macro avg       0.78      0.78      0.78        65\n",
      "weighted avg       0.78      0.78      0.78        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.53      0.60        30\n",
      "         1.0       0.67      0.80      0.73        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.68      0.67      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.63      0.68        30\n",
      "         1.0       0.72      0.80      0.76        35\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.72      0.72      0.72        65\n",
      "weighted avg       0.72      0.72      0.72        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.70      0.76        30\n",
      "         1.0       0.78      0.89      0.83        35\n",
      "\n",
      "    accuracy                           0.80        65\n",
      "   macro avg       0.81      0.79      0.80        65\n",
      "weighted avg       0.81      0.80      0.80        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.80      0.86        30\n",
      "         1.0       0.85      0.94      0.89        35\n",
      "\n",
      "    accuracy                           0.88        65\n",
      "   macro avg       0.88      0.87      0.87        65\n",
      "weighted avg       0.88      0.88      0.88        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.63      0.63        30\n",
      "         1.0       0.69      0.69      0.69        35\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.66      0.66      0.66        65\n",
      "weighted avg       0.66      0.66      0.66        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.93      0.73        30\n",
      "         1.0       0.89      0.46      0.60        35\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.74      0.70      0.67        65\n",
      "weighted avg       0.75      0.68      0.66        65\n",
      "\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.77      0.68        30\n",
      "         1.0       0.73      0.56      0.63        34\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.67      0.66      0.65        64\n",
      "weighted avg       0.67      0.66      0.65        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stratified_k_fold(X, y, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
