{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 6 - Grupo 7G\n",
    "\n",
    "## Bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`describe_dataset()` : realiza o cálculo das proporções de classes do dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataset(X, y, k):\n",
    "    # get dataset rows: instances , columns: features\n",
    "    rows, columns = X.shape\n",
    "    # get proportion from target\n",
    "    (unique, counts) = np.unique(y, return_counts=True) \n",
    "    # calculate proportion\n",
    "    prop_neg = int(counts[0]/rows*100)\n",
    "    prop_pos = int(counts[1]/rows*100)\n",
    "\n",
    "    print(\"k = {}, Dataset: {} positivas, {} negativas ({}% x {}%)\".format(k, counts[1], counts[0], prop_pos, prop_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_classes_from_index()` : realiza o cálculo das proporções de classes dos folds criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_from_index(y, skf):\n",
    "    _, y_idx, y_inv = np.unique(y, return_index=True, return_inverse=True)\n",
    "    y_counts = np.bincount(y_inv)\n",
    "    _, class_perm = np.unique(y_idx, return_inverse=True)\n",
    "    y_encoded = class_perm[y_inv]\n",
    "    y_order = np.sort(y_encoded)\n",
    "    n_classes = len(y_idx)\n",
    "    allocation = np.asarray(\n",
    "            [np.bincount(y_order[i::skf.n_splits], minlength=n_classes)\n",
    "             for i in range(skf.n_splits)])\n",
    "\n",
    "    for idx, f in enumerate(allocation):\n",
    "        count_neg = int(f[0])\n",
    "        count_pos = int(f[1])\n",
    "        total = count_neg+count_pos\n",
    "        prop_temp_neg = int(count_neg/total*100)\n",
    "        prop_temp_pos = int(count_pos/total*100)\n",
    "        print(\"Fold {}: Pos: {}, Neg: {}, Total: {}, Proporção: {}% x {}%\".format(idx, count_pos, count_neg, total, prop_temp_pos, prop_temp_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função final - Stratified K-Folds cross-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold(X, y, k):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------    \n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training data, where n_samples is the number of samples\n",
    "        and n_features is the number of features.\n",
    "    y : array-like, of length n_samples\n",
    "        The target variable for supervised learning problems.\n",
    "    k : int\n",
    "        Determines the number of folds.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    describe_dataset(X, y, k)\n",
    "    get_classes_from_index(y, skf)\n",
    "    \n",
    "    ### create naive bayes classifier\n",
    "    clf = GaussianNB()\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print(\"\\nTRAIN: {}  TEST: {}\".format(len(train_index), len(test_index)))\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        ### train classifier\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        ### calculate metrics\n",
    "        y_predicted = clf.predict(X_test)\n",
    "        print(metrics.classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/dataset-normalizado.csv', header = 0)\n",
    "X = df.drop('is_approved',axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, Dataset: 41 positivas, 608 negativas (6% x 93%)\n",
      "Fold 0: Pos: 4, Neg: 61, Total: 65, Proporção: 6% x 93%\n",
      "Fold 1: Pos: 4, Neg: 61, Total: 65, Proporção: 6% x 93%\n",
      "Fold 2: Pos: 4, Neg: 61, Total: 65, Proporção: 6% x 93%\n",
      "Fold 3: Pos: 4, Neg: 61, Total: 65, Proporção: 6% x 93%\n",
      "Fold 4: Pos: 4, Neg: 61, Total: 65, Proporção: 6% x 93%\n",
      "Fold 5: Pos: 4, Neg: 61, Total: 65, Proporção: 6% x 93%\n",
      "Fold 6: Pos: 4, Neg: 61, Total: 65, Proporção: 6% x 93%\n",
      "Fold 7: Pos: 4, Neg: 61, Total: 65, Proporção: 6% x 93%\n",
      "Fold 8: Pos: 5, Neg: 60, Total: 65, Proporção: 7% x 92%\n",
      "Fold 9: Pos: 4, Neg: 60, Total: 64, Proporção: 6% x 93%\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99        61\n",
      "         1.0       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.98        65\n",
      "   macro avg       0.99      0.88      0.92        65\n",
      "weighted avg       0.98      0.98      0.98        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99        61\n",
      "         1.0       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.98        65\n",
      "   macro avg       0.99      0.88      0.92        65\n",
      "weighted avg       0.98      0.98      0.98        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        61\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        65\n",
      "   macro avg       1.00      1.00      1.00        65\n",
      "weighted avg       1.00      1.00      1.00        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99        61\n",
      "         1.0       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.98        65\n",
      "   macro avg       0.99      0.88      0.92        65\n",
      "weighted avg       0.98      0.98      0.98        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        61\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        65\n",
      "   macro avg       1.00      1.00      1.00        65\n",
      "weighted avg       1.00      1.00      1.00        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        61\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        65\n",
      "   macro avg       1.00      1.00      1.00        65\n",
      "weighted avg       1.00      1.00      1.00        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        61\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        65\n",
      "   macro avg       1.00      1.00      1.00        65\n",
      "weighted avg       1.00      1.00      1.00        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        61\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        65\n",
      "   macro avg       1.00      1.00      1.00        65\n",
      "weighted avg       1.00      1.00      1.00        65\n",
      "\n",
      "\n",
      "TRAIN: 584  TEST: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99        60\n",
      "         1.0       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.98        65\n",
      "   macro avg       0.99      0.90      0.94        65\n",
      "weighted avg       0.98      0.98      0.98        65\n",
      "\n",
      "\n",
      "TRAIN: 585  TEST: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stratified_k_fold(X, y, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
