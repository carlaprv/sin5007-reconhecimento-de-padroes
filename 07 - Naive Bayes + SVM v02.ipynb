{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 06 - k-fold cross validation + naive Bayes v03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlaprv/sin5007-reconhecimento-de-padroes/blob/master/07%20-%20Naive%20Bayes%20%2B%20SVM%20v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43Lcv8EVOUvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "78ff903a-a802-4ec9-c8e1-09c72d0a55c4"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/carlaprv/sin5007-reconhecimento-de-padroes cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cloned-repo' already exists and is not an empty directory.\n",
            "/content/cloned-repo\n",
            "'02 - Normalizacao_dataset_v01.ipynb'\n",
            "'02 - Normalizacao_dataset_v02.ipynb'\n",
            "'02 - Normalizacao_dataset_v03-portugues.ipynb'\n",
            "'03 - PCA_v01.ipynb'\n",
            "'03 - PCA_v02-portugues.ipynb'\n",
            "'04 - 01 Features Selection - Chi Squared v01.ipynb'\n",
            "'04 - 01 Features Selection - Chi Squared v02.ipynb'\n",
            "'04 - 02 Features Selection - Recursive Feature Elimination.ipynb'\n",
            "'04 - 02 Features Selection - Recursive Feature Elimination v02.ipynb'\n",
            "'04 - 03 Features Selection - Feature Importance.ipynb'\n",
            "'04 - 03 Features Selection - Feature Importance v02.ipynb'\n",
            "'04 - 04 Features Selection - Correlation Matrix.ipynb'\n",
            "'04 - 05 Features Selection - Select from Model.ipynb'\n",
            "'04 - 06 Features Selection Comparison.ipynb'\n",
            "'05 - Function k-fold cross validation-(biblioteca sklearn).ipynb'\n",
            "'05 - Function k-fold cross validation.ipynb'\n",
            "'06 - k-fold cross validation + naive bayes v01.ipynb'\n",
            "'06 - k-fold cross validation + naive Bayes v02.ipynb'\n",
            "'06 - k-fold cross validation + naive Bayes v03.ipynb'\n",
            "'06 - k-fold cross validation + naive Bayes v04.ipynb'\n",
            "'06 - k-fold cross validation + naive Bayes v05.ipynb'\n",
            "'07 - Naive Bayes + SVM v01.ipynb'\n",
            "'data exploring notebooks'\n",
            " dataset\n",
            " graph.png\n",
            " kaggle\n",
            " README.md\n",
            " results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ikayTX9-yVZk"
      },
      "source": [
        "# Naive Bayes + SVM\n",
        "-------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KiZnnw89yVZm"
      },
      "source": [
        "# Bibliotecas Necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7xYCeWYlyVZn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5a099a0d-2bfc-4847-c5f9-db513fbff951"
      },
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np\n",
        "import seaborn as sns # visualize\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.stats.api as sms\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from statsmodels.stats.weightstats import DescrStatsW\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HRJncBBWyVZt"
      },
      "source": [
        "# Funções Auxiliares\n",
        "\n",
        "describe_dataset() : realiza o cálculo das proporções de classes do dataset original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KutB_XTYyVZu",
        "colab": {}
      },
      "source": [
        "def describe_dataset(X, y, k):\n",
        "    # get dataset rows: instances , columns: features\n",
        "    rows, columns = X.shape\n",
        "    # get proportion from target\n",
        "    (unique, counts) = np.unique(y, return_counts=True) \n",
        "    # calculate proportion\n",
        "    prop_neg = int(counts[0]/rows*100)\n",
        "    prop_pos = int(counts[1]/rows*100)\n",
        "\n",
        "    print(\"k = {}, Dataset: {} positivas, {} negativas ({}% x {}%)\".format(k, counts[1], counts[0], prop_pos, prop_neg))\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4Z4wMlsnyVZz"
      },
      "source": [
        "get_classes_from_index() : realiza o cálculo das proporções de classes dos folds criados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xEZ4jxJKyVZ0",
        "colab": {}
      },
      "source": [
        "def get_classes_from_index(y, skf):\n",
        "    _, y_idx, y_inv = np.unique(y, return_index=True, return_inverse=True)\n",
        "    y_counts = np.bincount(y_inv)\n",
        "    _, class_perm = np.unique(y_idx, return_inverse=True)\n",
        "    y_encoded = class_perm[y_inv]\n",
        "    y_order = np.sort(y_encoded)\n",
        "    n_classes = len(y_idx)\n",
        "    allocation = np.asarray(\n",
        "            [np.bincount(y_order[i::skf.n_splits], minlength=n_classes)\n",
        "             for i in range(skf.n_splits)])\n",
        "\n",
        "    for idx, f in enumerate(allocation):\n",
        "        count_neg = int(f[0])\n",
        "        count_pos = int(f[1])\n",
        "        total = count_neg+count_pos\n",
        "        prop_temp_neg = int(count_neg/total*100)\n",
        "        prop_temp_pos = int(count_pos/total*100)\n",
        "        print(\"Fold {}: Pos: {}, Neg: {}, Total: {}, Proporção: {}% x {}%\".format(idx, count_pos, count_neg, total, prop_temp_pos, prop_temp_neg))\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnTH2MMbXYb8",
        "colab_type": "text"
      },
      "source": [
        "get_ic(): realiza o cálculo do indice de confiança"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdWzmJ5LXYb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ic(data, alpha):\n",
        "    \n",
        "    mean_c = []\n",
        "    for result in lista_result:\n",
        "        \n",
        "        c = result[0]\n",
        "        result_c = result[1]\n",
        "        \n",
        "        # Calcula a média das medidas do parametro c\n",
        "        precision_mean = result_c['precision'].mean()\n",
        "        recall_mean = result_c['recall'].mean()\n",
        "        f1_score_mean = result_c['f1-score'].mean()\n",
        "        support_mean = result_c['support'].mean()\n",
        "        accuracy_mean = result_c['accuracy'].mean()\n",
        "\n",
        "        # Calcula as ic das medidas\n",
        "        precision_ic = sms.DescrStatsW(result_c['precision']).tconfint_mean(alpha)\n",
        "        recall_ic = sms.DescrStatsW(result_c['recall']).tconfint_mean(alpha)\n",
        "        f1_score_ic = sms.DescrStatsW(result_c['f1-score']).tconfint_mean(alpha)\n",
        "        support_ic = sms.DescrStatsW(result_c['support']).tconfint_mean(alpha)\n",
        "        accuracy_ic = sms.DescrStatsW(result_c['accuracy']).tconfint_mean(alpha)\n",
        "\n",
        "        ic = {'recall_ic' : recall_ic, 'support_ic' : support_ic, 'accuracy_ic': accuracy_ic }\n",
        "        ic = pd.DataFrame(ic, index=['inf','sup'])\n",
        "\n",
        "        # Armazena a média das medidas do parametro c\n",
        "        mean_c.append([c, precision_mean, recall_mean, f1_score_mean, support_mean, accuracy_mean])\n",
        "    \n",
        "    name_columns = ['c', 'precision_mean', 'recall_mean', 'f1_score_mean', 'support_mean', 'accuracy_mean']\n",
        "    mean_c = pd.DataFrame(mean_c, columns=name_columns)\n",
        "    return mean_c, ic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7M_cAJuXYcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ic(data, alpha):\n",
        "\n",
        "    # Calcula as ic das medidas\n",
        "    accuracy_ic = sms.DescrStatsW(data['accuracy']).tconfint_mean(alpha)\n",
        "    precision_ic = sms.DescrStatsW(data['precision']).tconfint_mean(alpha)\n",
        "    recall_ic = sms.DescrStatsW(data['recall']).tconfint_mean(alpha)\n",
        "    fscore_ic = sms.DescrStatsW(data['fscore']).tconfint_mean(alpha)\n",
        "    \n",
        "    ic = [accuracy_ic, precision_ic, recall_ic, fscore_ic]\n",
        "\n",
        "    return ic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VETmxrTIXYcM",
        "colab_type": "text"
      },
      "source": [
        "# 1. Naive Bayes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OefDdR7WyVaD"
      },
      "source": [
        "##### Parâmetros de execução do Naive Bayes\n",
        "* list_c : valores do parâmetro de ajuste de probabilidade \n",
        "\n",
        "* k_folds : número de folds para a estratificação do dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mss4hXMgyVaE",
        "colab": {}
      },
      "source": [
        "list_c = [0.001, 0.10, 0.25, 0.50, 0.75, 1]\n",
        "# list_c = [0.001]\n",
        "k_folds = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YezZQsp7yVZ5",
        "colab": {}
      },
      "source": [
        "def execute_NB(X, y, list_c, k, dataSet):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------    \n",
        "           X : array-like, shape (n_samples, n_features)\n",
        "               Training data, where n_samples is the number of samples\n",
        "               and n_features is the number of features.\n",
        "           y : array-like, of length n_samples\n",
        "               The target variable for supervised learning problems.\n",
        "           k : int\n",
        "               Determines the number of folds.\n",
        "     dataSet : method selection (string)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ### Estratifica o dataset em k folds\n",
        "    skf = StratifiedKFold(n_splits=k)\n",
        "    describe_dataset(X, y, k)\n",
        "    get_classes_from_index(y, skf) \n",
        "    \n",
        "    \n",
        "    ### result_c: armazena a média dos k resultados para cada c e o índice de confiança\n",
        "    result_c = []\n",
        "    result_ic = []\n",
        "    \n",
        "    \n",
        "    ### Executa o treino e teste para cada valor do parametro c\n",
        "    for c in list_c:\n",
        "        print(\"c =  {}\" .format(c))\n",
        "\n",
        "        ### create naive bayes classifier\n",
        "        clf = GaussianNB(var_smoothing = c)\n",
        "                        \n",
        "        ### resultado do fold-k\n",
        "        result_k = []\n",
        "        \n",
        "        ### Executa o treino e teste para k folds\n",
        "        fold_k = 1\n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            \n",
        "            ### print(\"fold_k: {}\" .format(fold_k))\n",
        "            ### print(\"\\nTRAIN: {}  TEST: {}\".format(len(train_index), len(test_index)))\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            ### train classifier\n",
        "            clf.fit(X_train, y_train)\n",
        "            \n",
        "            ### calculate metrics\n",
        "            y_predicted = clf.predict(X_test)\n",
        "            report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
        "            report_str = metrics.classification_report(y_test, y_predicted)\n",
        "            ### print(report_str)\n",
        "            \n",
        "            all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
        "            accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
        "            precision = all_metrics[0]\n",
        "            recall = all_metrics[1]\n",
        "            fscore = all_metrics[2]\n",
        "                        \n",
        "            ### Armazena o resultado do fold k\n",
        "            result_k.append([c, fold_k, accuracy, precision, recall, fscore])\n",
        "            \n",
        "            fold_k = fold_k + 1\n",
        "                \n",
        "        \n",
        "        result_k = pd.DataFrame(result_k, columns=['c', 'fold', 'accuracy','precision','recall','fscore'])\n",
        "        print(result_k)\n",
        "        print(\"\")\n",
        "        \n",
        "        ### calcula a média das métricas dos k-folds      \n",
        "        accuracy_avg = result_k['accuracy'].mean()\n",
        "        precision_avg = result_k['precision'].mean()\n",
        "        recall_avg = result_k['recall'].mean()\n",
        "        fscore_avg = result_k['fscore'].mean()\n",
        "        \n",
        "        ### Calcula o índice de confiança dos k-folds\n",
        "        alpha = 0.05\n",
        "        ic_c = get_ic(result_k, alpha)\n",
        "        \n",
        "        ### Armazena a média dos resultados dos k-folds e o índice de confiança de cada métrica\n",
        "        result_c.append([c, accuracy_avg, precision_avg, recall_avg, fscore_avg])\n",
        "        result_ic.append(ic_c)\n",
        "        \n",
        "    ### Converte em DataFrame\n",
        "    result_c = pd.DataFrame(result_c, columns=['c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    result_ic = pd.DataFrame(result_ic, columns=['accuracy_ic', 'precision_ic', 'recall_ic', 'fscore_ic'])\n",
        "    print(\"Média dos resultados de cada teste:\")\n",
        "    print(result_c)\n",
        "    print(\"\")    \n",
        "    \n",
        "    ### Armazena apenas as métricas da melhor acurácia média    \n",
        "    result = [] \n",
        "    result.append(result_c.iloc[result_c['accuracy_avg'].argmax()])    \n",
        "    result = pd.DataFrame(result, columns=['c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'], index=[dataSet])\n",
        "    \n",
        "    ### Armazena o indice de confiança da melhor acuracia\n",
        "    ic = result_ic.iloc[result_c['accuracy_avg'].argmax()]\n",
        "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
        "    ic = pd.DataFrame(ic, index=['inf','sup'])\n",
        "        \n",
        "    ### Retorna as métricas com a melhor acurácia e o índice de confiança\n",
        "    return result, ic\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3RsPfCv4yVZ4"
      },
      "source": [
        "### 1.1. Naive Bayes: All Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHKrCam0XYcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8015b0c-53e6-40b5-d9f2-492035df4f87"
      },
      "source": [
        "df = pd.read_csv('results/dataset-normalizado.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "result_NB_all, ic_NB_all = execute_NB(X, y, list_c, k=k_folds, dataSet='All Features')\n",
        "print(\"Melhor resultado:\")\n",
        "result_NB_all"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "c =  0.001\n",
            "       c  fold  accuracy  precision    recall    fscore\n",
            "0  0.001     1  0.569231   0.669231  0.569231  0.473250\n",
            "1  0.001     2  0.646154   0.662330  0.646154  0.624929\n",
            "2  0.001     3  0.769231   0.769906  0.769231  0.767900\n",
            "3  0.001     4  0.676923   0.680045  0.676923  0.670273\n",
            "4  0.001     5  0.723077   0.723866  0.723077  0.720671\n",
            "5  0.001     6  0.800000   0.805000  0.800000  0.797576\n",
            "6  0.001     7  0.876923   0.881657  0.876923  0.875854\n",
            "7  0.001     8  0.661538   0.661538  0.661538  0.661538\n",
            "8  0.001     9  0.676923   0.753592  0.676923  0.660773\n",
            "9  0.001    10  0.656250   0.671938  0.656250  0.653554\n",
            "\n",
            "c =  0.1\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.1     1  0.584615   0.690004  0.584615  0.500114\n",
            "1  0.1     2  0.676923   0.713846  0.676923  0.651584\n",
            "2  0.1     3  0.753846   0.755424  0.753846  0.751708\n",
            "3  0.1     4  0.692308   0.705128  0.692308  0.680769\n",
            "4  0.1     5  0.707692   0.707377  0.707692  0.706006\n",
            "5  0.1     6  0.830769   0.830681  0.830769  0.830527\n",
            "6  0.1     7  0.907692   0.908821  0.907692  0.907383\n",
            "7  0.1     8  0.692308   0.694493  0.692308  0.692746\n",
            "8  0.1     9  0.630769   0.703054  0.630769  0.609467\n",
            "9  0.1    10  0.671875   0.684904  0.671875  0.670189\n",
            "\n",
            "c =  0.25\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.25     1  0.569231   0.669231  0.569231  0.473250\n",
            "1  0.25     2  0.676923   0.732249  0.676923  0.644624\n",
            "2  0.25     3  0.769231   0.773077  0.769231  0.766434\n",
            "3  0.25     4  0.692308   0.705128  0.692308  0.680769\n",
            "4  0.25     5  0.676923   0.676113  0.676923  0.675060\n",
            "5  0.25     6  0.846154   0.846748  0.846154  0.845638\n",
            "6  0.25     7  0.892308   0.894962  0.892308  0.891687\n",
            "7  0.25     8  0.723077   0.722602  0.723077  0.722149\n",
            "8  0.25     9  0.615385   0.691817  0.615385  0.589992\n",
            "9  0.25    10  0.656250   0.665923  0.656250  0.655242\n",
            "\n",
            "c =  0.5\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.5     1  0.569231   0.669231  0.569231  0.473250\n",
            "1  0.5     2  0.661538   0.748252  0.661538  0.614530\n",
            "2  0.5     3  0.753846   0.759381  0.753846  0.749888\n",
            "3  0.5     4  0.661538   0.677032  0.661538  0.643996\n",
            "4  0.5     5  0.676923   0.677308  0.676923  0.673007\n",
            "5  0.5     6  0.861538   0.863698  0.861538  0.860740\n",
            "6  0.5     7  0.907692   0.908821  0.907692  0.907383\n",
            "7  0.5     8  0.692308   0.692308  0.692308  0.689635\n",
            "8  0.5     9  0.615385   0.674123  0.615385  0.596159\n",
            "9  0.5    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "c =  0.75\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.75     1  0.569231   0.669231  0.569231  0.473250\n",
            "1  0.75     2  0.630769   0.725034  0.630769  0.568034\n",
            "2  0.75     3  0.753846   0.759381  0.753846  0.749888\n",
            "3  0.75     4  0.630769   0.646978  0.630769  0.605351\n",
            "4  0.75     5  0.676923   0.677308  0.676923  0.673007\n",
            "5  0.75     6  0.892308   0.900769  0.892308  0.891002\n",
            "6  0.75     7  0.938462   0.939857  0.938462  0.938255\n",
            "7  0.75     8  0.707692   0.709231  0.707692  0.704149\n",
            "8  0.75     9  0.646154   0.697436  0.646154  0.633287\n",
            "9  0.75    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "c =  1\n",
            "   c  fold  accuracy  precision    recall    fscore\n",
            "0  1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  1     2  0.630769   0.725034  0.630769  0.568034\n",
            "2  1     3  0.738462   0.745819  0.738462  0.733078\n",
            "3  1     4  0.615385   0.630769  0.615385  0.585219\n",
            "4  1     5  0.676923   0.680045  0.676923  0.670273\n",
            "5  1     6  0.876923   0.888837  0.876923  0.874944\n",
            "6  1     7  0.923077   0.926226  0.923077  0.922633\n",
            "7  1     8  0.692308   0.698813  0.692308  0.684418\n",
            "8  1     9  0.692308   0.730530  0.692308  0.686118\n",
            "9  1    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "Média dos resultados de cada teste:\n",
            "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  0.001      0.705625       0.727910    0.705625    0.690632\n",
            "1  0.100      0.714880       0.739373    0.714880    0.700049\n",
            "2  0.250      0.711779       0.737785    0.711779    0.694484\n",
            "3  0.500      0.705625       0.733155    0.705625    0.686484\n",
            "4  0.750      0.710240       0.738662    0.710240    0.689247\n",
            "5  1.000      0.705625       0.732814    0.705625    0.682613\n",
            "\n",
            "Melhor resultado:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.71488</td>\n",
              "      <td>0.739373</td>\n",
              "      <td>0.71488</td>\n",
              "      <td>0.700049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "All Features  0.1       0.71488       0.739373     0.71488    0.700049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV_HDt2SXYcj",
        "colab_type": "text"
      },
      "source": [
        "Índice de Confiança do melhor resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRGrb5XmXYck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "3f5432a1-ca9b-4b2b-9f71-7b492688ebe1"
      },
      "source": [
        "ic_NB_all"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_ic</th>\n",
              "      <th>precision_ic</th>\n",
              "      <th>recall_ic</th>\n",
              "      <th>fscore_ic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>inf</th>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.686647</td>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.619341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sup</th>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.780758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
              "inf     0.647212      0.686647   0.647212   0.619341\n",
              "sup     0.782547      0.792099   0.782547   0.780758"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuroGu1gXYcp",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. Naive Bayes: PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ5T9RKiXYcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d1a862a-8372-4273-ae49-939555341994"
      },
      "source": [
        "df = pd.read_csv('results/dataset-pca.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "result_NB_pca, ic_NB_pca = execute_NB(X, y, list_c, k=k_folds, dataSet='PCA')\n",
        "print(\"Melhor resultado:\")\n",
        "result_NB_pca"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "c =  0.001\n",
            "       c  fold  accuracy  precision    recall    fscore\n",
            "0  0.001     1  0.600000   0.773333  0.600000  0.510875\n",
            "1  0.001     2  0.646154   0.686391  0.646154  0.610779\n",
            "2  0.001     3  0.815385   0.815711  0.815385  0.814766\n",
            "3  0.001     4  0.630769   0.639935  0.630769  0.611632\n",
            "4  0.001     5  0.646154   0.645447  0.646154  0.645647\n",
            "5  0.001     6  0.800000   0.800759  0.800000  0.800190\n",
            "6  0.001     7  0.815385   0.815385  0.815385  0.815385\n",
            "7  0.001     8  0.615385   0.633136  0.615385  0.612095\n",
            "8  0.001     9  0.646154   0.762443  0.646154  0.616199\n",
            "9  0.001    10  0.609375   0.651864  0.609375  0.593160\n",
            "\n",
            "c =  0.1\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.1     1  0.553846   0.759219  0.553846  0.424502\n",
            "1  0.1     2  0.615385   0.676282  0.615385  0.556213\n",
            "2  0.1     3  0.800000   0.811594  0.800000  0.795883\n",
            "3  0.1     4  0.615385   0.640533  0.615385  0.576933\n",
            "4  0.1     5  0.600000   0.598309  0.600000  0.589744\n",
            "5  0.1     6  0.784615   0.784615  0.784615  0.784615\n",
            "6  0.1     7  0.830769   0.830681  0.830769  0.830527\n",
            "7  0.1     8  0.661538   0.663753  0.661538  0.662020\n",
            "8  0.1     9  0.661538   0.724344  0.661538  0.647024\n",
            "9  0.1    10  0.625000   0.645833  0.625000  0.619458\n",
            "\n",
            "c =  0.25\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.25     1  0.538462   0.754808  0.538462  0.392759\n",
            "1  0.25     2  0.615385   0.711254  0.615385  0.543402\n",
            "2  0.25     3  0.784615   0.799317  0.784615  0.779093\n",
            "3  0.25     4  0.584615   0.615385  0.584615  0.520710\n",
            "4  0.25     5  0.615385   0.619257  0.615385  0.598329\n",
            "5  0.25     6  0.784615   0.791745  0.784615  0.781152\n",
            "6  0.25     7  0.830769   0.836923  0.830769  0.828718\n",
            "7  0.25     8  0.723077   0.723866  0.723077  0.720671\n",
            "8  0.25     9  0.692308   0.744755  0.692308  0.682952\n",
            "9  0.25    10  0.656250   0.658203  0.656250  0.656586\n",
            "\n",
            "c =  0.5\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.5     1  0.538462   0.754808  0.538462  0.392759\n",
            "1  0.5     2  0.615385   0.711254  0.615385  0.543402\n",
            "2  0.5     3  0.738462   0.763246  0.738462  0.726864\n",
            "3  0.5     4  0.569231   0.608866  0.569231  0.480633\n",
            "4  0.5     5  0.646154   0.662330  0.646154  0.624929\n",
            "5  0.5     6  0.800000   0.821429  0.800000  0.793745\n",
            "6  0.5     7  0.861538   0.877369  0.861538  0.858688\n",
            "7  0.5     8  0.707692   0.718781  0.707692  0.698551\n",
            "8  0.5     9  0.723077   0.764931  0.723077  0.717507\n",
            "9  0.5    10  0.671875   0.672685  0.671875  0.672116\n",
            "\n",
            "c =  0.75\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.75     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  0.75     2  0.615385   0.711254  0.615385  0.543402\n",
            "2  0.75     3  0.723077   0.751227  0.723077  0.708724\n",
            "3  0.75     4  0.569231   0.608866  0.569231  0.480633\n",
            "4  0.75     5  0.646154   0.672308  0.646154  0.618401\n",
            "5  0.75     6  0.784615   0.810256  0.784615  0.776538\n",
            "6  0.75     7  0.861538   0.889860  0.861538  0.857208\n",
            "7  0.75     8  0.692308   0.705128  0.692308  0.680769\n",
            "8  0.75     9  0.738462   0.763314  0.738462  0.736225\n",
            "9  0.75    10  0.656250   0.656250  0.656250  0.656250\n",
            "\n",
            "c =  1\n",
            "   c  fold  accuracy  precision    recall    fscore\n",
            "0  1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  1     2  0.615385   0.711254  0.615385  0.543402\n",
            "2  1     3  0.707692   0.739065  0.707692  0.690158\n",
            "3  1     4  0.553846   0.573077  0.553846  0.453210\n",
            "4  1     5  0.661538   0.700496  0.661538  0.631485\n",
            "5  1     6  0.753846   0.788325  0.753846  0.741088\n",
            "6  1     7  0.861538   0.889860  0.861538  0.857208\n",
            "7  1     8  0.661538   0.677032  0.661538  0.643996\n",
            "8  1     9  0.769231   0.778388  0.769231  0.769231\n",
            "9  1    10  0.671875   0.671398  0.671875  0.671472\n",
            "\n",
            "Média dos resultados de cada teste:\n",
            "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  0.001      0.682476       0.722440    0.682476    0.663073\n",
            "1  0.100      0.674808       0.713516    0.674808    0.648692\n",
            "2  0.250      0.682548       0.725551    0.682548    0.650437\n",
            "3  0.500      0.687188       0.735570    0.687188    0.650919\n",
            "4  0.750      0.681010       0.684207    0.681010    0.641744\n",
            "5  1.000      0.677957       0.680250    0.677957    0.636054\n",
            "\n",
            "Melhor resultado:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.73557</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.650919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "PCA  0.5      0.687188        0.73557    0.687188    0.650919"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0d-tvxtXYcv",
        "colab_type": "text"
      },
      "source": [
        "Índice de Confiança"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAvglXMXYcv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c66c0635-fcff-48c6-e8a5-4d4f524a9da4"
      },
      "source": [
        "ic_NB_pca"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_ic</th>\n",
              "      <th>precision_ic</th>\n",
              "      <th>recall_ic</th>\n",
              "      <th>fscore_ic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>inf</th>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.679282</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.548533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sup</th>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.791858</td>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.753306</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
              "inf     0.615426      0.679282   0.615426   0.548533\n",
              "sup     0.758949      0.791858   0.758949   0.753306"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2l0V4VOXYc1",
        "colab_type": "text"
      },
      "source": [
        "### 1.3. Naive Bayes: Chi Squared (K-Best)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceYFQDGPXYc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f90a264b-3859-4ca3-c05c-7775071279be"
      },
      "source": [
        "df = pd.read_csv('results/dataset-fs-chi-squared.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "result_NB_chi, ic_NB_chi = execute_NB(X, y, list_c, k=k_folds, dataSet='Chi')\n",
        "print(\"Melhor resultado:\")\n",
        "result_NB_chi"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "c =  0.001\n",
            "       c  fold  accuracy  precision    recall    fscore\n",
            "0  0.001     1  0.584615   0.690004  0.584615  0.500114\n",
            "1  0.001     2  0.692308   0.744021  0.692308  0.664986\n",
            "2  0.001     3  0.815385   0.815711  0.815385  0.814766\n",
            "3  0.001     4  0.723077   0.740171  0.723077  0.712692\n",
            "4  0.001     5  0.707692   0.707377  0.707692  0.706006\n",
            "5  0.001     6  0.861538   0.863698  0.861538  0.860740\n",
            "6  0.001     7  0.907692   0.913215  0.907692  0.906890\n",
            "7  0.001     8  0.723077   0.723077  0.723077  0.723077\n",
            "8  0.001     9  0.707692   0.793326  0.707692  0.693081\n",
            "9  0.001    10  0.687500   0.697917  0.687500  0.686584\n",
            "\n",
            "c =  0.1\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  0.1     2  0.646154   0.686391  0.646154  0.610779\n",
            "2  0.1     3  0.753846   0.753638  0.753846  0.753021\n",
            "3  0.1     4  0.692308   0.705128  0.692308  0.680769\n",
            "4  0.1     5  0.707692   0.707377  0.707692  0.706006\n",
            "5  0.1     6  0.861538   0.863698  0.861538  0.860740\n",
            "6  0.1     7  0.969231   0.969231  0.969231  0.969231\n",
            "7  0.1     8  0.738462   0.742351  0.738462  0.738833\n",
            "8  0.1     9  0.676923   0.777963  0.676923  0.655593\n",
            "9  0.1    10  0.687500   0.697917  0.687500  0.686584\n",
            "\n",
            "c =  0.25\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.25     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  0.25     2  0.615385   0.654753  0.615385  0.567321\n",
            "2  0.25     3  0.753846   0.753638  0.753846  0.753021\n",
            "3  0.25     4  0.692308   0.705128  0.692308  0.680769\n",
            "4  0.25     5  0.707692   0.707377  0.707692  0.706006\n",
            "5  0.25     6  0.830769   0.832434  0.830769  0.829793\n",
            "6  0.25     7  0.969231   0.969231  0.969231  0.969231\n",
            "7  0.25     8  0.753846   0.755973  0.753846  0.754196\n",
            "8  0.25     9  0.692308   0.785633  0.692308  0.674556\n",
            "9  0.25    10  0.656250   0.665923  0.656250  0.655242\n",
            "\n",
            "c =  0.5\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.5     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  0.5     2  0.615385   0.654753  0.615385  0.567321\n",
            "2  0.5     3  0.753846   0.755424  0.753846  0.751708\n",
            "3  0.5     4  0.676923   0.700698  0.676923  0.657543\n",
            "4  0.5     5  0.692308   0.694653  0.692308  0.687359\n",
            "5  0.5     6  0.861538   0.868846  0.861538  0.859860\n",
            "6  0.5     7  0.969231   0.970894  0.969231  0.969128\n",
            "7  0.5     8  0.784615   0.786713  0.784615  0.784922\n",
            "8  0.5     9  0.692308   0.785633  0.692308  0.674556\n",
            "9  0.5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "c =  0.75\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.75     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  0.75     2  0.630769   0.692308  0.630769  0.579487\n",
            "2  0.75     3  0.738462   0.741154  0.738462  0.735291\n",
            "3  0.75     4  0.676923   0.700698  0.676923  0.657543\n",
            "4  0.75     5  0.676923   0.680045  0.676923  0.670273\n",
            "5  0.75     6  0.861538   0.868846  0.861538  0.859860\n",
            "6  0.75     7  0.953846   0.957490  0.953846  0.953580\n",
            "7  0.75     8  0.784615   0.784615  0.784615  0.784615\n",
            "8  0.75     9  0.692308   0.785633  0.692308  0.674556\n",
            "9  0.75    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "c =  1\n",
            "   c  fold  accuracy  precision    recall    fscore\n",
            "0  1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  1     2  0.630769   0.692308  0.630769  0.579487\n",
            "2  1     3  0.723077   0.727017  0.723077  0.718623\n",
            "3  1     4  0.646154   0.672308  0.646154  0.618401\n",
            "4  1     5  0.676923   0.680045  0.676923  0.670273\n",
            "5  1     6  0.861538   0.868846  0.861538  0.859860\n",
            "6  1     7  0.953846   0.957490  0.953846  0.953580\n",
            "7  1     8  0.784615   0.784675  0.784615  0.783893\n",
            "8  1     9  0.676923   0.753592  0.676923  0.660773\n",
            "9  1    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "Média dos resultados de cada teste:\n",
            "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  0.001      0.741058       0.768852    0.741058    0.726894\n",
            "1  0.100      0.728750       0.754436    0.728750    0.710671\n",
            "2  0.250      0.722548       0.747076    0.722548    0.703529\n",
            "3  0.500      0.727187       0.753762    0.727187    0.706903\n",
            "4  0.750      0.722548       0.751285    0.722548    0.701662\n",
            "5  1.000      0.716394       0.743834    0.716394    0.694630\n",
            "\n",
            "Melhor resultado:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.768852</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.726894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "Chi  0.001      0.741058       0.768852    0.741058    0.726894"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdb3wYpGXYc8",
        "colab_type": "text"
      },
      "source": [
        "Índice de Confiança para o dataset Chi-Squared"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3yGSap7XYc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "524a963d-87d9-43c3-e75b-9837a37ee077"
      },
      "source": [
        "ic_NB_chi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_ic</th>\n",
              "      <th>precision_ic</th>\n",
              "      <th>recall_ic</th>\n",
              "      <th>fscore_ic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>inf</th>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.714899</td>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.645429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sup</th>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.822804</td>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.808358</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
              "inf     0.673445      0.714899   0.673445   0.645429\n",
              "sup     0.808670      0.822804   0.808670   0.808358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLrlvN-ZXYdD",
        "colab_type": "text"
      },
      "source": [
        "### 1.4. Naive Bayes: Recursive Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlZN83sBXYdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6417fb5c-f109-44a2-e1e8-e237429b1cc6"
      },
      "source": [
        "df = pd.read_csv('results/dataset-fs-recursive-feature.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "result_NB_rf, ic_NB_rf = execute_NB(X, y, list_c, k=k_folds, dataSet='Recursive')\n",
        "print(\"Melhor resultado:\")\n",
        "result_NB_rf"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "c =  0.001\n",
            "       c  fold  accuracy  precision    recall    fscore\n",
            "0  0.001     1  0.584615   0.768474  0.584615  0.483424\n",
            "1  0.001     2  0.676923   0.713846  0.676923  0.651584\n",
            "2  0.001     3  0.800000   0.811594  0.800000  0.795883\n",
            "3  0.001     4  0.646154   0.650350  0.646154  0.635088\n",
            "4  0.001     5  0.769231   0.787213  0.769231  0.762014\n",
            "5  0.001     6  0.800000   0.811594  0.800000  0.795883\n",
            "6  0.001     7  0.892308   0.900769  0.892308  0.891002\n",
            "7  0.001     8  0.661538   0.670085  0.661538  0.648846\n",
            "8  0.001     9  0.769231   0.785863  0.769231  0.768465\n",
            "9  0.001    10  0.718750   0.720703  0.718750  0.719025\n",
            "\n",
            "c =  0.1\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.1     1  0.538462   0.596361  0.538462  0.415724\n",
            "1  0.1     2  0.676923   0.758612  0.676923  0.636550\n",
            "2  0.1     3  0.753846   0.775214  0.753846  0.744615\n",
            "3  0.1     4  0.676923   0.713846  0.676923  0.651584\n",
            "4  0.1     5  0.769231   0.778707  0.769231  0.764481\n",
            "5  0.1     6  0.830769   0.855644  0.830769  0.825477\n",
            "6  0.1     7  0.892308   0.900769  0.892308  0.891002\n",
            "7  0.1     8  0.676923   0.691252  0.676923  0.662597\n",
            "8  0.1     9  0.769231   0.808787  0.769231  0.765595\n",
            "9  0.1    10  0.703125   0.703904  0.703125  0.703343\n",
            "\n",
            "c =  0.25\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.25     1  0.538462   0.596361  0.538462  0.415724\n",
            "1  0.25     2  0.630769   0.725034  0.630769  0.568034\n",
            "2  0.25     3  0.753846   0.775214  0.753846  0.744615\n",
            "3  0.25     4  0.676923   0.732249  0.676923  0.644624\n",
            "4  0.25     5  0.753846   0.775214  0.753846  0.744615\n",
            "5  0.25     6  0.815385   0.862520  0.815385  0.805816\n",
            "6  0.25     7  0.876923   0.888837  0.876923  0.874944\n",
            "7  0.25     8  0.707692   0.739065  0.707692  0.690158\n",
            "8  0.25     9  0.769231   0.795858  0.769231  0.767257\n",
            "9  0.25    10  0.718750   0.720703  0.718750  0.719025\n",
            "\n",
            "c =  0.5\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.5     1  0.553846   0.759219  0.553846  0.424502\n",
            "1  0.5     2  0.600000   0.694915  0.600000  0.517730\n",
            "2  0.5     3  0.723077   0.766484  0.723077  0.704013\n",
            "3  0.5     4  0.646154   0.706682  0.646154  0.601935\n",
            "4  0.5     5  0.769231   0.815799  0.769231  0.755388\n",
            "5  0.5     6  0.815385   0.862520  0.815385  0.805816\n",
            "6  0.5     7  0.892308   0.910256  0.892308  0.890091\n",
            "7  0.5     8  0.707692   0.739065  0.707692  0.690158\n",
            "8  0.5     9  0.753846   0.766136  0.753846  0.753497\n",
            "9  0.5    10  0.703125   0.703904  0.703125  0.703343\n",
            "\n",
            "c =  0.75\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.75     1  0.553846   0.759219  0.553846  0.424502\n",
            "1  0.75     2  0.600000   0.694915  0.600000  0.517730\n",
            "2  0.75     3  0.723077   0.787546  0.723077  0.698488\n",
            "3  0.75     4  0.646154   0.706682  0.646154  0.601935\n",
            "4  0.75     5  0.753846   0.806319  0.753846  0.736901\n",
            "5  0.75     6  0.800000   0.854167  0.800000  0.788003\n",
            "6  0.75     7  0.892308   0.910256  0.892308  0.890091\n",
            "7  0.75     8  0.692308   0.726648  0.692308  0.671126\n",
            "8  0.75     9  0.753846   0.760035  0.753846  0.754079\n",
            "9  0.75    10  0.687500   0.687500  0.687500  0.687500\n",
            "\n",
            "c =  1\n",
            "   c  fold  accuracy  precision    recall    fscore\n",
            "0  1     1  0.553846   0.759219  0.553846  0.424502\n",
            "1  1     2  0.600000   0.694915  0.600000  0.517730\n",
            "2  1     3  0.723077   0.817126  0.723077  0.692058\n",
            "3  1     4  0.630769   0.692308  0.630769  0.579487\n",
            "4  1     5  0.723077   0.787546  0.723077  0.698488\n",
            "5  1     6  0.800000   0.854167  0.800000  0.788003\n",
            "6  1     7  0.876923   0.899821  0.876923  0.873767\n",
            "7  1     8  0.676923   0.713846  0.676923  0.651584\n",
            "8  1     9  0.769231   0.770034  0.769231  0.769450\n",
            "9  1    10  0.671875   0.671398  0.671875  0.671472\n",
            "\n",
            "Média dos resultados de cada teste:\n",
            "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  0.001      0.731875       0.762049    0.731875    0.715121\n",
            "1  0.100      0.728774       0.758309    0.728774    0.706097\n",
            "2  0.250      0.724183       0.761105    0.724183    0.697481\n",
            "3  0.500      0.716466       0.772498    0.716466    0.684647\n",
            "4  0.750      0.710288       0.769329    0.710288    0.677036\n",
            "5  1.000      0.702572       0.766038    0.702572    0.666654\n",
            "\n",
            "Melhor resultado:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.762049</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.715121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "Recursive  0.001      0.731875       0.762049    0.731875    0.715121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-1UTe46XYdN",
        "colab_type": "text"
      },
      "source": [
        "Índice de Confiança para dataset Recursive-Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SlCXxWNXYdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c3ec35d0-b3fa-4639-93a5-ecad2f67ef45"
      },
      "source": [
        "ic_NB_rf"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_ic</th>\n",
              "      <th>precision_ic</th>\n",
              "      <th>recall_ic</th>\n",
              "      <th>fscore_ic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>inf</th>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.708537</td>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.633364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sup</th>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.815561</td>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.796879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
              "inf     0.666579      0.708537   0.666579   0.633364\n",
              "sup     0.797171      0.815561   0.797171   0.796879"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRoX2JhXYdV",
        "colab_type": "text"
      },
      "source": [
        "# 2. SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQQ7C2YYXYdW",
        "colab_type": "text"
      },
      "source": [
        "##### Parâmetros de execução do SVM\n",
        "\n",
        "* k_folds:     número de folds para a estratificação do dataset\n",
        "\n",
        "* list_c:      valores do parâmetro de ajuste de probabilidade \n",
        "\n",
        "* list_degree: valores do parâmetro degree utilizado no kernel poly\n",
        "\n",
        "* list_gamma:  valores do parâmetro gamma utilizado no kernel poly\n",
        "\n",
        "* list_coef:   valores do parâmetro coef utilizado no kernel rbf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3SyfgJAXYdW",
        "colab_type": "text"
      },
      "source": [
        "* Função que aplica o SVM para cada Kernel implementado\n",
        "* Em cada kernel é testado vários valores de cada parâmetro.\n",
        "* Com o resultado de cada parâmetro, verifica qual a melhor acurácia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRl-BHnXYdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def execute_SVM(X, y, k, list_c, list_degree, list_gamma, list_coef, dataSet):\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------    \n",
        "              X: array-like, shape (n_samples, n_features)\n",
        "                 Training data, where n_samples is the number of samples\n",
        "                 and n_features is the number of features.\n",
        "              y: array-like, of length n_samples\n",
        "                 The target variable for supervised learning problems.\n",
        "              k: int\n",
        "                 Determines the number of folds.\n",
        "        dataSet: method selection (string)\n",
        "         list_c: values of parameter c\n",
        "    list_degree: values of parameter degree\n",
        "     list_gamma: values of parameter gamma\n",
        "      list_coef: values of parameter coef\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    ### Resultados\n",
        "    result = []              # result:             melhor resultado geral do SVM\n",
        "    result_best_linear = []  # result_best_linear: melhor resultado do kernel linear\n",
        "    result_best_poly = []    # result_best_poly:   melhor resultado do kernel poly\n",
        "    result_best_rbf = []     # result_best_rbf:    melhor resultado do kernel rbf\n",
        "\n",
        "\n",
        "    ### Estratifica o dataset em k folds\n",
        "    skf = StratifiedKFold(n_splits=k)\n",
        "    describe_dataset(X, y, k)\n",
        "    get_classes_from_index(y, skf) \n",
        "    \n",
        "    \n",
        "    #################################################################################################################\n",
        "    # 1. KERNEL LINEAR\n",
        "    #################################################################################################################\n",
        "    result_linear = []\n",
        "    result_linear_ic = []\n",
        "    for C in list_c:\n",
        "        \n",
        "        ### Create a SVM Linear Classifier\n",
        "        model_linear = svm.SVC(kernel='linear', C=C)\n",
        "        kernel = model_linear.kernel\n",
        "        \n",
        "        ### resultado do fold-k\n",
        "        result_k = []\n",
        "        \n",
        "        fold_k = 1\n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "            ### Train the model\n",
        "            model_linear.fit(X_train, y_train)\n",
        "    \n",
        "            ### Test the model\n",
        "            y_predicted = model_linear.predict(X_test)\n",
        "            \n",
        "            ### calculate metrics\n",
        "            report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
        "            report_str = metrics.classification_report(y_test, y_predicted)        \n",
        "            ### print(report_str)\n",
        "            \n",
        "            all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
        "            accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
        "            precision = all_metrics[0]\n",
        "            recall = all_metrics[1]\n",
        "            fscore = all_metrics[2]\n",
        "                        \n",
        "            ### Armazena o resultado do fold k\n",
        "            result_k.append([kernel, C, fold_k, accuracy, precision, recall, fscore])\n",
        "            \n",
        "            fold_k = fold_k + 1\n",
        "    \n",
        "        result_k = pd.DataFrame(result_k, columns=['kernel', 'c', 'fold', 'accuracy','precision','recall','fscore'])\n",
        "        print(result_k)\n",
        "        print(\"\")\n",
        "        \n",
        "        ### calcula a média das métricas dos k-folds      \n",
        "        accuracy_avg = result_k['accuracy'].mean()\n",
        "        precision_avg = result_k['precision'].mean()\n",
        "        recall_avg = result_k['recall'].mean()\n",
        "        fscore_avg = result_k['fscore'].mean()\n",
        "        \n",
        "        ### Calcula o índice de confiança dos k-folds\n",
        "        alpha = 0.05\n",
        "        ic_c = get_ic(result_k, alpha)\n",
        "        \n",
        "        ### Armazena a média dos resultados dos k-folds e o índice de confiança\n",
        "        result_linear.append([kernel, C, accuracy_avg, precision_avg, recall_avg, fscore_avg]) \n",
        "        result_linear_ic.append(ic_c)\n",
        "\n",
        "    \n",
        "    ### Exibe os resultados de cada valor c\n",
        "    result_linear = pd.DataFrame(result_linear, columns=['kernel', 'c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    result_linear_ic = pd.DataFrame(result_linear_ic, columns=['accuracy_ic','precision_ic','recall_ic','fscore_ic'])\n",
        "    print(\"Média dos resultados do kernel linear\")\n",
        "    print(result_linear)\n",
        "    print(\"\")\n",
        "    \n",
        "    \n",
        "    #################################################################################################################\n",
        "    # 2.KERNEL POLY\n",
        "    #################################################################################################################\n",
        "    result_poly = []\n",
        "    result_poly_ic = []\n",
        "    for C in list_c:\n",
        "        for gamma in list_gamma:\n",
        "            for degree in list_degree:\n",
        "                \n",
        "                ### Create a SVM Linear Classifier\n",
        "                model_poly = svm.SVC(kernel='poly', degree=degree, gamma=gamma, C=C)\n",
        "                kernel = model_poly.kernel\n",
        "                \n",
        "                ### resultado do fold-k\n",
        "                result_k = []\n",
        "                \n",
        "                fold_k = 1\n",
        "                for train_index, test_index in skf.split(X, y):\n",
        "                    X_train, X_test = X[train_index], X[test_index]\n",
        "                    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                    ### Train the model\n",
        "                    model_poly.fit(X_train, y_train)\n",
        "\n",
        "                    ### Test the model\n",
        "                    y_predicted = model_poly.predict(X_test)\n",
        "\n",
        "                    ### calculate metrics\n",
        "                    report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
        "                    report_str = metrics.classification_report(y_test, y_predicted)        \n",
        "                    ### print(report_str)\n",
        "\n",
        "                    all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
        "                    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
        "                    precision = all_metrics[0]\n",
        "                    recall = all_metrics[1]\n",
        "                    fscore = all_metrics[2]\n",
        "\n",
        "                    ### Armazena o resultado do fold k\n",
        "                    result_k.append([kernel, C, gamma, degree, fold_k, accuracy, precision, recall, fscore])\n",
        "\n",
        "                    fold_k = fold_k + 1\n",
        "\n",
        "                result_k = pd.DataFrame(result_k, columns=['kernel', 'c', 'gamma', 'degree', 'fold', 'accuracy','precision','recall','fscore'])\n",
        "                print(result_k)\n",
        "                print(\"\")\n",
        "                \n",
        "                ### calcula a média das métricas dos k-folds      \n",
        "                accuracy_avg = result_k['accuracy'].mean()\n",
        "                precision_avg = result_k['precision'].mean()\n",
        "                recall_avg = result_k['recall'].mean()\n",
        "                fscore_avg = result_k['fscore'].mean()\n",
        "\n",
        "                ### Calcula o índice de confiança dos k-folds\n",
        "                alpha = 0.05\n",
        "                ic_c = get_ic(result_k, alpha)\n",
        "\n",
        "                ### Armazena a média dos resultados dos k-folds e o índice de confiança\n",
        "                result_poly.append([kernel, C, gamma, degree, accuracy_avg, precision_avg, recall_avg, fscore_avg]) \n",
        "                result_poly_ic.append(ic_c)\n",
        "    \n",
        "    ### Exibe os resultados de cada valor c\n",
        "    result_poly = pd.DataFrame(result_poly, columns=['kernel', 'c', 'gamma', 'degree', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    result_poly_ic = pd.DataFrame(result_poly_ic, columns=['accuracy_ic','precision_ic','recall_ic','fscore_ic'])\n",
        "    print(\"Média dos resultados do kernel poly\")\n",
        "    print(result_poly)\n",
        "    print(\"\")            \n",
        "        \n",
        "        \n",
        "    #################################################################################################################\n",
        "    ### 3. KERNEL RBF\n",
        "    #################################################################################################################\n",
        "    result_rbf = []\n",
        "    result_rbf_ic = []\n",
        "    for C in list_c:\n",
        "        for gamma in list_gamma:\n",
        "            ### Create a SVM Linear Classifier\n",
        "            model_rbf = svm.SVC(kernel='rbf', gamma=gamma, C=C)   \n",
        "            kernel = model_rbf.kernel\n",
        "                \n",
        "            ### resultado do fold-k\n",
        "            result_k = []\n",
        "\n",
        "            fold_k = 1\n",
        "            \n",
        "            for train_index, test_index in skf.split(X, y):\n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                ### Train the model\n",
        "                model_rbf.fit(X_train, y_train)\n",
        "\n",
        "                ### Test the model\n",
        "                y_predicted = model_rbf.predict(X_test)\n",
        "\n",
        "                ### calculate metrics\n",
        "                report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
        "                report_str = metrics.classification_report(y_test, y_predicted)        \n",
        "                ### print(report_str)\n",
        "\n",
        "                all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
        "                accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
        "                precision = all_metrics[0]\n",
        "                recall = all_metrics[1]\n",
        "                fscore = all_metrics[2]\n",
        "\n",
        "                ### Armazena o resultado do fold k\n",
        "                result_k.append([kernel, C, gamma, fold_k, accuracy, precision, recall, fscore])\n",
        "\n",
        "                fold_k = fold_k + 1\n",
        "\n",
        "            result_k = pd.DataFrame(result_k, columns=['kernel', 'c', 'gamma', 'fold', 'accuracy','precision','recall','fscore'])\n",
        "            print(result_k)\n",
        "            print(\"\")           \n",
        "            \n",
        "            ### calcula a média das métricas dos k-folds      \n",
        "            accuracy_avg = result_k['accuracy'].mean()\n",
        "            precision_avg = result_k['precision'].mean()\n",
        "            recall_avg = result_k['recall'].mean()\n",
        "            fscore_avg = result_k['fscore'].mean()\n",
        "\n",
        "            ### Calcula o índice de confiança dos k-folds\n",
        "            alpha = 0.05\n",
        "            ic_c = get_ic(result_k, alpha)\n",
        "\n",
        "            ### Armazena a média dos resultados dos k-folds e o índice de confiança\n",
        "            result_rbf.append([kernel, C, gamma, accuracy_avg, precision_avg, recall_avg, fscore_avg]) \n",
        "            result_rbf_ic.append(ic_c)\n",
        "    \n",
        "    ### Exibe os resultados de cada valor c\n",
        "    result_rbf = pd.DataFrame(result_rbf, columns=['kernel', 'c', 'gamma', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    result_rbf_ic = pd.DataFrame(result_rbf_ic, columns=['accuracy_ic','precision_ic','recall_ic','fscore_ic'])\n",
        "    print(\"Média dos resultados do kernel rbf\")\n",
        "    print(result_rbf)\n",
        "    print(\"\")            \n",
        "           \n",
        "    \n",
        "    \n",
        "    #################################################################################################################\n",
        "    ### ARMAZENA OS MELHORES RESULTADOS \n",
        "    #################################################################################################################\n",
        "    \n",
        "    ### Armazena apenas as métricas da melhor acurácia média do MODELO LINEAR e o seu indice de confiança\n",
        "    result_best_linear.append(result_linear.iloc[result_linear['accuracy_avg'].argmax()])\n",
        "    result_best_linear = pd.DataFrame(result_best_linear, columns=['kernel', 'c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    # print(result_best_linear)\n",
        "    print(\"\")\n",
        "    \n",
        "    ic = result_linear_ic.iloc[result_linear['accuracy_avg'].argmax()]\n",
        "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
        "    ic_best_linear = pd.DataFrame(ic, index=['inf','sup'])\n",
        "    \n",
        "    \n",
        "    ### Armazena apenas as métricas da melhor acurácia média do MODELO POLY e o seu respectivo indice de confiança\n",
        "    result_best_poly.append(result_poly.iloc[result_poly['accuracy_avg'].argmax()])\n",
        "    result_best_poly = pd.DataFrame(result_best_poly, columns=['kernel', 'c', 'gamma', 'degree', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    # print(result_best_poly)\n",
        "    print(\"\")\n",
        "    \n",
        "    ic = result_poly_ic.iloc[result_poly['accuracy_avg'].argmax()]\n",
        "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
        "    ic_best_poly = pd.DataFrame(ic, index=['inf','sup'])\n",
        "    \n",
        "    \n",
        "    ### Armazena apenas as métricas da melhor acurácia média do MODELO RBF e seu índice de confiança\n",
        "    result_best_rbf.append(result_rbf.iloc[result_rbf['accuracy_avg'].argmax()])\n",
        "    result_best_rbf = pd.DataFrame(result_best_rbf, columns=['kernel', 'c', 'gamma', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    # print(result_best_rbf)\n",
        "    print(\"\")\n",
        "    \n",
        "    ic = result_rbf_ic.iloc[result_rbf['accuracy_avg'].argmax()]\n",
        "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
        "    ic_best_rbf = pd.DataFrame(ic, index=['inf','sup'])\n",
        "    \n",
        "    \n",
        "    ### Retorna o melhor resultado de cada kernel e seus respectivos índices de confiança \n",
        "    return result_best_linear, result_best_poly, result_best_rbf, ic_best_linear, ic_best_poly, ic_best_rbf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWggVTGVXYdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list_c = [0.001, 0.10, 0.25, 0.50, 0.75, 1]\n",
        "list_c = [0.001, 0.10]\n",
        "list_gamma = [0.001, 0.1, 0.5, 1]\n",
        "list_degree = [1, 2, 3, 4, 5]\n",
        "\n",
        "list_coef = [0.01]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkUiX3QMXYdg",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. SVM: all features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GhPrp6blXYdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d256364c-2102-49c1-fdf6-e6496bd3ce16"
      },
      "source": [
        "df = pd.read_csv('results/dataset-normalizado.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "\n",
        "result_linear_all, result_poly_all, result_rbf_all, ic_linear_all, ic_poly_all, ic_rbf_all = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, list_coef, dataSet='All Features')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "   kernel      c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "   kernel    c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.1     1  0.584615   0.768474  0.584615  0.483424\n",
            "1  linear  0.1     2  0.676923   0.758612  0.676923  0.636550\n",
            "2  linear  0.1     3  0.800000   0.805000  0.800000  0.797576\n",
            "3  linear  0.1     4  0.646154   0.686391  0.646154  0.610779\n",
            "4  linear  0.1     5  0.738462   0.752997  0.738462  0.730282\n",
            "5  linear  0.1     6  0.738462   0.745819  0.738462  0.733078\n",
            "6  linear  0.1     7  0.907692   0.908821  0.907692  0.907383\n",
            "7  linear  0.1     8  0.661538   0.660750  0.661538  0.658598\n",
            "8  linear  0.1     9  0.584615   0.781377  0.584615  0.518660\n",
            "9  linear  0.1    10  0.640625   0.677291  0.640625  0.630153\n",
            "\n",
            "Média dos resultados do kernel linear\n",
            "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1  linear  0.100      0.697909       0.754553    0.697909    0.670648\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       2     2  0.538462   0.521368  0.538462  0.402473\n",
            "2   poly  0.001    0.5       2     3  0.600000   0.657895  0.600000  0.532037\n",
            "3   poly  0.001    0.5       2     4  0.553846   0.602978  0.553846  0.433422\n",
            "4   poly  0.001    0.5       2     5  0.584615   0.636036  0.584615  0.506874\n",
            "5   poly  0.001    0.5       2     6  0.676923   0.798077  0.676923  0.627219\n",
            "6   poly  0.001    0.5       2     7  0.723077   0.817126  0.723077  0.692058\n",
            "7   poly  0.001    0.5       2     8  0.615385   0.676282  0.615385  0.556213\n",
            "8   poly  0.001    0.5       2     9  0.815385   0.815385  0.815385  0.815385\n",
            "9   poly  0.001    0.5       2    10  0.656250   0.657813  0.656250  0.651089\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       3     1  0.538462   0.596361  0.538462  0.415724\n",
            "1   poly  0.001    0.5       3     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.001    0.5       3     3  0.738462   0.752997  0.738462  0.730282\n",
            "3   poly  0.001    0.5       3     4  0.630769   0.692308  0.630769  0.579487\n",
            "4   poly  0.001    0.5       3     5  0.707692   0.718781  0.707692  0.698551\n",
            "5   poly  0.001    0.5       3     6  0.800000   0.821429  0.800000  0.793745\n",
            "6   poly  0.001    0.5       3     7  0.876923   0.888837  0.876923  0.874944\n",
            "7   poly  0.001    0.5       3     8  0.676923   0.677308  0.676923  0.673007\n",
            "8   poly  0.001    0.5       3     9  0.584615   0.692550  0.584615  0.540532\n",
            "9   poly  0.001    0.5       3    10  0.687500   0.704706  0.687500  0.685049\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       4     1  0.569231   0.607509  0.569231  0.503419\n",
            "1   poly  0.001    0.5       4     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.001    0.5       4     3  0.769231   0.778707  0.769231  0.764481\n",
            "3   poly  0.001    0.5       4     4  0.615385   0.623963  0.615385  0.592314\n",
            "4   poly  0.001    0.5       4     5  0.692308   0.692308  0.692308  0.689635\n",
            "5   poly  0.001    0.5       4     6  0.815385   0.832818  0.815385  0.810651\n",
            "6   poly  0.001    0.5       4     7  0.861538   0.862210  0.861538  0.861670\n",
            "7   poly  0.001    0.5       4     8  0.630769   0.629492  0.630769  0.629531\n",
            "8   poly  0.001    0.5       4     9  0.584615   0.667421  0.584615  0.549451\n",
            "9   poly  0.001    0.5       4    10  0.671875   0.684904  0.671875  0.670189\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       5     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.001    0.5       5     2  0.707692   0.718781  0.707692  0.698551\n",
            "2   poly  0.001    0.5       5     3  0.723077   0.727017  0.723077  0.718623\n",
            "3   poly  0.001    0.5       5     4  0.538462   0.531306  0.538462  0.526627\n",
            "4   poly  0.001    0.5       5     5  0.707692   0.707377  0.707692  0.706006\n",
            "5   poly  0.001    0.5       5     6  0.738462   0.738064  0.738462  0.738087\n",
            "6   poly  0.001    0.5       5     7  0.769231   0.778388  0.769231  0.769231\n",
            "7   poly  0.001    0.5       5     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.001    0.5       5     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.001    0.5       5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       2     1  0.538462   0.596361  0.538462  0.415724\n",
            "1   poly  0.001      1       2     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.001      1       2     3  0.753846   0.765816  0.753846  0.747535\n",
            "3   poly  0.001      1       2     4  0.600000   0.657895  0.600000  0.532037\n",
            "4   poly  0.001      1       2     5  0.661538   0.670085  0.661538  0.648846\n",
            "5   poly  0.001      1       2     6  0.815385   0.832818  0.815385  0.810651\n",
            "6   poly  0.001      1       2     7  0.907692   0.913215  0.907692  0.906890\n",
            "7   poly  0.001      1       2     8  0.707692   0.707377  0.707692  0.706006\n",
            "8   poly  0.001      1       2     9  0.630769   0.754438  0.630769  0.595685\n",
            "9   poly  0.001      1       2    10  0.671875   0.692212  0.671875  0.668248\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       3     1  0.600000   0.669841  0.600000  0.538889\n",
            "1   poly  0.001      1       3     2  0.738462   0.752997  0.738462  0.730282\n",
            "2   poly  0.001      1       3     3  0.784615   0.799317  0.784615  0.779093\n",
            "3   poly  0.001      1       3     4  0.646154   0.662330  0.646154  0.624929\n",
            "4   poly  0.001      1       3     5  0.692308   0.694653  0.692308  0.687359\n",
            "5   poly  0.001      1       3     6  0.846154   0.856473  0.846154  0.843680\n",
            "6   poly  0.001      1       3     7  0.907692   0.908821  0.907692  0.907383\n",
            "7   poly  0.001      1       3     8  0.630769   0.629492  0.630769  0.629531\n",
            "8   poly  0.001      1       3     9  0.600000   0.680000  0.600000  0.570000\n",
            "9   poly  0.001      1       3    10  0.656250   0.665923  0.656250  0.655242\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       4     1  0.553846   0.564417  0.553846  0.503995\n",
            "1   poly  0.001      1       4     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.001      1       4     3  0.676923   0.676113  0.676923  0.675060\n",
            "3   poly  0.001      1       4     4  0.538462   0.532833  0.538462  0.531039\n",
            "4   poly  0.001      1       4     5  0.692308   0.691565  0.692308  0.691276\n",
            "5   poly  0.001      1       4     6  0.707692   0.708583  0.707692  0.707970\n",
            "6   poly  0.001      1       4     7  0.784615   0.790979  0.784615  0.784819\n",
            "7   poly  0.001      1       4     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.001      1       4     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.001      1       4    10  0.640625   0.652559  0.640625  0.638778\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       5     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.001      1       5     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.001      1       5     3  0.738462   0.741154  0.738462  0.735291\n",
            "3   poly  0.001      1       5     4  0.523077   0.515608  0.523077  0.513260\n",
            "4   poly  0.001      1       5     5  0.707692   0.707377  0.707692  0.706006\n",
            "5   poly  0.001      1       5     6  0.738462   0.738064  0.738462  0.738087\n",
            "6   poly  0.001      1       5     7  0.769231   0.778388  0.769231  0.769231\n",
            "7   poly  0.001      1       5     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.001      1       5     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.001      1       5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       1     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.1    0.1       1     2  0.615385   0.711254  0.615385  0.543402\n",
            "2   poly  0.1    0.1       1     3  0.738462   0.745819  0.738462  0.733078\n",
            "3   poly  0.1    0.1       1     4  0.615385   0.676282  0.615385  0.556213\n",
            "4   poly  0.1    0.1       1     5  0.646154   0.662330  0.646154  0.624929\n",
            "5   poly  0.1    0.1       1     6  0.846154   0.856473  0.846154  0.843680\n",
            "6   poly  0.1    0.1       1     7  0.907692   0.913215  0.907692  0.906890\n",
            "7   poly  0.1    0.1       1     8  0.676923   0.684565  0.676923  0.666819\n",
            "8   poly  0.1    0.1       1     9  0.661538   0.770256  0.661538  0.636154\n",
            "9   poly  0.1    0.1       1    10  0.640625   0.658942  0.640625  0.636653\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       2     1  0.538462   0.596361  0.538462  0.415724\n",
            "1   poly  0.1    0.1       2     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.1       2     3  0.753846   0.765816  0.753846  0.747535\n",
            "3   poly  0.1    0.1       2     4  0.600000   0.657895  0.600000  0.532037\n",
            "4   poly  0.1    0.1       2     5  0.661538   0.670085  0.661538  0.648846\n",
            "5   poly  0.1    0.1       2     6  0.815385   0.832818  0.815385  0.810651\n",
            "6   poly  0.1    0.1       2     7  0.907692   0.913215  0.907692  0.906890\n",
            "7   poly  0.1    0.1       2     8  0.707692   0.707377  0.707692  0.706006\n",
            "8   poly  0.1    0.1       2     9  0.630769   0.754438  0.630769  0.595685\n",
            "9   poly  0.1    0.1       2    10  0.671875   0.692212  0.671875  0.668248\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       3     1  0.538462   0.596361  0.538462  0.415724\n",
            "1   poly  0.1    0.1       3     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.1       3     3  0.753846   0.765816  0.753846  0.747535\n",
            "3   poly  0.1    0.1       3     4  0.630769   0.692308  0.630769  0.579487\n",
            "4   poly  0.1    0.1       3     5  0.707692   0.718781  0.707692  0.698551\n",
            "5   poly  0.1    0.1       3     6  0.800000   0.821429  0.800000  0.793745\n",
            "6   poly  0.1    0.1       3     7  0.876923   0.888837  0.876923  0.874944\n",
            "7   poly  0.1    0.1       3     8  0.692308   0.694653  0.692308  0.687359\n",
            "8   poly  0.1    0.1       3     9  0.584615   0.692550  0.584615  0.540532\n",
            "9   poly  0.1    0.1       3    10  0.687500   0.704706  0.687500  0.685049\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       4     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.1    0.1       4     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.1       4     3  0.753846   0.765816  0.753846  0.747535\n",
            "3   poly  0.1    0.1       4     4  0.630769   0.671263  0.630769  0.589411\n",
            "4   poly  0.1    0.1       4     5  0.692308   0.705128  0.692308  0.680769\n",
            "5   poly  0.1    0.1       4     6  0.800000   0.821429  0.800000  0.793745\n",
            "6   poly  0.1    0.1       4     7  0.846154   0.856473  0.846154  0.843680\n",
            "7   poly  0.1    0.1       4     8  0.646154   0.645385  0.646154  0.641865\n",
            "8   poly  0.1    0.1       4     9  0.630769   0.725128  0.630769  0.603077\n",
            "9   poly  0.1    0.1       4    10  0.687500   0.697917  0.687500  0.686584\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       5     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.1    0.1       5     2  0.661538   0.748252  0.661538  0.614530\n",
            "2   poly  0.1    0.1       5     3  0.738462   0.763246  0.738462  0.726864\n",
            "3   poly  0.1    0.1       5     4  0.615385   0.654753  0.615385  0.567321\n",
            "4   poly  0.1    0.1       5     5  0.692308   0.714130  0.692308  0.676360\n",
            "5   poly  0.1    0.1       5     6  0.784615   0.810256  0.784615  0.776538\n",
            "6   poly  0.1    0.1       5     7  0.830769   0.836923  0.830769  0.828718\n",
            "7   poly  0.1    0.1       5     8  0.630769   0.629925  0.630769  0.624831\n",
            "8   poly  0.1    0.1       5     9  0.615385   0.714932  0.615385  0.582825\n",
            "9   poly  0.1    0.1       5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       1     1  0.584615   0.768474  0.584615  0.483424\n",
            "1   poly  0.1    0.5       1     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.5       1     3  0.769231   0.778707  0.769231  0.764481\n",
            "3   poly  0.1    0.5       1     4  0.630769   0.692308  0.630769  0.579487\n",
            "4   poly  0.1    0.5       1     5  0.738462   0.745819  0.738462  0.733078\n",
            "5   poly  0.1    0.5       1     6  0.815385   0.818540  0.815385  0.813781\n",
            "6   poly  0.1    0.5       1     7  0.907692   0.908821  0.907692  0.907383\n",
            "7   poly  0.1    0.5       1     8  0.661538   0.660750  0.661538  0.658598\n",
            "8   poly  0.1    0.5       1     9  0.600000   0.737374  0.600000  0.552795\n",
            "9   poly  0.1    0.5       1    10  0.640625   0.677291  0.640625  0.630153\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       2     1  0.584615   0.651350  0.584615  0.514624\n",
            "1   poly  0.1    0.5       2     2  0.738462   0.763246  0.738462  0.726864\n",
            "2   poly  0.1    0.5       2     3  0.800000   0.821429  0.800000  0.793745\n",
            "3   poly  0.1    0.5       2     4  0.661538   0.670085  0.661538  0.648846\n",
            "4   poly  0.1    0.5       2     5  0.692308   0.694653  0.692308  0.687359\n",
            "5   poly  0.1    0.5       2     6  0.846154   0.850099  0.846154  0.844817\n",
            "6   poly  0.1    0.5       2     7  0.907692   0.908821  0.907692  0.907383\n",
            "7   poly  0.1    0.5       2     8  0.600000   0.598456  0.600000  0.598659\n",
            "8   poly  0.1    0.5       2     9  0.615385   0.691817  0.615385  0.589992\n",
            "9   poly  0.1    0.5       2    10  0.640625   0.647629  0.640625  0.640186\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       3     1  0.569231   0.585207  0.569231  0.526199\n",
            "1   poly  0.1    0.5       3     2  0.707692   0.709231  0.707692  0.704149\n",
            "2   poly  0.1    0.5       3     3  0.707692   0.707191  0.707692  0.707274\n",
            "3   poly  0.1    0.5       3     4  0.569231   0.565197  0.569231  0.562303\n",
            "4   poly  0.1    0.5       3     5  0.723077   0.723866  0.723077  0.720671\n",
            "5   poly  0.1    0.5       3     6  0.676923   0.680726  0.676923  0.677382\n",
            "6   poly  0.1    0.5       3     7  0.769231   0.773164  0.769231  0.769559\n",
            "7   poly  0.1    0.5       3     8  0.553846   0.549615  0.553846  0.548438\n",
            "8   poly  0.1    0.5       3     9  0.630769   0.703054  0.630769  0.609467\n",
            "9   poly  0.1    0.5       3    10  0.609375   0.625673  0.609375  0.605057\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       4     1  0.553846   0.564417  0.553846  0.503995\n",
            "1   poly  0.1    0.5       4     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.1    0.5       4     3  0.692308   0.691565  0.692308  0.691276\n",
            "3   poly  0.1    0.5       4     4  0.538462   0.532833  0.538462  0.531039\n",
            "4   poly  0.1    0.5       4     5  0.692308   0.691565  0.692308  0.691276\n",
            "5   poly  0.1    0.5       4     6  0.707692   0.708583  0.707692  0.707970\n",
            "6   poly  0.1    0.5       4     7  0.784615   0.790979  0.784615  0.784819\n",
            "7   poly  0.1    0.5       4     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.1    0.5       4     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.1    0.5       4    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       5     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.1    0.5       5     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.1    0.5       5     3  0.738462   0.741154  0.738462  0.735291\n",
            "3   poly  0.1    0.5       5     4  0.523077   0.515608  0.523077  0.513260\n",
            "4   poly  0.1    0.5       5     5  0.707692   0.707377  0.707692  0.706006\n",
            "5   poly  0.1    0.5       5     6  0.738462   0.738064  0.738462  0.738087\n",
            "6   poly  0.1    0.5       5     7  0.769231   0.778388  0.769231  0.769231\n",
            "7   poly  0.1    0.5       5     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.1    0.5       5     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.1    0.5       5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       1     1  0.584615   0.768474  0.584615  0.483424\n",
            "1   poly  0.1      1       1     2  0.676923   0.758612  0.676923  0.636550\n",
            "2   poly  0.1      1       1     3  0.800000   0.805000  0.800000  0.797576\n",
            "3   poly  0.1      1       1     4  0.646154   0.686391  0.646154  0.610779\n",
            "4   poly  0.1      1       1     5  0.738462   0.752997  0.738462  0.730282\n",
            "5   poly  0.1      1       1     6  0.738462   0.745819  0.738462  0.733078\n",
            "6   poly  0.1      1       1     7  0.907692   0.908821  0.907692  0.907383\n",
            "7   poly  0.1      1       1     8  0.661538   0.660750  0.661538  0.658598\n",
            "8   poly  0.1      1       1     9  0.584615   0.781377  0.584615  0.518660\n",
            "9   poly  0.1      1       1    10  0.640625   0.677291  0.640625  0.630153\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       2     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.1      1       2     2  0.723077   0.740171  0.723077  0.712692\n",
            "2   poly  0.1      1       2     3  0.615385   0.616406  0.615385  0.615750\n",
            "3   poly  0.1      1       2     4  0.630769   0.635043  0.630769  0.616923\n",
            "4   poly  0.1      1       2     5  0.661538   0.660529  0.661538  0.660404\n",
            "5   poly  0.1      1       2     6  0.753846   0.753846  0.753846  0.753846\n",
            "6   poly  0.1      1       2     7  0.830769   0.831484  0.830769  0.830930\n",
            "7   poly  0.1      1       2     8  0.630769   0.629492  0.630769  0.629531\n",
            "8   poly  0.1      1       2     9  0.584615   0.648744  0.584615  0.557191\n",
            "9   poly  0.1      1       2    10  0.656250   0.665923  0.656250  0.655242\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       3     1  0.584615   0.604029  0.584615  0.547692\n",
            "1   poly  0.1      1       3     2  0.753846   0.759381  0.753846  0.749888\n",
            "2   poly  0.1      1       3     3  0.692308   0.692308  0.692308  0.692308\n",
            "3   poly  0.1      1       3     4  0.523077   0.519793  0.523077  0.520326\n",
            "4   poly  0.1      1       3     5  0.676923   0.676113  0.676923  0.675060\n",
            "5   poly  0.1      1       3     6  0.676923   0.680726  0.676923  0.677382\n",
            "6   poly  0.1      1       3     7  0.815385   0.817453  0.815385  0.815647\n",
            "7   poly  0.1      1       3     8  0.553846   0.549615  0.553846  0.548438\n",
            "8   poly  0.1      1       3     9  0.630769   0.703054  0.630769  0.609467\n",
            "9   poly  0.1      1       3    10  0.593750   0.601935  0.593750  0.592559\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       4     1  0.553846   0.564417  0.553846  0.503995\n",
            "1   poly  0.1      1       4     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.1      1       4     3  0.692308   0.691565  0.692308  0.691276\n",
            "3   poly  0.1      1       4     4  0.538462   0.532833  0.538462  0.531039\n",
            "4   poly  0.1      1       4     5  0.692308   0.691565  0.692308  0.691276\n",
            "5   poly  0.1      1       4     6  0.707692   0.708583  0.707692  0.707970\n",
            "6   poly  0.1      1       4     7  0.784615   0.790979  0.784615  0.784819\n",
            "7   poly  0.1      1       4     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.1      1       4     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.1      1       4    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       5     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.1      1       5     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.1      1       5     3  0.738462   0.741154  0.738462  0.735291\n",
            "3   poly  0.1      1       5     4  0.523077   0.515608  0.523077  0.513260\n",
            "4   poly  0.1      1       5     5  0.707692   0.707377  0.707692  0.706006\n",
            "5   poly  0.1      1       5     6  0.738462   0.738064  0.738462  0.738087\n",
            "6   poly  0.1      1       5     7  0.769231   0.778388  0.769231  0.769231\n",
            "7   poly  0.1      1       5     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.1      1       5     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.1      1       5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "Média dos resultados do kernel poly\n",
            "   kernel      c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
            "0    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "1    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "2    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "3    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "4    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "5    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "6    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "7    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "8    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "9    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "10   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "11   poly  0.001  0.500  ...       0.645657    0.628702    0.557605\n",
            "12   poly  0.001  0.500  ...       0.728246    0.688750    0.658304\n",
            "13   poly  0.001  0.500  ...       0.708446    0.690264    0.675211\n",
            "14   poly  0.001  0.500  ...       0.663156    0.654880    0.644915\n",
            "15   poly  0.001  1.000  ...       0.287536    0.536202    0.374329\n",
            "16   poly  0.001  1.000  ...       0.732740    0.693341    0.662334\n",
            "17   poly  0.001  1.000  ...       0.731985    0.710240    0.696639\n",
            "18   poly  0.001  1.000  ...       0.653500    0.644062    0.634190\n",
            "19   poly  0.001  1.000  ...       0.661634    0.653341    0.643467\n",
            "20   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "21   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "22   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "23   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "24   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "25   poly  0.100  0.100  ...       0.743836    0.690216    0.657232\n",
            "26   poly  0.100  0.100  ...       0.732740    0.693341    0.662334\n",
            "27   poly  0.100  0.100  ...       0.731262    0.691827    0.661464\n",
            "28   poly  0.100  0.100  ...       0.738494    0.688750    0.660288\n",
            "29   poly  0.100  0.100  ...       0.731098    0.679495    0.649396\n",
            "30   poly  0.100  0.500  ...       0.752526    0.699447    0.671490\n",
            "31   poly  0.100  0.500  ...       0.729758    0.708678    0.695248\n",
            "32   poly  0.100  0.500  ...       0.662292    0.651707    0.643050\n",
            "33   poly  0.100  0.500  ...       0.655929    0.647163    0.637559\n",
            "34   poly  0.100  0.500  ...       0.661634    0.653341    0.643467\n",
            "35   poly  0.100  1.000  ...       0.754553    0.697909    0.670648\n",
            "36   poly  0.100  1.000  ...       0.672010    0.662548    0.652487\n",
            "37   poly  0.100  1.000  ...       0.660441    0.650144    0.642877\n",
            "38   poly  0.100  1.000  ...       0.655929    0.647163    0.637559\n",
            "39   poly  0.100  1.000  ...       0.661634    0.653341    0.643467\n",
            "\n",
            "[40 rows x 8 columns]\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.1     1  0.523077   0.512454  0.523077  0.384812\n",
            "1    rbf  0.1    0.1     2  0.615385   0.711254  0.615385  0.543402\n",
            "2    rbf  0.1    0.1     3  0.707692   0.755385  0.707692  0.684766\n",
            "3    rbf  0.1    0.1     4  0.584615   0.636036  0.584615  0.506874\n",
            "4    rbf  0.1    0.1     5  0.630769   0.646978  0.630769  0.605351\n",
            "5    rbf  0.1    0.1     6  0.815385   0.845299  0.815385  0.808462\n",
            "6    rbf  0.1    0.1     7  0.830769   0.871237  0.830769  0.823265\n",
            "7    rbf  0.1    0.1     8  0.661538   0.686813  0.661538  0.638239\n",
            "8    rbf  0.1    0.1     9  0.692308   0.744755  0.692308  0.682952\n",
            "9    rbf  0.1    0.1    10  0.671875   0.672685  0.671875  0.672116\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "Média dos resultados do kernel rbf\n",
            "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
            "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "5    rbf  0.100  0.100      0.673341       0.708290    0.673341    0.635024\n",
            "6    rbf  0.100  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "7    rbf  0.100  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvbAxtIYXYdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "f189c09d-d364-4e47-f0a7-b9b837c1d9bd"
      },
      "source": [
        "# Exibe o resultado do kernel Linear\n",
        "print(ic_linear_all)\n",
        "result_linear_all = result_linear_all.rename(index={result_linear_all.index[0]:'All Features'})\n",
        "result_linear_all"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.625931      0.702986   0.625931   0.580070\n",
            "sup     0.769886      0.806120   0.769886   0.761227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.754553</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.670648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "All Features  linear  0.1      0.697909       0.754553    0.697909    0.670648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XBSlfCtXYdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "2d6b2f45-828f-4330-d688-f35eb496dfeb"
      },
      "source": [
        "# Exibe o resultado do kernel Polynomial\n",
        "print(ic_poly_all)\n",
        "result_poly_all = result_poly_all.rename(index={result_poly_all.index[0]:'All Features'})\n",
        "result_poly_all"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.634177      0.664784   0.634177   0.611885\n",
            "sup     0.786304      0.799185   0.786304   0.781393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.71024</td>\n",
              "      <td>0.731985</td>\n",
              "      <td>0.71024</td>\n",
              "      <td>0.696639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             kernel      c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "All Features   poly  0.001    1.0  ...       0.731985     0.71024    0.696639\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai5JE1lgXYdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "ca703b16-d866-4156-b769-c9666b45bcf7"
      },
      "source": [
        "# Exibe o resultado do Kernel RBF\n",
        "print(ic_rbf_all)\n",
        "result_rbf_all = result_rbf_all.rename(index={result_rbf_all.index[0]:'All Features'})\n",
        "result_rbf_all"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.604949      0.633665   0.604949   0.539650\n",
            "sup     0.741734      0.782914   0.741734   0.730398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.70829</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.635024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "All Features    rbf  0.1    0.1  ...        0.70829    0.673341    0.635024\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAvBSpgoXYdy",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. SVM: PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "USU96y9LXYdy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e00682f3-206e-4e0f-e40d-310a027ece47"
      },
      "source": [
        "\n",
        "df = pd.read_csv('results/dataset-pca.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "\n",
        "result_linear_pca, result_poly_pca, result_rbf_pca, ic_linear_pca, ic_poly_pca, ic_rbf_pca = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, list_coef, dataSet='PCA')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "   kernel      c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "   kernel    c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.1     1  0.584615   0.768474  0.584615  0.483424\n",
            "1  linear  0.1     2  0.646154   0.706682  0.646154  0.601935\n",
            "2  linear  0.1     3  0.769231   0.773077  0.769231  0.766434\n",
            "3  linear  0.1     4  0.569231   0.569920  0.569231  0.530981\n",
            "4  linear  0.1     5  0.707692   0.712932  0.707692  0.701676\n",
            "5  linear  0.1     6  0.830769   0.830681  0.830769  0.830527\n",
            "6  linear  0.1     7  0.876923   0.876923  0.876923  0.876923\n",
            "7  linear  0.1     8  0.738462   0.738064  0.738462  0.738087\n",
            "8  linear  0.1     9  0.600000   0.704142  0.600000  0.561992\n",
            "9  linear  0.1    10  0.671875   0.701584  0.671875  0.665632\n",
            "\n",
            "Média dos resultados do kernel linear\n",
            "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1  linear  0.100      0.699495       0.738248    0.699495    0.675761\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       5     4  0.553846   0.756010  0.553846  0.410507\n",
            "4   poly  0.001    0.5       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       5     6  0.569231   0.760684  0.569231  0.442308\n",
            "6   poly  0.001    0.5       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       5     8  0.553846   0.756010  0.553846  0.410507\n",
            "8   poly  0.001    0.5       5     9  0.507692   0.282051  0.507692  0.362637\n",
            "9   poly  0.001    0.5       5    10  0.546875   0.599898  0.546875  0.425897\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001      1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001      1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001      1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001      1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001      1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001      1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001      1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001      1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       3     1  0.538462   0.754808  0.538462  0.392759\n",
            "1   poly  0.001      1       3     2  0.584615   0.765509  0.584615  0.472497\n",
            "2   poly  0.001      1       3     3  0.630769   0.725034  0.630769  0.568034\n",
            "3   poly  0.001      1       3     4  0.569231   0.646280  0.569231  0.462858\n",
            "4   poly  0.001      1       3     5  0.600000   0.657895  0.600000  0.532037\n",
            "5   poly  0.001      1       3     6  0.707692   0.778107  0.707692  0.678469\n",
            "6   poly  0.001      1       3     7  0.800000   0.854167  0.800000  0.788003\n",
            "7   poly  0.001      1       3     8  0.630769   0.671263  0.630769  0.589411\n",
            "8   poly  0.001      1       3     9  0.676923   0.676319  0.676923  0.676460\n",
            "9   poly  0.001      1       3    10  0.656250   0.657813  0.656250  0.651089\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       4     1  0.523077   0.512454  0.523077  0.384812\n",
            "1   poly  0.001      1       4     2  0.584615   0.674359  0.584615  0.490920\n",
            "2   poly  0.001      1       4     3  0.630769   0.639935  0.630769  0.611632\n",
            "3   poly  0.001      1       4     4  0.584615   0.615385  0.584615  0.520710\n",
            "4   poly  0.001      1       4     5  0.553846   0.547263  0.553846  0.534062\n",
            "5   poly  0.001      1       4     6  0.676923   0.713846  0.676923  0.651584\n",
            "6   poly  0.001      1       4     7  0.707692   0.712932  0.707692  0.701676\n",
            "7   poly  0.001      1       4     8  0.600000   0.607143  0.600000  0.572464\n",
            "8   poly  0.001      1       4     9  0.630769   0.640584  0.630769  0.630245\n",
            "9   poly  0.001      1       4    10  0.687500   0.695076  0.687500  0.679909\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       5     1  0.492308   0.444973  0.492308  0.406762\n",
            "1   poly  0.001      1       5     2  0.584615   0.636036  0.584615  0.506874\n",
            "2   poly  0.001      1       5     3  0.661538   0.665311  0.661538  0.652860\n",
            "3   poly  0.001      1       5     4  0.600000   0.636364  0.600000  0.544444\n",
            "4   poly  0.001      1       5     5  0.600000   0.597561  0.600000  0.593567\n",
            "5   poly  0.001      1       5     6  0.692308   0.691565  0.692308  0.691276\n",
            "6   poly  0.001      1       5     7  0.769231   0.770034  0.769231  0.769450\n",
            "7   poly  0.001      1       5     8  0.523077   0.511266  0.523077  0.501928\n",
            "8   poly  0.001      1       5     9  0.630769   0.685971  0.630769  0.614935\n",
            "9   poly  0.001      1       5    10  0.656250   0.658203  0.656250  0.656586\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       1     1  0.538462   0.596361  0.538462  0.415724\n",
            "1   poly  0.1    0.1       1     2  0.630769   0.725034  0.630769  0.568034\n",
            "2   poly  0.1    0.1       1     3  0.707692   0.718781  0.707692  0.698551\n",
            "3   poly  0.1    0.1       1     4  0.538462   0.523617  0.538462  0.460042\n",
            "4   poly  0.1    0.1       1     5  0.615385   0.623963  0.615385  0.592314\n",
            "5   poly  0.1    0.1       1     6  0.846154   0.856473  0.846154  0.843680\n",
            "6   poly  0.1    0.1       1     7  0.907692   0.913215  0.907692  0.906890\n",
            "7   poly  0.1    0.1       1     8  0.784615   0.786982  0.784615  0.782744\n",
            "8   poly  0.1    0.1       1     9  0.676923   0.753592  0.676923  0.660773\n",
            "9   poly  0.1    0.1       1    10  0.656250   0.671938  0.656250  0.653554\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.5       1     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.5       1     3  0.769231   0.773077  0.769231  0.766434\n",
            "3   poly  0.1    0.5       1     4  0.615385   0.630769  0.615385  0.585219\n",
            "4   poly  0.1    0.5       1     5  0.676923   0.680045  0.676923  0.670273\n",
            "5   poly  0.1    0.5       1     6  0.830769   0.830681  0.830769  0.830527\n",
            "6   poly  0.1    0.5       1     7  0.876923   0.877784  0.876923  0.876510\n",
            "7   poly  0.1    0.5       1     8  0.784615   0.784675  0.784615  0.783893\n",
            "8   poly  0.1    0.5       1     9  0.646154   0.762443  0.646154  0.616199\n",
            "9   poly  0.1    0.5       1    10  0.609375   0.632523  0.609375  0.601943\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       2     1  0.507692   0.488008  0.507692  0.446420\n",
            "1   poly  0.1    0.5       2     2  0.676923   0.732249  0.676923  0.644624\n",
            "2   poly  0.1    0.5       2     3  0.569231   0.564807  0.569231  0.558185\n",
            "3   poly  0.1    0.5       2     4  0.600000   0.607143  0.600000  0.572464\n",
            "4   poly  0.1    0.5       2     5  0.492308   0.493505  0.492308  0.492790\n",
            "5   poly  0.1    0.5       2     6  0.707692   0.707191  0.707692  0.707274\n",
            "6   poly  0.1    0.5       2     7  0.676923   0.677857  0.676923  0.677230\n",
            "7   poly  0.1    0.5       2     8  0.600000   0.605313  0.600000  0.600379\n",
            "8   poly  0.1    0.5       2     9  0.615385   0.622711  0.615385  0.615385\n",
            "9   poly  0.1    0.5       2    10  0.609375   0.608713  0.609375  0.608895\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       3     1  0.476923   0.420513  0.476923  0.397009\n",
            "1   poly  0.1    0.5       3     2  0.553846   0.554487  0.553846  0.485207\n",
            "2   poly  0.1    0.5       3     3  0.676923   0.677308  0.676923  0.673007\n",
            "3   poly  0.1    0.5       3     4  0.600000   0.600000  0.600000  0.585000\n",
            "4   poly  0.1    0.5       3     5  0.584615   0.582321  0.584615  0.582220\n",
            "5   poly  0.1    0.5       3     6  0.738462   0.738064  0.738462  0.738087\n",
            "6   poly  0.1    0.5       3     7  0.676923   0.690748  0.676923  0.675852\n",
            "7   poly  0.1    0.5       3     8  0.569231   0.567419  0.569231  0.567787\n",
            "8   poly  0.1    0.5       3     9  0.646154   0.713857  0.646154  0.628466\n",
            "9   poly  0.1    0.5       3    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       4     1  0.446154   0.398225  0.446154  0.390828\n",
            "1   poly  0.1    0.5       4     2  0.615385   0.630769  0.615385  0.585219\n",
            "2   poly  0.1    0.5       4     3  0.553846   0.547702  0.553846  0.539893\n",
            "3   poly  0.1    0.5       4     4  0.553846   0.548817  0.553846  0.509243\n",
            "4   poly  0.1    0.5       4     5  0.538462   0.536383  0.538462  0.536914\n",
            "5   poly  0.1    0.5       4     6  0.615385   0.613585  0.615385  0.613166\n",
            "6   poly  0.1    0.5       4     7  0.615385   0.619100  0.615385  0.615931\n",
            "7   poly  0.1    0.5       4     8  0.461538   0.449833  0.461538  0.450455\n",
            "8   poly  0.1    0.5       4     9  0.646154   0.674015  0.646154  0.640579\n",
            "9   poly  0.1    0.5       4    10  0.578125   0.584206  0.578125  0.577610\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       5     1  0.507692   0.482845  0.507692  0.432479\n",
            "1   poly  0.1    0.5       5     2  0.615385   0.676282  0.615385  0.556213\n",
            "2   poly  0.1    0.5       5     3  0.630769   0.629925  0.630769  0.624831\n",
            "3   poly  0.1    0.5       5     4  0.646154   0.686391  0.646154  0.610779\n",
            "4   poly  0.1    0.5       5     5  0.600000   0.597561  0.600000  0.593567\n",
            "5   poly  0.1    0.5       5     6  0.692308   0.691565  0.692308  0.691276\n",
            "6   poly  0.1    0.5       5     7  0.753846   0.755973  0.753846  0.754196\n",
            "7   poly  0.1    0.5       5     8  0.523077   0.511266  0.523077  0.501928\n",
            "8   poly  0.1    0.5       5     9  0.646154   0.697436  0.646154  0.633287\n",
            "9   poly  0.1    0.5       5    10  0.640625   0.647629  0.640625  0.640186\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       1     1  0.584615   0.768474  0.584615  0.483424\n",
            "1   poly  0.1      1       1     2  0.646154   0.706682  0.646154  0.601935\n",
            "2   poly  0.1      1       1     3  0.769231   0.773077  0.769231  0.766434\n",
            "3   poly  0.1      1       1     4  0.569231   0.569920  0.569231  0.530981\n",
            "4   poly  0.1      1       1     5  0.707692   0.712932  0.707692  0.701676\n",
            "5   poly  0.1      1       1     6  0.830769   0.830681  0.830769  0.830527\n",
            "6   poly  0.1      1       1     7  0.876923   0.876923  0.876923  0.876923\n",
            "7   poly  0.1      1       1     8  0.738462   0.738064  0.738462  0.738087\n",
            "8   poly  0.1      1       1     9  0.600000   0.704142  0.600000  0.561992\n",
            "9   poly  0.1      1       1    10  0.671875   0.701584  0.671875  0.665632\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       2     1  0.476923   0.452308  0.476923  0.435770\n",
            "1   poly  0.1      1       2     2  0.676923   0.700698  0.676923  0.657543\n",
            "2   poly  0.1      1       2     3  0.569231   0.565197  0.569231  0.562303\n",
            "3   poly  0.1      1       2     4  0.661538   0.662289  0.661538  0.656095\n",
            "4   poly  0.1      1       2     5  0.584615   0.585681  0.584615  0.585010\n",
            "5   poly  0.1      1       2     6  0.707692   0.716117  0.707692  0.707692\n",
            "6   poly  0.1      1       2     7  0.738462   0.738064  0.738462  0.738087\n",
            "7   poly  0.1      1       2     8  0.630769   0.636257  0.630769  0.631119\n",
            "8   poly  0.1      1       2     9  0.630769   0.646124  0.630769  0.628667\n",
            "9   poly  0.1      1       2    10  0.593750   0.598407  0.593750  0.593750\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       3     1  0.538462   0.536821  0.538462  0.502150\n",
            "1   poly  0.1      1       3     2  0.661538   0.686813  0.661538  0.638239\n",
            "2   poly  0.1      1       3     3  0.676923   0.676319  0.676923  0.676460\n",
            "3   poly  0.1      1       3     4  0.538462   0.529915  0.538462  0.521154\n",
            "4   poly  0.1      1       3     5  0.600000   0.598456  0.600000  0.598659\n",
            "5   poly  0.1      1       3     6  0.630769   0.640584  0.630769  0.630245\n",
            "6   poly  0.1      1       3     7  0.646154   0.653846  0.646154  0.646154\n",
            "7   poly  0.1      1       3     8  0.584615   0.582321  0.584615  0.582220\n",
            "8   poly  0.1      1       3     9  0.584615   0.667421  0.584615  0.549451\n",
            "9   poly  0.1      1       3    10  0.578125   0.587869  0.578125  0.575957\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       4     1  0.446154   0.398225  0.446154  0.390828\n",
            "1   poly  0.1      1       4     2  0.615385   0.623963  0.615385  0.592314\n",
            "2   poly  0.1      1       4     3  0.553846   0.547702  0.553846  0.539893\n",
            "3   poly  0.1      1       4     4  0.584615   0.589231  0.584615  0.552036\n",
            "4   poly  0.1      1       4     5  0.507692   0.505346  0.507692  0.506042\n",
            "5   poly  0.1      1       4     6  0.615385   0.614574  0.615385  0.614834\n",
            "6   poly  0.1      1       4     7  0.646154   0.653846  0.646154  0.646154\n",
            "7   poly  0.1      1       4     8  0.461538   0.449833  0.461538  0.450455\n",
            "8   poly  0.1      1       4     9  0.600000   0.636364  0.600000  0.587838\n",
            "9   poly  0.1      1       4    10  0.609375   0.612628  0.609375  0.609661\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       5     1  0.507692   0.482845  0.507692  0.432479\n",
            "1   poly  0.1      1       5     2  0.630769   0.692308  0.630769  0.579487\n",
            "2   poly  0.1      1       5     3  0.630769   0.629925  0.630769  0.624831\n",
            "3   poly  0.1      1       5     4  0.615385   0.640533  0.615385  0.576933\n",
            "4   poly  0.1      1       5     5  0.600000   0.597561  0.600000  0.593567\n",
            "5   poly  0.1      1       5     6  0.692308   0.691565  0.692308  0.691276\n",
            "6   poly  0.1      1       5     7  0.707692   0.711538  0.707692  0.708108\n",
            "7   poly  0.1      1       5     8  0.523077   0.511266  0.523077  0.501928\n",
            "8   poly  0.1      1       5     9  0.600000   0.647597  0.600000  0.582846\n",
            "9   poly  0.1      1       5    10  0.640625   0.647629  0.640625  0.640186\n",
            "\n",
            "Média dos resultados do kernel poly\n",
            "   kernel      c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
            "0    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "1    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "2    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "3    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "4    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "5    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "6    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "7    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "8    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "9    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "10   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "11   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "12   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "13   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "14   poly  0.001  0.500  ...       0.458802    0.540841    0.391883\n",
            "15   poly  0.001  1.000  ...       0.287536    0.536202    0.374329\n",
            "16   poly  0.001  1.000  ...       0.287536    0.536202    0.374329\n",
            "17   poly  0.001  1.000  ...       0.718719    0.639471    0.581162\n",
            "18   poly  0.001  1.000  ...       0.635898    0.617981    0.577801\n",
            "19   poly  0.001  1.000  ...       0.629728    0.621010    0.593868\n",
            "20   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "21   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "22   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "23   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "24   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "25   poly  0.100  0.100  ...       0.716996    0.690240    0.658231\n",
            "26   poly  0.100  0.100  ...       0.287536    0.536202    0.374329\n",
            "27   poly  0.100  0.100  ...       0.287536    0.536202    0.374329\n",
            "28   poly  0.100  0.100  ...       0.287536    0.536202    0.374329\n",
            "29   poly  0.100  0.100  ...       0.287536    0.536202    0.374329\n",
            "30   poly  0.100  0.500  ...       0.734984    0.700937    0.676787\n",
            "31   poly  0.100  0.500  ...       0.610750    0.605553    0.592365\n",
            "32   poly  0.100  0.500  ...       0.620611    0.617933    0.598888\n",
            "33   poly  0.100  0.500  ...       0.560263    0.562428    0.545984\n",
            "34   poly  0.100  0.500  ...       0.637687    0.625601    0.603874\n",
            "35   poly  0.100  1.000  ...       0.738248    0.699495    0.675761\n",
            "36   poly  0.100  1.000  ...       0.630114    0.627067    0.619604\n",
            "37   poly  0.100  1.000  ...       0.616036    0.603966    0.592069\n",
            "38   poly  0.100  1.000  ...       0.563171    0.564014    0.549005\n",
            "39   poly  0.100  1.000  ...       0.625277    0.614832    0.593164\n",
            "\n",
            "[40 rows x 8 columns]\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.1     1  0.523077   0.512454  0.523077  0.384812\n",
            "1    rbf  0.1    0.1     2  0.661538   0.748252  0.661538  0.614530\n",
            "2    rbf  0.1    0.1     3  0.692308   0.705128  0.692308  0.680769\n",
            "3    rbf  0.1    0.1     4  0.553846   0.550894  0.553846  0.498092\n",
            "4    rbf  0.1    0.1     5  0.600000   0.600000  0.600000  0.585000\n",
            "5    rbf  0.1    0.1     6  0.830769   0.844482  0.830769  0.827286\n",
            "6    rbf  0.1    0.1     7  0.892308   0.910256  0.892308  0.890091\n",
            "7    rbf  0.1    0.1     8  0.738462   0.745819  0.738462  0.733078\n",
            "8    rbf  0.1    0.1     9  0.676923   0.734615  0.676923  0.665175\n",
            "9    rbf  0.1    0.1    10  0.671875   0.684904  0.671875  0.670189\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "Média dos resultados do kernel rbf\n",
            "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
            "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "5    rbf  0.100  0.100      0.684111       0.703680    0.684111    0.654902\n",
            "6    rbf  0.100  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "7    rbf  0.100  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8XhR4AKXYd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "5326e94e-954c-47ad-9224-c1d82018993d"
      },
      "source": [
        "# Exibe o resultado do kernel Linear\n",
        "print(ic_linear_pca)\n",
        "result_linear_pca = result_linear_pca.rename(index={result_linear_pca.index[0]:'PCA'})\n",
        "result_linear_pca"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf      0.62453      0.678692    0.62453   0.582293\n",
            "sup      0.77446      0.797804    0.77446   0.769229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.738248</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.675761</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "PCA  linear  0.1      0.699495       0.738248    0.699495    0.675761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q--RHDuYXYd-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "95127964-976e-4be0-c42f-8f932a937223"
      },
      "source": [
        "# Exibe o resultado do kernel poly\n",
        "print(ic_poly_pca)\n",
        "result_poly_pca = result_poly_pca.rename(index={result_poly_pca.index[0]:'PCA'})\n",
        "result_poly_pca"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.624257      0.673032   0.624257   0.580924\n",
            "sup     0.777618      0.796937   0.777618   0.772650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.734984</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.676787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "PCA   poly  0.1    0.5  ...       0.734984    0.700937    0.676787\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8YRx2dOXYeC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "dec41ef9-4ac5-4dff-c047-4a17f263507c"
      },
      "source": [
        "# Exibe o resultado do kernel rbf\n",
        "print(ic_rbf_pca)\n",
        "result_rbf_pca = result_rbf_pca.rename(index={result_rbf_pca.index[0]:'PCA'})\n",
        "result_rbf_pca"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.602005      0.615024   0.602005   0.549280\n",
            "sup     0.766217      0.792336   0.766217   0.760524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.70368</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.654902</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    kernel    c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "PCA    rbf  0.1    0.1      0.684111        0.70368    0.684111    0.654902"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ10y9FEXYeI",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. SVM: Chi Squared (k-Best)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNe5wTvZXYeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da1e62c9-2770-45fb-f6fb-c6ac63003a8c"
      },
      "source": [
        "df = pd.read_csv('results/dataset-fs-chi-squared.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "\n",
        "result_linear_chi, result_poly_chi, result_rbf_chi, ic_linear_chi, ic_poly_chi, ic_rbf_chi = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, list_coef, dataSet='chi')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "   kernel      c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "   kernel    c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  linear  0.1     2  0.646154   0.706682  0.646154  0.601935\n",
            "2  linear  0.1     3  0.815385   0.824109  0.815385  0.812416\n",
            "3  linear  0.1     4  0.646154   0.686391  0.646154  0.610779\n",
            "4  linear  0.1     5  0.723077   0.740171  0.723077  0.712692\n",
            "5  linear  0.1     6  0.830769   0.844482  0.830769  0.827286\n",
            "6  linear  0.1     7  0.938462   0.939857  0.938462  0.938255\n",
            "7  linear  0.1     8  0.630769   0.629925  0.630769  0.624831\n",
            "8  linear  0.1     9  0.569231   0.717643  0.569231  0.507074\n",
            "9  linear  0.1    10  0.656250   0.717844  0.656250  0.639550\n",
            "\n",
            "Média dos resultados do kernel linear\n",
            "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1  linear  0.100      0.701010       0.744777    0.701010    0.671998\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       3     3  0.553846   0.756010  0.553846  0.410507\n",
            "3   poly  0.001    0.5       3     4  0.553846   0.756010  0.553846  0.410507\n",
            "4   poly  0.001    0.5       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       3     6  0.615385   0.775641  0.615385  0.528629\n",
            "6   poly  0.001    0.5       3     7  0.584615   0.765509  0.584615  0.472497\n",
            "7   poly  0.001    0.5       3     8  0.584615   0.765509  0.584615  0.472497\n",
            "8   poly  0.001    0.5       3     9  0.600000   0.622642  0.600000  0.555195\n",
            "9   poly  0.001    0.5       3    10  0.578125   0.633067  0.578125  0.500316\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       4     2  0.538462   0.521368  0.538462  0.402473\n",
            "2   poly  0.001    0.5       4     3  0.600000   0.770492  0.600000  0.501225\n",
            "3   poly  0.001    0.5       4     4  0.538462   0.521368  0.538462  0.402473\n",
            "4   poly  0.001    0.5       4     5  0.553846   0.602978  0.553846  0.433422\n",
            "5   poly  0.001    0.5       4     6  0.676923   0.798077  0.676923  0.627219\n",
            "6   poly  0.001    0.5       4     7  0.692308   0.804196  0.692308  0.649573\n",
            "7   poly  0.001    0.5       4     8  0.615385   0.676282  0.615385  0.556213\n",
            "8   poly  0.001    0.5       4     9  0.646154   0.647157  0.646154  0.638871\n",
            "9   poly  0.001    0.5       4    10  0.640625   0.658675  0.640625  0.619763\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       5     2  0.569231   0.646280  0.569231  0.462858\n",
            "2   poly  0.001    0.5       5     3  0.600000   0.770492  0.600000  0.501225\n",
            "3   poly  0.001    0.5       5     4  0.538462   0.521368  0.538462  0.402473\n",
            "4   poly  0.001    0.5       5     5  0.538462   0.522068  0.538462  0.424491\n",
            "5   poly  0.001    0.5       5     6  0.723077   0.817126  0.723077  0.692058\n",
            "6   poly  0.001    0.5       5     7  0.753846   0.831071  0.753846  0.731989\n",
            "7   poly  0.001    0.5       5     8  0.646154   0.706682  0.646154  0.601935\n",
            "8   poly  0.001    0.5       5     9  0.661538   0.660529  0.661538  0.660404\n",
            "9   poly  0.001    0.5       5    10  0.703125   0.709272  0.703125  0.697374\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       2     2  0.553846   0.602978  0.553846  0.433422\n",
            "2   poly  0.001      1       2     3  0.600000   0.694915  0.600000  0.517730\n",
            "3   poly  0.001      1       2     4  0.538462   0.521368  0.538462  0.402473\n",
            "4   poly  0.001      1       2     5  0.553846   0.560818  0.553846  0.470346\n",
            "5   poly  0.001      1       2     6  0.723077   0.817126  0.723077  0.692058\n",
            "6   poly  0.001      1       2     7  0.738462   0.823964  0.738462  0.712315\n",
            "7   poly  0.001      1       2     8  0.630769   0.692308  0.630769  0.579487\n",
            "8   poly  0.001      1       2     9  0.753846   0.753638  0.753846  0.753021\n",
            "9   poly  0.001      1       2    10  0.671875   0.671453  0.671875  0.670172\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       3     1  0.538462   0.754808  0.538462  0.392759\n",
            "1   poly  0.001      1       3     2  0.584615   0.674359  0.584615  0.490920\n",
            "2   poly  0.001      1       3     3  0.646154   0.686391  0.646154  0.610779\n",
            "3   poly  0.001      1       3     4  0.569231   0.646280  0.569231  0.462858\n",
            "4   poly  0.001      1       3     5  0.569231   0.608866  0.569231  0.480633\n",
            "5   poly  0.001      1       3     6  0.800000   0.854167  0.800000  0.788003\n",
            "6   poly  0.001      1       3     7  0.846154   0.880342  0.846154  0.840385\n",
            "7   poly  0.001      1       3     8  0.630769   0.635043  0.630769  0.616923\n",
            "8   poly  0.001      1       3     9  0.707692   0.754838  0.707692  0.700386\n",
            "9   poly  0.001      1       3    10  0.703125   0.706653  0.703125  0.703342\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       4     1  0.523077   0.512454  0.523077  0.384812\n",
            "1   poly  0.001      1       4     2  0.600000   0.694915  0.600000  0.517730\n",
            "2   poly  0.001      1       4     3  0.753846   0.806319  0.753846  0.736901\n",
            "3   poly  0.001      1       4     4  0.553846   0.573077  0.553846  0.453210\n",
            "4   poly  0.001      1       4     5  0.584615   0.615385  0.584615  0.520710\n",
            "5   poly  0.001      1       4     6  0.769231   0.787213  0.769231  0.762014\n",
            "6   poly  0.001      1       4     7  0.846154   0.856473  0.846154  0.843680\n",
            "7   poly  0.001      1       4     8  0.630769   0.639935  0.630769  0.611632\n",
            "8   poly  0.001      1       4     9  0.661538   0.708625  0.661538  0.651247\n",
            "9   poly  0.001      1       4    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       5     1  0.553846   0.601651  0.553846  0.463085\n",
            "1   poly  0.001      1       5     2  0.646154   0.706682  0.646154  0.601935\n",
            "2   poly  0.001      1       5     3  0.723077   0.727017  0.723077  0.718623\n",
            "3   poly  0.001      1       5     4  0.553846   0.573077  0.553846  0.453210\n",
            "4   poly  0.001      1       5     5  0.507692   0.487637  0.507692  0.473802\n",
            "5   poly  0.001      1       5     6  0.738462   0.741154  0.738462  0.735291\n",
            "6   poly  0.001      1       5     7  0.800000   0.801170  0.800000  0.798846\n",
            "7   poly  0.001      1       5     8  0.615385   0.613585  0.615385  0.613166\n",
            "8   poly  0.001      1       5     9  0.676923   0.734615  0.676923  0.665175\n",
            "9   poly  0.001      1       5    10  0.671875   0.675312  0.671875  0.672115\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.1       1     2  0.630769   0.725034  0.630769  0.568034\n",
            "2   poly  0.1    0.1       1     3  0.738462   0.777432  0.738462  0.722773\n",
            "3   poly  0.1    0.1       1     4  0.600000   0.657895  0.600000  0.532037\n",
            "4   poly  0.1    0.1       1     5  0.615385   0.619257  0.615385  0.598329\n",
            "5   poly  0.1    0.1       1     6  0.815385   0.845299  0.815385  0.808462\n",
            "6   poly  0.1    0.1       1     7  0.892308   0.910256  0.892308  0.890091\n",
            "7   poly  0.1    0.1       1     8  0.738462   0.738641  0.738462  0.736953\n",
            "8   poly  0.1    0.1       1     9  0.676923   0.753592  0.676923  0.660773\n",
            "9   poly  0.1    0.1       1    10  0.687500   0.692892  0.687500  0.687500\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       2     2  0.553846   0.602978  0.553846  0.433422\n",
            "2   poly  0.1    0.1       2     3  0.600000   0.694915  0.600000  0.517730\n",
            "3   poly  0.1    0.1       2     4  0.538462   0.521368  0.538462  0.402473\n",
            "4   poly  0.1    0.1       2     5  0.553846   0.560818  0.553846  0.470346\n",
            "5   poly  0.1    0.1       2     6  0.723077   0.817126  0.723077  0.692058\n",
            "6   poly  0.1    0.1       2     7  0.738462   0.823964  0.738462  0.712315\n",
            "7   poly  0.1    0.1       2     8  0.630769   0.692308  0.630769  0.579487\n",
            "8   poly  0.1    0.1       2     9  0.753846   0.753638  0.753846  0.753021\n",
            "9   poly  0.1    0.1       2    10  0.671875   0.671453  0.671875  0.670172\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       3     3  0.553846   0.756010  0.553846  0.410507\n",
            "3   poly  0.1    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       3     6  0.600000   0.770492  0.600000  0.501225\n",
            "6   poly  0.1    0.1       3     7  0.553846   0.756010  0.553846  0.410507\n",
            "7   poly  0.1    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       3     9  0.553846   0.573077  0.553846  0.453210\n",
            "9   poly  0.1    0.1       3    10  0.546875   0.599898  0.546875  0.425897\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       4     9  0.553846   0.756010  0.553846  0.410507\n",
            "9   poly  0.1    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.5       1     2  0.630769   0.725034  0.630769  0.568034\n",
            "2   poly  0.1    0.5       1     3  0.800000   0.811594  0.800000  0.795883\n",
            "3   poly  0.1    0.5       1     4  0.630769   0.671263  0.630769  0.589411\n",
            "4   poly  0.1    0.5       1     5  0.723077   0.740171  0.723077  0.712692\n",
            "5   poly  0.1    0.5       1     6  0.846154   0.856473  0.846154  0.843680\n",
            "6   poly  0.1    0.5       1     7  0.907692   0.913215  0.907692  0.906890\n",
            "7   poly  0.1    0.5       1     8  0.676923   0.676113  0.676923  0.675060\n",
            "8   poly  0.1    0.5       1     9  0.584615   0.727972  0.584615  0.530317\n",
            "9   poly  0.1    0.5       1    10  0.625000   0.678140  0.625000  0.606781\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       2     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.1    0.5       2     2  0.630769   0.725034  0.630769  0.568034\n",
            "2   poly  0.1    0.5       2     3  0.753846   0.775214  0.753846  0.744615\n",
            "3   poly  0.1    0.5       2     4  0.615385   0.676282  0.615385  0.556213\n",
            "4   poly  0.1    0.5       2     5  0.676923   0.700698  0.676923  0.657543\n",
            "5   poly  0.1    0.5       2     6  0.861538   0.877369  0.861538  0.858688\n",
            "6   poly  0.1    0.5       2     7  0.892308   0.900769  0.892308  0.891002\n",
            "7   poly  0.1    0.5       2     8  0.661538   0.662289  0.661538  0.656095\n",
            "8   poly  0.1    0.5       2     9  0.569231   0.717643  0.569231  0.507074\n",
            "9   poly  0.1    0.5       2    10  0.656250   0.671938  0.656250  0.653554\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       3     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.5       3     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.5       3     3  0.769231   0.778707  0.769231  0.764481\n",
            "3   poly  0.1    0.5       3     4  0.600000   0.657895  0.600000  0.532037\n",
            "4   poly  0.1    0.5       3     5  0.584615   0.585596  0.584615  0.559699\n",
            "5   poly  0.1    0.5       3     6  0.800000   0.805000  0.800000  0.797576\n",
            "6   poly  0.1    0.5       3     7  0.846154   0.846748  0.846154  0.845638\n",
            "7   poly  0.1    0.5       3     8  0.615385   0.614270  0.615385  0.607468\n",
            "8   poly  0.1    0.5       3     9  0.661538   0.770256  0.661538  0.636154\n",
            "9   poly  0.1    0.5       3    10  0.671875   0.675312  0.671875  0.672115\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       4     1  0.553846   0.601651  0.553846  0.463085\n",
            "1   poly  0.1    0.5       4     2  0.661538   0.748252  0.661538  0.614530\n",
            "2   poly  0.1    0.5       4     3  0.738462   0.738064  0.738462  0.738087\n",
            "3   poly  0.1    0.5       4     4  0.569231   0.590756  0.569231  0.496039\n",
            "4   poly  0.1    0.5       4     5  0.569231   0.565739  0.569231  0.546904\n",
            "5   poly  0.1    0.5       4     6  0.707692   0.709231  0.707692  0.704149\n",
            "6   poly  0.1    0.5       4     7  0.846154   0.846748  0.846154  0.845638\n",
            "7   poly  0.1    0.5       4     8  0.661538   0.661538  0.661538  0.661538\n",
            "8   poly  0.1    0.5       4     9  0.707692   0.754838  0.707692  0.700386\n",
            "9   poly  0.1    0.5       4    10  0.687500   0.692892  0.687500  0.687500\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       5     1  0.569231   0.594095  0.569231  0.515618\n",
            "1   poly  0.1    0.5       5     2  0.661538   0.719884  0.661538  0.623626\n",
            "2   poly  0.1    0.5       5     3  0.738462   0.738064  0.738462  0.738087\n",
            "3   poly  0.1    0.5       5     4  0.584615   0.602823  0.584615  0.532707\n",
            "4   poly  0.1    0.5       5     5  0.492308   0.479271  0.492308  0.476430\n",
            "5   poly  0.1    0.5       5     6  0.707692   0.709231  0.707692  0.704149\n",
            "6   poly  0.1    0.5       5     7  0.784615   0.791745  0.784615  0.781152\n",
            "7   poly  0.1    0.5       5     8  0.661538   0.660750  0.661538  0.658598\n",
            "8   poly  0.1    0.5       5     9  0.646154   0.684420  0.646154  0.637310\n",
            "9   poly  0.1    0.5       5    10  0.656250   0.658203  0.656250  0.656586\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1      1       1     2  0.646154   0.706682  0.646154  0.601935\n",
            "2   poly  0.1      1       1     3  0.815385   0.824109  0.815385  0.812416\n",
            "3   poly  0.1      1       1     4  0.646154   0.686391  0.646154  0.610779\n",
            "4   poly  0.1      1       1     5  0.723077   0.740171  0.723077  0.712692\n",
            "5   poly  0.1      1       1     6  0.830769   0.844482  0.830769  0.827286\n",
            "6   poly  0.1      1       1     7  0.938462   0.939857  0.938462  0.938255\n",
            "7   poly  0.1      1       1     8  0.630769   0.629925  0.630769  0.624831\n",
            "8   poly  0.1      1       1     9  0.569231   0.717643  0.569231  0.507074\n",
            "9   poly  0.1      1       1    10  0.656250   0.717844  0.656250  0.639550\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       2     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1      1       2     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1      1       2     3  0.800000   0.821429  0.800000  0.793745\n",
            "3   poly  0.1      1       2     4  0.646154   0.706682  0.646154  0.601935\n",
            "4   poly  0.1      1       2     5  0.692308   0.698813  0.692308  0.684418\n",
            "5   poly  0.1      1       2     6  0.830769   0.844482  0.830769  0.827286\n",
            "6   poly  0.1      1       2     7  0.923077   0.923298  0.923077  0.922967\n",
            "7   poly  0.1      1       2     8  0.676923   0.684565  0.676923  0.666819\n",
            "8   poly  0.1      1       2     9  0.646154   0.762443  0.646154  0.616199\n",
            "9   poly  0.1      1       2    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       3     1  0.538462   0.545177  0.538462  0.467949\n",
            "1   poly  0.1      1       3     2  0.676923   0.732249  0.676923  0.644624\n",
            "2   poly  0.1      1       3     3  0.738462   0.742351  0.738462  0.738833\n",
            "3   poly  0.1      1       3     4  0.600000   0.613445  0.600000  0.564482\n",
            "4   poly  0.1      1       3     5  0.630769   0.629191  0.630769  0.627562\n",
            "5   poly  0.1      1       3     6  0.676923   0.677308  0.676923  0.673007\n",
            "6   poly  0.1      1       3     7  0.861538   0.861553  0.861538  0.861340\n",
            "7   poly  0.1      1       3     8  0.661538   0.661538  0.661538  0.661538\n",
            "8   poly  0.1      1       3     9  0.692308   0.744755  0.692308  0.682952\n",
            "9   poly  0.1      1       3    10  0.671875   0.675312  0.671875  0.672115\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       4     1  0.615385   0.629569  0.615385  0.595228\n",
            "1   poly  0.1      1       4     2  0.646154   0.662330  0.646154  0.624929\n",
            "2   poly  0.1      1       4     3  0.753846   0.766136  0.753846  0.753497\n",
            "3   poly  0.1      1       4     4  0.584615   0.585596  0.584615  0.559699\n",
            "4   poly  0.1      1       4     5  0.661538   0.663753  0.661538  0.662020\n",
            "5   poly  0.1      1       4     6  0.661538   0.660750  0.661538  0.658598\n",
            "6   poly  0.1      1       4     7  0.723077   0.723077  0.723077  0.723077\n",
            "7   poly  0.1      1       4     8  0.523077   0.524230  0.523077  0.523530\n",
            "8   poly  0.1      1       4     9  0.676923   0.734615  0.676923  0.665175\n",
            "9   poly  0.1      1       4    10  0.750000   0.752024  0.750000  0.748016\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       5     1  0.600000   0.613725  0.600000  0.575813\n",
            "1   poly  0.1      1       5     2  0.615385   0.616134  0.615385  0.603356\n",
            "2   poly  0.1      1       5     3  0.661538   0.667202  0.661538  0.661859\n",
            "3   poly  0.1      1       5     4  0.569231   0.564957  0.569231  0.553077\n",
            "4   poly  0.1      1       5     5  0.692308   0.694493  0.692308  0.692746\n",
            "5   poly  0.1      1       5     6  0.630769   0.630769  0.630769  0.630769\n",
            "6   poly  0.1      1       5     7  0.769231   0.773164  0.769231  0.769559\n",
            "7   poly  0.1      1       5     8  0.492308   0.493505  0.492308  0.492790\n",
            "8   poly  0.1      1       5     9  0.707692   0.754838  0.707692  0.700386\n",
            "9   poly  0.1      1       5    10  0.703125   0.705288  0.703125  0.699798\n",
            "\n",
            "Média dos resultados do kernel poly\n",
            "   kernel      c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
            "0    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "1    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "2    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "3    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "4    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "5    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "6    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "7    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "8    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "9    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "10   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "11   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "12   poly  0.001  0.500  ...       0.592788    0.567043    0.446328\n",
            "13   poly  0.001  0.500  ...       0.627420    0.602524    0.519052\n",
            "14   poly  0.001  0.500  ...       0.645850    0.625697    0.553409\n",
            "15   poly  0.001  1.000  ...       0.287536    0.536202    0.374329\n",
            "16   poly  0.001  1.000  ...       0.641218    0.628726    0.559031\n",
            "17   poly  0.001  1.000  ...       0.720175    0.659543    0.608699\n",
            "18   poly  0.001  1.000  ...       0.685579    0.657933    0.613819\n",
            "19   poly  0.001  1.000  ...       0.666190    0.648726    0.619525\n",
            "20   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "21   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "22   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "23   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "24   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "25   poly  0.100  0.100  ...       0.736097    0.694904    0.665011\n",
            "26   poly  0.100  0.100  ...       0.641218    0.628726    0.559031\n",
            "27   poly  0.100  0.100  ...       0.488886    0.548534    0.406832\n",
            "28   poly  0.100  0.100  ...       0.334143    0.537740    0.377688\n",
            "29   poly  0.100  0.100  ...       0.287536    0.536202    0.374329\n",
            "30   poly  0.100  0.500  ...       0.744064    0.697885    0.667391\n",
            "31   poly  0.100  0.500  ...       0.746645    0.687163    0.651732\n",
            "32   poly  0.100  0.500  ...       0.711163    0.674880    0.645204\n",
            "33   poly  0.100  0.500  ...       0.690971    0.670288    0.645786\n",
            "34   poly  0.100  0.500  ...       0.663848    0.650240    0.632426\n",
            "35   poly  0.100  1.000  ...       0.744777    0.701010    0.671998\n",
            "36   poly  0.100  1.000  ...       0.749890    0.708726    0.682172\n",
            "37   poly  0.100  1.000  ...       0.688288    0.674880    0.659440\n",
            "38   poly  0.100  1.000  ...       0.670208    0.659615    0.651377\n",
            "39   poly  0.100  1.000  ...       0.651408    0.644159    0.638015\n",
            "\n",
            "[40 rows x 8 columns]\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1    rbf  0.1    0.1     2  0.630769   0.725034  0.630769  0.568034\n",
            "2    rbf  0.1    0.1     3  0.723077   0.740171  0.723077  0.712692\n",
            "3    rbf  0.1    0.1     4  0.646154   0.706682  0.646154  0.601935\n",
            "4    rbf  0.1    0.1     5  0.646154   0.650350  0.646154  0.635088\n",
            "5    rbf  0.1    0.1     6  0.876923   0.888837  0.876923  0.874944\n",
            "6    rbf  0.1    0.1     7  0.969231   0.970894  0.969231  0.969128\n",
            "7    rbf  0.1    0.1     8  0.784615   0.784615  0.784615  0.784615\n",
            "8    rbf  0.1    0.1     9  0.615385   0.746130  0.615385  0.574567\n",
            "9    rbf  0.1    0.1    10  0.671875   0.701584  0.671875  0.665632\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.5     1  0.553846   0.640668  0.553846  0.445159\n",
            "1    rbf  0.1    0.5     2  0.661538   0.748252  0.661538  0.614530\n",
            "2    rbf  0.1    0.5     3  0.738462   0.741154  0.738462  0.735291\n",
            "3    rbf  0.1    0.5     4  0.661538   0.686813  0.661538  0.638239\n",
            "4    rbf  0.1    0.5     5  0.676923   0.680045  0.676923  0.670273\n",
            "5    rbf  0.1    0.5     6  0.907692   0.913215  0.907692  0.906890\n",
            "6    rbf  0.1    0.5     7  0.938462   0.939857  0.938462  0.938255\n",
            "7    rbf  0.1    0.5     8  0.753846   0.755973  0.753846  0.754196\n",
            "8    rbf  0.1    0.5     9  0.569231   0.717643  0.569231  0.507074\n",
            "9    rbf  0.1    0.5    10  0.656250   0.717844  0.656250  0.639550\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "Média dos resultados do kernel rbf\n",
            "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
            "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "5    rbf  0.100  0.100      0.711803       0.755496    0.711803    0.683179\n",
            "6    rbf  0.100  0.500      0.711779       0.754147    0.711779    0.684946\n",
            "7    rbf  0.100  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVq5Bhv5XYeN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "a749cdeb-6f1a-487c-adc2-4bb1922e86ee"
      },
      "source": [
        "# Exibe o resultado do kernel Linear\n",
        "print(ic_linear_chi)\n",
        "result_linear_chi = result_linear_chi.rename(index={result_linear_chi.index[0]:'Chi Square'})\n",
        "result_linear_chi"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.612182      0.675395   0.612182   0.563516\n",
            "sup     0.789837      0.814160   0.789837   0.780479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Chi Square</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.70101</td>\n",
              "      <td>0.744777</td>\n",
              "      <td>0.70101</td>\n",
              "      <td>0.671998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "Chi Square  linear  0.1       0.70101       0.744777     0.70101    0.671998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA_ju72JXYeT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "2e03281e-ff94-492a-85c3-0f354ea8ee1f"
      },
      "source": [
        "# Exibe o resultado do kernel Poly\n",
        "print(ic_poly_chi)\n",
        "result_poly_chi = result_poly_chi.rename(index={result_poly_chi.index[0]:'Chi Square'})\n",
        "result_poly_chi"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.630528      0.686755   0.630528   0.584729\n",
            "sup     0.786924      0.813026   0.786924   0.779615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Chi Square</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.74989</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.682172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "Chi Square   poly  0.1    1.0  ...        0.74989    0.708726    0.682172\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdnq2CDJXYea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "cd5608e8-212f-4244-a44c-9fe41d1c8f72"
      },
      "source": [
        "# Exibe o resultado do kernel RBF\n",
        "print(ic_rbf_chi)\n",
        "result_rbf_chi = result_rbf_chi.rename(index={result_rbf_chi.index[0]:'Chi Square'})\n",
        "result_rbf_chi"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.619454      0.681690   0.619454   0.571175\n",
            "sup     0.804152      0.829303   0.804152   0.795184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Chi Square</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.755496</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.683179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "Chi Square    rbf  0.1    0.1  ...       0.755496    0.711803    0.683179\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Qa8UIHXYef",
        "colab_type": "text"
      },
      "source": [
        "### 2.4. SVM: Recursive Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWM879b8XYef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cae6ea79-6631-4025-ef3d-0fe810e05678"
      },
      "source": [
        "df = pd.read_csv('results/dataset-fs-recursive-feature.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "\n",
        "result_linear_rf, result_poly_rf, result_rbf_rf, ic_linear_rf, ic_poly_rf, ic_rbf_rf = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, \n",
        "                                                                 list_coef, dataSet='recursive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "   kernel      c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "   kernel    c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  linear  0.1     2  0.676923   0.758612  0.676923  0.636550\n",
            "2  linear  0.1     3  0.769231   0.799243  0.769231  0.758998\n",
            "3  linear  0.1     4  0.661538   0.700496  0.661538  0.631485\n",
            "4  linear  0.1     5  0.784615   0.810256  0.784615  0.776538\n",
            "5  linear  0.1     6  0.876923   0.881657  0.876923  0.875854\n",
            "6  linear  0.1     7  0.938462   0.939857  0.938462  0.938255\n",
            "7  linear  0.1     8  0.738462   0.741154  0.738462  0.735291\n",
            "8  linear  0.1     9  0.569231   0.777188  0.569231  0.494172\n",
            "9  linear  0.1    10  0.625000   0.654221  0.625000  0.616071\n",
            "\n",
            "Média dos resultados do kernel linear\n",
            "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1  linear  0.100      0.719423       0.770335    0.719423    0.690837\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       3     3  0.615385   0.775641  0.615385  0.528629\n",
            "3   poly  0.001    0.5       3     4  0.569231   0.760684  0.569231  0.442308\n",
            "4   poly  0.001    0.5       3     5  0.584615   0.765509  0.584615  0.472497\n",
            "5   poly  0.001    0.5       3     6  0.630769   0.780965  0.630769  0.554828\n",
            "6   poly  0.001    0.5       3     7  0.630769   0.780965  0.630769  0.554828\n",
            "7   poly  0.001    0.5       3     8  0.676923   0.798077  0.676923  0.627219\n",
            "8   poly  0.001    0.5       3     9  0.769231   0.773077  0.769231  0.766434\n",
            "9   poly  0.001    0.5       3    10  0.718750   0.748641  0.718750  0.704688\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       4     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.001    0.5       4     2  0.584615   0.674359  0.584615  0.490920\n",
            "2   poly  0.001    0.5       4     3  0.661538   0.792173  0.661538  0.604031\n",
            "3   poly  0.001    0.5       4     4  0.569231   0.646280  0.569231  0.462858\n",
            "4   poly  0.001    0.5       4     5  0.615385   0.711254  0.615385  0.543402\n",
            "5   poly  0.001    0.5       4     6  0.723077   0.787546  0.723077  0.698488\n",
            "6   poly  0.001    0.5       4     7  0.784615   0.846154  0.784615  0.769788\n",
            "7   poly  0.001    0.5       4     8  0.738462   0.777432  0.738462  0.722773\n",
            "8   poly  0.001    0.5       4     9  0.738462   0.763314  0.738462  0.736225\n",
            "9   poly  0.001    0.5       4    10  0.640625   0.639733  0.640625  0.638760\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       5     1  0.569231   0.763772  0.569231  0.454676\n",
            "1   poly  0.001    0.5       5     2  0.630769   0.725034  0.630769  0.568034\n",
            "2   poly  0.001    0.5       5     3  0.692308   0.804196  0.692308  0.649573\n",
            "3   poly  0.001    0.5       5     4  0.569231   0.646280  0.569231  0.462858\n",
            "4   poly  0.001    0.5       5     5  0.630769   0.692308  0.630769  0.579487\n",
            "5   poly  0.001    0.5       5     6  0.769231   0.838462  0.769231  0.751131\n",
            "6   poly  0.001    0.5       5     7  0.784615   0.825423  0.784615  0.773452\n",
            "7   poly  0.001    0.5       5     8  0.723077   0.766484  0.723077  0.704013\n",
            "8   poly  0.001    0.5       5     9  0.723077   0.752308  0.723077  0.719780\n",
            "9   poly  0.001    0.5       5    10  0.640625   0.640055  0.640625  0.640184\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       2     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.001      1       2     2  0.569231   0.760684  0.569231  0.442308\n",
            "2   poly  0.001      1       2     3  0.630769   0.780965  0.630769  0.554828\n",
            "3   poly  0.001      1       2     4  0.569231   0.760684  0.569231  0.442308\n",
            "4   poly  0.001      1       2     5  0.600000   0.770492  0.600000  0.501225\n",
            "5   poly  0.001      1       2     6  0.723077   0.817126  0.723077  0.692058\n",
            "6   poly  0.001      1       2     7  0.753846   0.831071  0.753846  0.731989\n",
            "7   poly  0.001      1       2     8  0.661538   0.719884  0.661538  0.623626\n",
            "8   poly  0.001      1       2     9  0.769231   0.773164  0.769231  0.769559\n",
            "9   poly  0.001      1       2    10  0.671875   0.671453  0.671875  0.670172\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       3     1  0.569231   0.763772  0.569231  0.454676\n",
            "1   poly  0.001      1       3     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.001      1       3     3  0.738462   0.796923  0.738462  0.717949\n",
            "3   poly  0.001      1       3     4  0.600000   0.694915  0.600000  0.517730\n",
            "4   poly  0.001      1       3     5  0.676923   0.732249  0.676923  0.644624\n",
            "5   poly  0.001      1       3     6  0.830769   0.855644  0.830769  0.825477\n",
            "6   poly  0.001      1       3     7  0.830769   0.855644  0.830769  0.825477\n",
            "7   poly  0.001      1       3     8  0.723077   0.740171  0.723077  0.712692\n",
            "8   poly  0.001      1       3     9  0.676923   0.809955  0.676923  0.649573\n",
            "9   poly  0.001      1       3    10  0.640625   0.647629  0.640625  0.640186\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       4     1  0.538462   0.565128  0.538462  0.435625\n",
            "1   poly  0.001      1       4     2  0.676923   0.758612  0.676923  0.636550\n",
            "2   poly  0.001      1       4     3  0.769231   0.787213  0.769231  0.762014\n",
            "3   poly  0.001      1       4     4  0.615385   0.654753  0.615385  0.567321\n",
            "4   poly  0.001      1       4     5  0.707692   0.755385  0.707692  0.684766\n",
            "5   poly  0.001      1       4     6  0.769231   0.799243  0.769231  0.758998\n",
            "6   poly  0.001      1       4     7  0.815385   0.832818  0.815385  0.810651\n",
            "7   poly  0.001      1       4     8  0.676923   0.691252  0.676923  0.662597\n",
            "8   poly  0.001      1       4     9  0.630769   0.754438  0.630769  0.595685\n",
            "9   poly  0.001      1       4    10  0.671875   0.675312  0.671875  0.672115\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       5     1  0.538462   0.536821  0.538462  0.502150\n",
            "1   poly  0.001      1       5     2  0.692308   0.726648  0.692308  0.671126\n",
            "2   poly  0.001      1       5     3  0.753846   0.775214  0.753846  0.744615\n",
            "3   poly  0.001      1       5     4  0.584615   0.615385  0.584615  0.520710\n",
            "4   poly  0.001      1       5     5  0.692308   0.694653  0.692308  0.687359\n",
            "5   poly  0.001      1       5     6  0.661538   0.670085  0.661538  0.648846\n",
            "6   poly  0.001      1       5     7  0.769231   0.787213  0.769231  0.762014\n",
            "7   poly  0.001      1       5     8  0.661538   0.665311  0.661538  0.652860\n",
            "8   poly  0.001      1       5     9  0.630769   0.685971  0.630769  0.614935\n",
            "9   poly  0.001      1       5    10  0.578125   0.604893  0.578125  0.565831\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       1     1  0.538462   0.754808  0.538462  0.392759\n",
            "1   poly  0.1    0.1       1     2  0.584615   0.674359  0.584615  0.490920\n",
            "2   poly  0.1    0.1       1     3  0.692308   0.804196  0.692308  0.649573\n",
            "3   poly  0.1    0.1       1     4  0.569231   0.608866  0.569231  0.480633\n",
            "4   poly  0.1    0.1       1     5  0.692308   0.804196  0.692308  0.649573\n",
            "5   poly  0.1    0.1       1     6  0.800000   0.854167  0.800000  0.788003\n",
            "6   poly  0.1    0.1       1     7  0.907692   0.921201  0.907692  0.906208\n",
            "7   poly  0.1    0.1       1     8  0.738462   0.777432  0.738462  0.722773\n",
            "8   poly  0.1    0.1       1     9  0.646154   0.713857  0.646154  0.628466\n",
            "9   poly  0.1    0.1       1    10  0.671875   0.675312  0.671875  0.672115\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       2     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.1    0.1       2     2  0.569231   0.760684  0.569231  0.442308\n",
            "2   poly  0.1    0.1       2     3  0.630769   0.780965  0.630769  0.554828\n",
            "3   poly  0.1    0.1       2     4  0.569231   0.760684  0.569231  0.442308\n",
            "4   poly  0.1    0.1       2     5  0.600000   0.770492  0.600000  0.501225\n",
            "5   poly  0.1    0.1       2     6  0.723077   0.817126  0.723077  0.692058\n",
            "6   poly  0.1    0.1       2     7  0.753846   0.831071  0.753846  0.731989\n",
            "7   poly  0.1    0.1       2     8  0.661538   0.719884  0.661538  0.623626\n",
            "8   poly  0.1    0.1       2     9  0.769231   0.773164  0.769231  0.769559\n",
            "9   poly  0.1    0.1       2    10  0.671875   0.671453  0.671875  0.670172\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       3     3  0.553846   0.756010  0.553846  0.410507\n",
            "3   poly  0.1    0.1       3     4  0.569231   0.760684  0.569231  0.442308\n",
            "4   poly  0.1    0.1       3     5  0.553846   0.756010  0.553846  0.410507\n",
            "5   poly  0.1    0.1       3     6  0.630769   0.780965  0.630769  0.554828\n",
            "6   poly  0.1    0.1       3     7  0.615385   0.775641  0.615385  0.528629\n",
            "7   poly  0.1    0.1       3     8  0.630769   0.780965  0.630769  0.554828\n",
            "8   poly  0.1    0.1       3     9  0.661538   0.700496  0.661538  0.631485\n",
            "9   poly  0.1    0.1       3    10  0.609375   0.709352  0.609375  0.537329\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       4     6  0.600000   0.770492  0.600000  0.501225\n",
            "6   poly  0.1    0.1       4     7  0.569231   0.760684  0.569231  0.442308\n",
            "7   poly  0.1    0.1       4     8  0.553846   0.756010  0.553846  0.410507\n",
            "8   poly  0.1    0.1       4     9  0.584615   0.765509  0.584615  0.472497\n",
            "9   poly  0.1    0.1       4    10  0.546875   0.755456  0.546875  0.402665\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       5     6  0.584615   0.765509  0.584615  0.472497\n",
            "6   poly  0.1    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       5     9  0.569231   0.760684  0.569231  0.442308\n",
            "9   poly  0.1    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.5       1     2  0.661538   0.748252  0.661538  0.614530\n",
            "2   poly  0.1    0.5       1     3  0.769231   0.799243  0.769231  0.758998\n",
            "3   poly  0.1    0.5       1     4  0.615385   0.654753  0.615385  0.567321\n",
            "4   poly  0.1    0.5       1     5  0.753846   0.788325  0.753846  0.741088\n",
            "5   poly  0.1    0.5       1     6  0.892308   0.900769  0.892308  0.891002\n",
            "6   poly  0.1    0.5       1     7  0.923077   0.926226  0.923077  0.922633\n",
            "7   poly  0.1    0.5       1     8  0.738462   0.741154  0.738462  0.735291\n",
            "8   poly  0.1    0.5       1     9  0.584615   0.781377  0.584615  0.518660\n",
            "9   poly  0.1    0.5       1    10  0.640625   0.690241  0.640625  0.625708\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       2     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.5       2     2  0.676923   0.758612  0.676923  0.636550\n",
            "2   poly  0.1    0.5       2     3  0.784615   0.810256  0.784615  0.776538\n",
            "3   poly  0.1    0.5       2     4  0.661538   0.686813  0.661538  0.638239\n",
            "4   poly  0.1    0.5       2     5  0.769231   0.799243  0.769231  0.758998\n",
            "5   poly  0.1    0.5       2     6  0.846154   0.856473  0.846154  0.843680\n",
            "6   poly  0.1    0.5       2     7  0.923077   0.926226  0.923077  0.922633\n",
            "7   poly  0.1    0.5       2     8  0.707692   0.718781  0.707692  0.698551\n",
            "8   poly  0.1    0.5       2     9  0.630769   0.794872  0.630769  0.587195\n",
            "9   poly  0.1    0.5       2    10  0.625000   0.645833  0.625000  0.619458\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       3     1  0.569231   0.629254  0.569231  0.489386\n",
            "1   poly  0.1    0.5       3     2  0.676923   0.758612  0.676923  0.636550\n",
            "2   poly  0.1    0.5       3     3  0.800000   0.821429  0.800000  0.793745\n",
            "3   poly  0.1    0.5       3     4  0.646154   0.672308  0.646154  0.618401\n",
            "4   poly  0.1    0.5       3     5  0.784615   0.825423  0.784615  0.773452\n",
            "5   poly  0.1    0.5       3     6  0.753846   0.775214  0.753846  0.744615\n",
            "6   poly  0.1    0.5       3     7  0.876923   0.888837  0.876923  0.874944\n",
            "7   poly  0.1    0.5       3     8  0.692308   0.714130  0.692308  0.676360\n",
            "8   poly  0.1    0.5       3     9  0.615385   0.714932  0.615385  0.582825\n",
            "9   poly  0.1    0.5       3    10  0.640625   0.652559  0.640625  0.638778\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       4     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.1    0.5       4     2  0.661538   0.686813  0.661538  0.638239\n",
            "2   poly  0.1    0.5       4     3  0.753846   0.765816  0.753846  0.747535\n",
            "3   poly  0.1    0.5       4     4  0.584615   0.594675  0.584615  0.543088\n",
            "4   poly  0.1    0.5       4     5  0.676923   0.680045  0.676923  0.670273\n",
            "5   poly  0.1    0.5       4     6  0.723077   0.740171  0.723077  0.712692\n",
            "6   poly  0.1    0.5       4     7  0.815385   0.832818  0.815385  0.810651\n",
            "7   poly  0.1    0.5       4     8  0.661538   0.665311  0.661538  0.652860\n",
            "8   poly  0.1    0.5       4     9  0.600000   0.680000  0.600000  0.570000\n",
            "9   poly  0.1    0.5       4    10  0.562500   0.578125  0.562500  0.556034\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       5     1  0.523077   0.516694  0.523077  0.498083\n",
            "1   poly  0.1    0.5       5     2  0.630769   0.635043  0.630769  0.616923\n",
            "2   poly  0.1    0.5       5     3  0.723077   0.723866  0.723077  0.720671\n",
            "3   poly  0.1    0.5       5     4  0.538462   0.526395  0.538462  0.497479\n",
            "4   poly  0.1    0.5       5     5  0.692308   0.698813  0.692308  0.684418\n",
            "5   poly  0.1    0.5       5     6  0.661538   0.660750  0.661538  0.658598\n",
            "6   poly  0.1    0.5       5     7  0.753846   0.765816  0.753846  0.747535\n",
            "7   poly  0.1    0.5       5     8  0.630769   0.629191  0.630769  0.627562\n",
            "8   poly  0.1    0.5       5     9  0.661538   0.724344  0.661538  0.647024\n",
            "9   poly  0.1    0.5       5    10  0.531250   0.553125  0.531250  0.514827\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1      1       1     2  0.676923   0.758612  0.676923  0.636550\n",
            "2   poly  0.1      1       1     3  0.769231   0.799243  0.769231  0.758998\n",
            "3   poly  0.1      1       1     4  0.661538   0.700496  0.661538  0.631485\n",
            "4   poly  0.1      1       1     5  0.784615   0.810256  0.784615  0.776538\n",
            "5   poly  0.1      1       1     6  0.876923   0.881657  0.876923  0.875854\n",
            "6   poly  0.1      1       1     7  0.938462   0.939857  0.938462  0.938255\n",
            "7   poly  0.1      1       1     8  0.738462   0.741154  0.738462  0.735291\n",
            "8   poly  0.1      1       1     9  0.569231   0.777188  0.569231  0.494172\n",
            "9   poly  0.1      1       1    10  0.625000   0.654221  0.625000  0.616071\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       2     1  0.553846   0.601651  0.553846  0.463085\n",
            "1   poly  0.1      1       2     2  0.707692   0.778107  0.707692  0.678469\n",
            "2   poly  0.1      1       2     3  0.830769   0.855644  0.830769  0.825477\n",
            "3   poly  0.1      1       2     4  0.661538   0.686813  0.661538  0.638239\n",
            "4   poly  0.1      1       2     5  0.769231   0.799243  0.769231  0.758998\n",
            "5   poly  0.1      1       2     6  0.784615   0.791745  0.784615  0.781152\n",
            "6   poly  0.1      1       2     7  0.923077   0.926226  0.923077  0.922633\n",
            "7   poly  0.1      1       2     8  0.661538   0.665311  0.661538  0.652860\n",
            "8   poly  0.1      1       2     9  0.630769   0.794872  0.630769  0.587195\n",
            "9   poly  0.1      1       2    10  0.656250   0.665923  0.656250  0.655242\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       3     1  0.553846   0.559707  0.553846  0.514188\n",
            "1   poly  0.1      1       3     2  0.646154   0.662330  0.646154  0.624929\n",
            "2   poly  0.1      1       3     3  0.723077   0.727017  0.723077  0.718623\n",
            "3   poly  0.1      1       3     4  0.569231   0.565739  0.569231  0.546904\n",
            "4   poly  0.1      1       3     5  0.692308   0.694653  0.692308  0.687359\n",
            "5   poly  0.1      1       3     6  0.707692   0.707377  0.707692  0.706006\n",
            "6   poly  0.1      1       3     7  0.815385   0.824109  0.815385  0.812416\n",
            "7   poly  0.1      1       3     8  0.630769   0.629925  0.630769  0.624831\n",
            "8   poly  0.1      1       3     9  0.646154   0.713857  0.646154  0.628466\n",
            "9   poly  0.1      1       3    10  0.593750   0.611979  0.593750  0.587746\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       4     1  0.569231   0.571766  0.569231  0.549846\n",
            "1   poly  0.1      1       4     2  0.646154   0.645385  0.646154  0.641865\n",
            "2   poly  0.1      1       4     3  0.738462   0.738064  0.738462  0.738087\n",
            "3   poly  0.1      1       4     4  0.553846   0.547702  0.553846  0.539893\n",
            "4   poly  0.1      1       4     5  0.646154   0.647157  0.646154  0.638871\n",
            "5   poly  0.1      1       4     6  0.584615   0.582321  0.584615  0.582220\n",
            "6   poly  0.1      1       4     7  0.738462   0.741154  0.738462  0.735291\n",
            "7   poly  0.1      1       4     8  0.600000   0.598456  0.600000  0.598659\n",
            "8   poly  0.1      1       4     9  0.646154   0.713857  0.646154  0.628466\n",
            "9   poly  0.1      1       4    10  0.484375   0.494400  0.484375  0.474564\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       5     1  0.492308   0.481966  0.492308  0.472902\n",
            "1   poly  0.1      1       5     2  0.600000   0.597633  0.600000  0.596525\n",
            "2   poly  0.1      1       5     3  0.753846   0.753638  0.753846  0.753021\n",
            "3   poly  0.1      1       5     4  0.584615   0.581538  0.584615  0.579580\n",
            "4   poly  0.1      1       5     5  0.661538   0.660529  0.661538  0.660404\n",
            "5   poly  0.1      1       5     6  0.646154   0.645447  0.646154  0.645647\n",
            "6   poly  0.1      1       5     7  0.753846   0.753846  0.753846  0.753846\n",
            "7   poly  0.1      1       5     8  0.538462   0.540793  0.538462  0.539118\n",
            "8   poly  0.1      1       5     9  0.646154   0.684420  0.646154  0.637310\n",
            "9   poly  0.1      1       5    10  0.515625   0.520782  0.515625  0.515034\n",
            "\n",
            "Média dos resultados do kernel poly\n",
            "   kernel      c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
            "0    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "1    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "2    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "3    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "4    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "5    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "6    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "7    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "8    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "9    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "10   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "11   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "12   poly  0.001  0.500  ...       0.674711    0.625721    0.538764\n",
            "13   poly  0.001  0.500  ...       0.739746    0.660986    0.609175\n",
            "14   poly  0.001  0.500  ...       0.745432    0.673293    0.630319\n",
            "15   poly  0.001  1.000  ...       0.287536    0.536202    0.374329\n",
            "16   poly  0.001  1.000  ...       0.764474    0.650264    0.585258\n",
            "17   poly  0.001  1.000  ...       0.763408    0.693293    0.658010\n",
            "18   poly  0.001  1.000  ...       0.727415    0.687188    0.658632\n",
            "19   poly  0.001  1.000  ...       0.676219    0.656274    0.637045\n",
            "20   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "21   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "22   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "23   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "24   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "25   poly  0.100  0.100  ...       0.758839    0.684111    0.638102\n",
            "26   poly  0.100  0.100  ...       0.764474    0.650264    0.585258\n",
            "27   poly  0.100  0.100  ...       0.658367    0.588630    0.480663\n",
            "28   poly  0.100  0.100  ...       0.524152    0.553149    0.409618\n",
            "29   poly  0.100  0.100  ...       0.382167    0.543894    0.390425\n",
            "30   poly  0.100  0.500  ...       0.767101    0.713293    0.682039\n",
            "31   poly  0.100  0.500  ...       0.763778    0.717885    0.692700\n",
            "32   poly  0.100  0.500  ...       0.745270    0.705601    0.682906\n",
            "33   poly  0.100  0.500  ...       0.676224    0.657788    0.639373\n",
            "34   poly  0.100  0.500  ...       0.643404    0.634663    0.621312\n",
            "35   poly  0.100  1.000  ...       0.770335    0.719423    0.690837\n",
            "36   poly  0.100  1.000  ...       0.756554    0.717933    0.696335\n",
            "37   poly  0.100  1.000  ...       0.669669    0.657837    0.645147\n",
            "38   poly  0.100  1.000  ...       0.628026    0.620745    0.612776\n",
            "39   poly  0.100  1.000  ...       0.622059    0.619255    0.615339\n",
            "\n",
            "[40 rows x 8 columns]\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.1     1  0.553846   0.759219  0.553846  0.424502\n",
            "1    rbf  0.1    0.1     2  0.615385   0.711254  0.615385  0.543402\n",
            "2    rbf  0.1    0.1     3  0.738462   0.823964  0.738462  0.712315\n",
            "3    rbf  0.1    0.1     4  0.600000   0.657895  0.600000  0.532037\n",
            "4    rbf  0.1    0.1     5  0.738462   0.777432  0.738462  0.722773\n",
            "5    rbf  0.1    0.1     6  0.876923   0.899821  0.876923  0.873767\n",
            "6    rbf  0.1    0.1     7  0.923077   0.932692  0.923077  0.922145\n",
            "7    rbf  0.1    0.1     8  0.738462   0.752997  0.738462  0.730282\n",
            "8    rbf  0.1    0.1     9  0.630769   0.754438  0.630769  0.595685\n",
            "9    rbf  0.1    0.1    10  0.609375   0.625673  0.609375  0.605057\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.5     1  0.553846   0.640668  0.553846  0.445159\n",
            "1    rbf  0.1    0.5     2  0.676923   0.758612  0.676923  0.636550\n",
            "2    rbf  0.1    0.5     3  0.753846   0.775214  0.753846  0.744615\n",
            "3    rbf  0.1    0.5     4  0.646154   0.706682  0.646154  0.601935\n",
            "4    rbf  0.1    0.5     5  0.753846   0.765816  0.753846  0.747535\n",
            "5    rbf  0.1    0.5     6  0.892308   0.894962  0.892308  0.891687\n",
            "6    rbf  0.1    0.5     7  0.907692   0.913215  0.907692  0.906890\n",
            "7    rbf  0.1    0.5     8  0.753846   0.753638  0.753846  0.753021\n",
            "8    rbf  0.1    0.5     9  0.523077   0.765448  0.523077  0.414765\n",
            "9    rbf  0.1    0.5    10  0.578125   0.719381  0.578125  0.517527\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1      1     6  0.553846   0.756010  0.553846  0.410507\n",
            "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1      1     8  0.569231   0.760684  0.569231  0.442308\n",
            "8    rbf  0.1      1     9  0.707692   0.708583  0.707692  0.707970\n",
            "9    rbf  0.1      1    10  0.671875   0.680752  0.671875  0.662099\n",
            "\n",
            "Média dos resultados do kernel rbf\n",
            "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
            "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "5    rbf  0.100  0.100      0.702476       0.769539    0.702476    0.666196\n",
            "6    rbf  0.100  0.500      0.703966       0.769364    0.703966    0.665968\n",
            "7    rbf  0.100  1.000      0.571803       0.462934    0.571803    0.446678\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jz4oGIuXYem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "32915670-0db7-4fbd-a286-0fa943302eae"
      },
      "source": [
        "# Exibe o resultado do kernel Linear\n",
        "print(ic_linear_rf)\n",
        "result_linear_rf = result_linear_rf.rename(index={result_linear_rf.index[0]:'Recursive'})\n",
        "result_linear_rf"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.628961      0.702988   0.628961   0.578864\n",
            "sup     0.809885      0.837682   0.809885   0.802811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.690837</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "Recursive  linear  0.1      0.719423       0.770335    0.719423    0.690837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5o8JoHuXYer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "939d9729-8e32-44b8-c75e-951e73b72477"
      },
      "source": [
        "# Exibe o resultado do kernel Poly\n",
        "print(ic_poly_rf)\n",
        "result_poly_rf = result_poly_rf.rename(index={result_poly_rf.index[0]:'Recursive'})\n",
        "result_poly_rf"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.628961      0.702988   0.628961   0.578864\n",
            "sup     0.809885      0.837682   0.809885   0.802811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.690837</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "Recursive   poly  0.1    1.0  ...       0.770335    0.719423    0.690837\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNm7Gtf2XYe1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "8d08c579-3c66-4129-933c-7bed8068dea2"
      },
      "source": [
        "# Exibe o resultado do kernel RBF\n",
        "print(ic_rbf_rf)\n",
        "result_rbf_rf = result_rbf_rf.rename(index={result_rbf_rf.index[0]:'Recursive'})\n",
        "result_rbf_rf"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.608703      0.711012   0.608703   0.542463\n",
            "sup     0.799230      0.827715   0.799230   0.789474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.769364</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.665968</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "Recursive    rbf  0.1    0.5  ...       0.769364    0.703966    0.665968\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xd-pQsZXYe7",
        "colab_type": "text"
      },
      "source": [
        "# Resultados do Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmXwx6DMXYe8",
        "colab_type": "text"
      },
      "source": [
        "##### Imprime os resultados com os respectivos parametros e intervalos de confiança"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "_dVoheAABROt",
        "colab": {}
      },
      "source": [
        "r  = ['result_NB_all','result_NB_pca','result_NB_chi','result_NB_rf']\n",
        "i  = ['ic_NB_all','ic_NB_pca','ic_NB_chi','ic_NB_rf']\n",
        "j  = ['accuracy_avg','precision_avg','recall_avg','fscore_avg']\n",
        "k  = ['accuracy_ic','precision_ic','recall_ic','fscore_ic']\n",
        "for x,y in zip(r,i):\n",
        "  for w,z in zip(j,k):\n",
        "    exec(\"{r}.insert({r}.columns.get_loc('{j}')+1,'{k}_inf',{i}['{k}'][0],False)\".format(r=x,i=y,j=w,k=z))\n",
        "    exec(\"{r}.insert({r}.columns.get_loc('{j}')+2,'{k}_sup',{i}['{k}'][1],False)\".format(r=x,i=y,j=w,k=z))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mmgQ4ydd_wD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "273b35ca-7ae1-431c-c77c-c5d469c39b51"
      },
      "source": [
        "g_NB = pd.concat([result_NB_all,result_NB_pca,result_NB_chi,result_NB_rf],axis=0)\n",
        "g_NB['Classificador'] = 'Naive Bayes'\n",
        "g_NB"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>accuracy_ic_inf</th>\n",
              "      <th>accuracy_ic_sup</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>precision_ic_inf</th>\n",
              "      <th>precision_ic_sup</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>recall_ic_inf</th>\n",
              "      <th>recall_ic_sup</th>\n",
              "      <th>fscore_avg</th>\n",
              "      <th>fscore_ic_inf</th>\n",
              "      <th>fscore_ic_sup</th>\n",
              "      <th>Classificador</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.714880</td>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.739373</td>\n",
              "      <td>0.686647</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.714880</td>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.700049</td>\n",
              "      <td>0.619341</td>\n",
              "      <td>0.780758</td>\n",
              "      <td>Naive Bayes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.735570</td>\n",
              "      <td>0.679282</td>\n",
              "      <td>0.791858</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.650919</td>\n",
              "      <td>0.548533</td>\n",
              "      <td>0.753306</td>\n",
              "      <td>Naive Bayes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.768852</td>\n",
              "      <td>0.714899</td>\n",
              "      <td>0.822804</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.726894</td>\n",
              "      <td>0.645429</td>\n",
              "      <td>0.808358</td>\n",
              "      <td>Naive Bayes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.762049</td>\n",
              "      <td>0.708537</td>\n",
              "      <td>0.815561</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.715121</td>\n",
              "      <td>0.633364</td>\n",
              "      <td>0.796879</td>\n",
              "      <td>Naive Bayes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  c  accuracy_avg  ...  fscore_ic_sup  Classificador\n",
              "All Features  0.100      0.714880  ...       0.780758    Naive Bayes\n",
              "PCA           0.500      0.687188  ...       0.753306    Naive Bayes\n",
              "Chi           0.001      0.741058  ...       0.808358    Naive Bayes\n",
              "Recursive     0.001      0.731875  ...       0.796879    Naive Bayes\n",
              "\n",
              "[4 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kcz3wFzZ2w1",
        "colab_type": "text"
      },
      "source": [
        "# Resultados do SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuE8vK5waAzV",
        "colab_type": "text"
      },
      "source": [
        "Imprime os resultados com os respectivos parametros e intervalos de confiança"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjtqTFINaAE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r  = ['result_linear_all', 'result_poly_all', 'result_rbf_all','result_linear_pca', 'result_poly_pca', 'result_rbf_pca','result_linear_chi', 'result_poly_chi', 'result_rbf_chi','result_linear_rf', 'result_poly_rf', 'result_rbf_rf']\n",
        "i  = ['ic_linear_all', 'ic_poly_all', 'ic_rbf_all','ic_linear_pca', 'ic_poly_pca', 'ic_rbf_pca','ic_linear_chi', 'ic_poly_chi', 'ic_rbf_chi','ic_linear_rf', 'ic_poly_rf', 'ic_rbf_rf']\n",
        "j  = ['accuracy_avg','precision_avg','recall_avg','fscore_avg']\n",
        "k  = ['accuracy_ic','precision_ic','recall_ic','fscore_ic']\n",
        "for x,y in zip(r,i):\n",
        "  for w,z in zip(j,k):\n",
        "    exec(\"{r}.insert({r}.columns.get_loc('{j}')+1,'{k}_inf',{i}['{k}'][0],False)\".format(r=x,i=y,j=w,k=z))\n",
        "    exec(\"{r}.insert({r}.columns.get_loc('{j}')+2,'{k}_sup',{i}['{k}'][1],False)\".format(r=x,i=y,j=w,k=z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bGukg8VeH9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "60e095aa-6b72-4ab3-d4d8-dd6d2bfc8bb6"
      },
      "source": [
        "g_SVM = pd.concat([result_linear_all, result_poly_all, result_rbf_all,result_linear_pca, result_poly_pca, result_rbf_pca,result_linear_chi, result_poly_chi, result_rbf_chi,result_linear_rf, result_poly_rf, result_rbf_rf],axis=0)\n",
        "g_SVM['Classificador'] = 'SVM'\n",
        "g_SVM\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>accuracy_ic_inf</th>\n",
              "      <th>accuracy_ic_sup</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>precision_ic_inf</th>\n",
              "      <th>precision_ic_sup</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>recall_ic_inf</th>\n",
              "      <th>recall_ic_sup</th>\n",
              "      <th>fscore_avg</th>\n",
              "      <th>fscore_ic_inf</th>\n",
              "      <th>fscore_ic_sup</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>Classificador</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.625931</td>\n",
              "      <td>0.769886</td>\n",
              "      <td>0.754553</td>\n",
              "      <td>0.702986</td>\n",
              "      <td>0.806120</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.625931</td>\n",
              "      <td>0.769886</td>\n",
              "      <td>0.670648</td>\n",
              "      <td>0.580070</td>\n",
              "      <td>0.761227</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.710240</td>\n",
              "      <td>0.634177</td>\n",
              "      <td>0.786304</td>\n",
              "      <td>0.731985</td>\n",
              "      <td>0.664784</td>\n",
              "      <td>0.799185</td>\n",
              "      <td>0.710240</td>\n",
              "      <td>0.634177</td>\n",
              "      <td>0.786304</td>\n",
              "      <td>0.696639</td>\n",
              "      <td>0.611885</td>\n",
              "      <td>0.781393</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.604949</td>\n",
              "      <td>0.741734</td>\n",
              "      <td>0.708290</td>\n",
              "      <td>0.633665</td>\n",
              "      <td>0.782914</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.604949</td>\n",
              "      <td>0.741734</td>\n",
              "      <td>0.635024</td>\n",
              "      <td>0.539650</td>\n",
              "      <td>0.730398</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.624530</td>\n",
              "      <td>0.774460</td>\n",
              "      <td>0.738248</td>\n",
              "      <td>0.678692</td>\n",
              "      <td>0.797804</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.624530</td>\n",
              "      <td>0.774460</td>\n",
              "      <td>0.675761</td>\n",
              "      <td>0.582293</td>\n",
              "      <td>0.769229</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.624257</td>\n",
              "      <td>0.777618</td>\n",
              "      <td>0.734984</td>\n",
              "      <td>0.673032</td>\n",
              "      <td>0.796937</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.624257</td>\n",
              "      <td>0.777618</td>\n",
              "      <td>0.676787</td>\n",
              "      <td>0.580924</td>\n",
              "      <td>0.772650</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.602005</td>\n",
              "      <td>0.766217</td>\n",
              "      <td>0.703680</td>\n",
              "      <td>0.615024</td>\n",
              "      <td>0.792336</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.602005</td>\n",
              "      <td>0.766217</td>\n",
              "      <td>0.654902</td>\n",
              "      <td>0.549280</td>\n",
              "      <td>0.760524</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi Square</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.701010</td>\n",
              "      <td>0.612182</td>\n",
              "      <td>0.789837</td>\n",
              "      <td>0.744777</td>\n",
              "      <td>0.675395</td>\n",
              "      <td>0.814160</td>\n",
              "      <td>0.701010</td>\n",
              "      <td>0.612182</td>\n",
              "      <td>0.789837</td>\n",
              "      <td>0.671998</td>\n",
              "      <td>0.563516</td>\n",
              "      <td>0.780479</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi Square</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.630528</td>\n",
              "      <td>0.786924</td>\n",
              "      <td>0.749890</td>\n",
              "      <td>0.686755</td>\n",
              "      <td>0.813026</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.630528</td>\n",
              "      <td>0.786924</td>\n",
              "      <td>0.682172</td>\n",
              "      <td>0.584729</td>\n",
              "      <td>0.779615</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi Square</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.619454</td>\n",
              "      <td>0.804152</td>\n",
              "      <td>0.755496</td>\n",
              "      <td>0.681690</td>\n",
              "      <td>0.829303</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.619454</td>\n",
              "      <td>0.804152</td>\n",
              "      <td>0.683179</td>\n",
              "      <td>0.571175</td>\n",
              "      <td>0.795184</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.702988</td>\n",
              "      <td>0.837682</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.690837</td>\n",
              "      <td>0.578864</td>\n",
              "      <td>0.802811</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.702988</td>\n",
              "      <td>0.837682</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.690837</td>\n",
              "      <td>0.578864</td>\n",
              "      <td>0.802811</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.608703</td>\n",
              "      <td>0.799230</td>\n",
              "      <td>0.769364</td>\n",
              "      <td>0.711012</td>\n",
              "      <td>0.827715</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.608703</td>\n",
              "      <td>0.799230</td>\n",
              "      <td>0.665968</td>\n",
              "      <td>0.542463</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              kernel      c  accuracy_avg  ...  gamma  degree  Classificador\n",
              "All Features  linear  0.100      0.697909  ...    NaN     NaN            SVM\n",
              "All Features    poly  0.001      0.710240  ...    1.0     3.0            SVM\n",
              "All Features     rbf  0.100      0.673341  ...    0.1     NaN            SVM\n",
              "PCA           linear  0.100      0.699495  ...    NaN     NaN            SVM\n",
              "PCA             poly  0.100      0.700937  ...    0.5     1.0            SVM\n",
              "PCA              rbf  0.100      0.684111  ...    0.1     NaN            SVM\n",
              "Chi Square    linear  0.100      0.701010  ...    NaN     NaN            SVM\n",
              "Chi Square      poly  0.100      0.708726  ...    1.0     2.0            SVM\n",
              "Chi Square       rbf  0.100      0.711803  ...    0.1     NaN            SVM\n",
              "Recursive     linear  0.100      0.719423  ...    NaN     NaN            SVM\n",
              "Recursive       poly  0.100      0.719423  ...    1.0     1.0            SVM\n",
              "Recursive        rbf  0.100      0.703966  ...    0.5     NaN            SVM\n",
              "\n",
              "[12 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6v8AgPoERhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "f7ed668a-377d-47d6-9f7b-e436dc3dae7b"
      },
      "source": [
        "G = pd.concat([g_NB,g_SVM],axis=0)\n",
        "G['Features'] = G.index\n",
        "G"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>accuracy_ic_inf</th>\n",
              "      <th>accuracy_ic_sup</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>precision_ic_inf</th>\n",
              "      <th>precision_ic_sup</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>recall_ic_inf</th>\n",
              "      <th>recall_ic_sup</th>\n",
              "      <th>fscore_avg</th>\n",
              "      <th>fscore_ic_inf</th>\n",
              "      <th>fscore_ic_sup</th>\n",
              "      <th>Classificador</th>\n",
              "      <th>kernel</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>Features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.714880</td>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.739373</td>\n",
              "      <td>0.686647</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.714880</td>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.700049</td>\n",
              "      <td>0.619341</td>\n",
              "      <td>0.780758</td>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All Features</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.735570</td>\n",
              "      <td>0.679282</td>\n",
              "      <td>0.791858</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.650919</td>\n",
              "      <td>0.548533</td>\n",
              "      <td>0.753306</td>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.768852</td>\n",
              "      <td>0.714899</td>\n",
              "      <td>0.822804</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.726894</td>\n",
              "      <td>0.645429</td>\n",
              "      <td>0.808358</td>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.762049</td>\n",
              "      <td>0.708537</td>\n",
              "      <td>0.815561</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.715121</td>\n",
              "      <td>0.633364</td>\n",
              "      <td>0.796879</td>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Recursive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.625931</td>\n",
              "      <td>0.769886</td>\n",
              "      <td>0.754553</td>\n",
              "      <td>0.702986</td>\n",
              "      <td>0.806120</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.625931</td>\n",
              "      <td>0.769886</td>\n",
              "      <td>0.670648</td>\n",
              "      <td>0.580070</td>\n",
              "      <td>0.761227</td>\n",
              "      <td>SVM</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All Features</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.710240</td>\n",
              "      <td>0.634177</td>\n",
              "      <td>0.786304</td>\n",
              "      <td>0.731985</td>\n",
              "      <td>0.664784</td>\n",
              "      <td>0.799185</td>\n",
              "      <td>0.710240</td>\n",
              "      <td>0.634177</td>\n",
              "      <td>0.786304</td>\n",
              "      <td>0.696639</td>\n",
              "      <td>0.611885</td>\n",
              "      <td>0.781393</td>\n",
              "      <td>SVM</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>All Features</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.604949</td>\n",
              "      <td>0.741734</td>\n",
              "      <td>0.708290</td>\n",
              "      <td>0.633665</td>\n",
              "      <td>0.782914</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.604949</td>\n",
              "      <td>0.741734</td>\n",
              "      <td>0.635024</td>\n",
              "      <td>0.539650</td>\n",
              "      <td>0.730398</td>\n",
              "      <td>SVM</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All Features</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.624530</td>\n",
              "      <td>0.774460</td>\n",
              "      <td>0.738248</td>\n",
              "      <td>0.678692</td>\n",
              "      <td>0.797804</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.624530</td>\n",
              "      <td>0.774460</td>\n",
              "      <td>0.675761</td>\n",
              "      <td>0.582293</td>\n",
              "      <td>0.769229</td>\n",
              "      <td>SVM</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.624257</td>\n",
              "      <td>0.777618</td>\n",
              "      <td>0.734984</td>\n",
              "      <td>0.673032</td>\n",
              "      <td>0.796937</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.624257</td>\n",
              "      <td>0.777618</td>\n",
              "      <td>0.676787</td>\n",
              "      <td>0.580924</td>\n",
              "      <td>0.772650</td>\n",
              "      <td>SVM</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>PCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.602005</td>\n",
              "      <td>0.766217</td>\n",
              "      <td>0.703680</td>\n",
              "      <td>0.615024</td>\n",
              "      <td>0.792336</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.602005</td>\n",
              "      <td>0.766217</td>\n",
              "      <td>0.654902</td>\n",
              "      <td>0.549280</td>\n",
              "      <td>0.760524</td>\n",
              "      <td>SVM</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi Square</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.701010</td>\n",
              "      <td>0.612182</td>\n",
              "      <td>0.789837</td>\n",
              "      <td>0.744777</td>\n",
              "      <td>0.675395</td>\n",
              "      <td>0.814160</td>\n",
              "      <td>0.701010</td>\n",
              "      <td>0.612182</td>\n",
              "      <td>0.789837</td>\n",
              "      <td>0.671998</td>\n",
              "      <td>0.563516</td>\n",
              "      <td>0.780479</td>\n",
              "      <td>SVM</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chi Square</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi Square</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.630528</td>\n",
              "      <td>0.786924</td>\n",
              "      <td>0.749890</td>\n",
              "      <td>0.686755</td>\n",
              "      <td>0.813026</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.630528</td>\n",
              "      <td>0.786924</td>\n",
              "      <td>0.682172</td>\n",
              "      <td>0.584729</td>\n",
              "      <td>0.779615</td>\n",
              "      <td>SVM</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Chi Square</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi Square</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.619454</td>\n",
              "      <td>0.804152</td>\n",
              "      <td>0.755496</td>\n",
              "      <td>0.681690</td>\n",
              "      <td>0.829303</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.619454</td>\n",
              "      <td>0.804152</td>\n",
              "      <td>0.683179</td>\n",
              "      <td>0.571175</td>\n",
              "      <td>0.795184</td>\n",
              "      <td>SVM</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chi Square</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.702988</td>\n",
              "      <td>0.837682</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.690837</td>\n",
              "      <td>0.578864</td>\n",
              "      <td>0.802811</td>\n",
              "      <td>SVM</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Recursive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.702988</td>\n",
              "      <td>0.837682</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.690837</td>\n",
              "      <td>0.578864</td>\n",
              "      <td>0.802811</td>\n",
              "      <td>SVM</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Recursive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.608703</td>\n",
              "      <td>0.799230</td>\n",
              "      <td>0.769364</td>\n",
              "      <td>0.711012</td>\n",
              "      <td>0.827715</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.608703</td>\n",
              "      <td>0.799230</td>\n",
              "      <td>0.665968</td>\n",
              "      <td>0.542463</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>SVM</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Recursive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  c  accuracy_avg  accuracy_ic_inf  ...  gamma  degree      Features\n",
              "All Features  0.100      0.714880         0.647212  ...    NaN     NaN  All Features\n",
              "PCA           0.500      0.687188         0.615426  ...    NaN     NaN           PCA\n",
              "Chi           0.001      0.741058         0.673445  ...    NaN     NaN           Chi\n",
              "Recursive     0.001      0.731875         0.666579  ...    NaN     NaN     Recursive\n",
              "All Features  0.100      0.697909         0.625931  ...    NaN     NaN  All Features\n",
              "All Features  0.001      0.710240         0.634177  ...    1.0     3.0  All Features\n",
              "All Features  0.100      0.673341         0.604949  ...    0.1     NaN  All Features\n",
              "PCA           0.100      0.699495         0.624530  ...    NaN     NaN           PCA\n",
              "PCA           0.100      0.700937         0.624257  ...    0.5     1.0           PCA\n",
              "PCA           0.100      0.684111         0.602005  ...    0.1     NaN           PCA\n",
              "Chi Square    0.100      0.701010         0.612182  ...    NaN     NaN    Chi Square\n",
              "Chi Square    0.100      0.708726         0.630528  ...    1.0     2.0    Chi Square\n",
              "Chi Square    0.100      0.711803         0.619454  ...    0.1     NaN    Chi Square\n",
              "Recursive     0.100      0.719423         0.628961  ...    NaN     NaN     Recursive\n",
              "Recursive     0.100      0.719423         0.628961  ...    1.0     1.0     Recursive\n",
              "Recursive     0.100      0.703966         0.608703  ...    0.5     NaN     Recursive\n",
              "\n",
              "[16 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5nPWiXY29cEu"
      },
      "source": [
        "# Gerar Graficos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CFhU-Fp2yVbw",
        "outputId": "669cab90-f5a8-4162-cda9-f29183def23c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "\n",
        "df = G\n",
        "df['Parametros'] = df[['Features','Classificador']].fillna('').apply(lambda x: ' '.join((x).astype(str)), axis=1)\n",
        "conf = [df['accuracy_ic_sup'].array , df['accuracy_ic_inf'].array]\n",
        "means = df['accuracy_avg'].array\n",
        "ic = [conf[0]-means , means-conf[1]]\n",
        "g = plt.bar(df['Parametros'].array, df['accuracy_avg'].array, yerr=ic,width=0.5,zorder=2)\n",
        "plt.grid()\n",
        "g[0].set_color('g')\n",
        "g[1].set_color('g')\n",
        "g[2].set_color('g')\n",
        "g[3].set_color('g')\n",
        "plt.title(\"Accuracy_avg\")\n",
        "plt.ylabel('Accuracy_avg')\n",
        "plt.xlabel('Classificador')\n",
        "plt.yticks(np.arange(0, 1.1, .1))\n",
        "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
        "plt.show()\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EdqWuhELhsu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "0c47e20a-2671-49be-e70a-d85d0030ddd7"
      },
      "source": [
        "df = G\n",
        "df['Parametros'] = df[['Features','Classificador']].fillna('').apply(lambda x: ' '.join((x).astype(str)), axis=1)\n",
        "conf = [df['precision_ic_sup'].array , df['precision_ic_inf'].array]\n",
        "means = df['precision_avg'].array\n",
        "ic = [conf[0]-means , means-conf[1]]\n",
        "g = plt.bar(df['Parametros'].array, df['precision_avg'].array, yerr=ic,width=0.5,zorder=2)\n",
        "plt.grid()\n",
        "g[0].set_color('g')\n",
        "g[1].set_color('g')\n",
        "g[2].set_color('g')\n",
        "g[3].set_color('g')\n",
        "plt.title(\"Precision_avg\")\n",
        "plt.ylabel('Precision_avg')\n",
        "plt.xlabel('Classificador')\n",
        "plt.yticks(np.arange(0, 1.1, .1))\n",
        "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1224x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sgwPunXMHXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "c739ab0d-4842-4b92-cb41-8cbb6363f04f"
      },
      "source": [
        "df = G\n",
        "df['Parametros'] = df[['Features','Classificador']].fillna('').apply(lambda x: ' '.join((x).astype(str)), axis=1)\n",
        "conf = [df['recall_ic_sup'].array , df['recall_ic_inf'].array]\n",
        "means = df['recall_avg'].array\n",
        "ic = [conf[0]-means , means-conf[1]]\n",
        "g = plt.bar(df['Parametros'].array, df['recall_avg'].array, yerr=ic,width=0.5,zorder=2)\n",
        "plt.grid()\n",
        "g[0].set_color('g')\n",
        "g[1].set_color('g')\n",
        "g[2].set_color('g')\n",
        "g[3].set_color('g')\n",
        "plt.title(\"Recall_avg\")\n",
        "plt.ylabel('Recall_avg')\n",
        "plt.xlabel('Classificador')\n",
        "plt.yticks(np.arange(0, 1.1, .1))\n",
        "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1224x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}