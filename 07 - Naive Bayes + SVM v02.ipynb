{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 06 - k-fold cross validation + naive Bayes v03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlaprv/sin5007-reconhecimento-de-padroes/blob/master/07%20-%20Naive%20Bayes%20%2B%20SVM%20v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43Lcv8EVOUvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "8c497c36-35c2-4c01-bb94-a025b6e635d6"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/carlaprv/sin5007-reconhecimento-de-padroes cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cloned-repo' already exists and is not an empty directory.\n",
            "/content/cloned-repo\n",
            "'02 - Normalizacao_dataset_v01.ipynb'\n",
            "'02 - Normalizacao_dataset_v02.ipynb'\n",
            "'02 - Normalizacao_dataset_v03-portugues.ipynb'\n",
            "'03 - PCA_v01.ipynb'\n",
            "'03 - PCA_v02-portugues.ipynb'\n",
            "'04 - 01 Features Selection - Chi Squared v01.ipynb'\n",
            "'04 - 01 Features Selection - Chi Squared v02.ipynb'\n",
            "'04 - 02 Features Selection - Recursive Feature Elimination.ipynb'\n",
            "'04 - 02 Features Selection - Recursive Feature Elimination v02.ipynb'\n",
            "'04 - 03 Features Selection - Feature Importance.ipynb'\n",
            "'04 - 03 Features Selection - Feature Importance v02.ipynb'\n",
            "'04 - 04 Features Selection - Correlation Matrix.ipynb'\n",
            "'04 - 05 Features Selection - Select from Model.ipynb'\n",
            "'04 - 06 Features Selection Comparison.ipynb'\n",
            "'05 - Function k-fold cross validation-(biblioteca sklearn).ipynb'\n",
            "'05 - Function k-fold cross validation.ipynb'\n",
            "'06 - k-fold cross validation + naive bayes v01.ipynb'\n",
            "'06 - k-fold cross validation + naive Bayes v02.ipynb'\n",
            "'06 - k-fold cross validation + naive Bayes v03.ipynb'\n",
            "'06 - k-fold cross validation + naive Bayes v04.ipynb'\n",
            "'06 - k-fold cross validation + naive Bayes v05.ipynb'\n",
            "'07 - Naive Bayes + SVM v01.ipynb'\n",
            "'07 - Naive Bayes + SVM v02.ipynb'\n",
            "'data exploring notebooks'\n",
            " dataset\n",
            " graph.png\n",
            " kaggle\n",
            " README.md\n",
            " results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ikayTX9-yVZk"
      },
      "source": [
        "# Naive Bayes + SVM\n",
        "-------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KiZnnw89yVZm"
      },
      "source": [
        "# Bibliotecas Necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7xYCeWYlyVZn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0ac46622-a531-4169-e1c4-82bbaa38b631"
      },
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np\n",
        "import seaborn as sns # visualize\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.stats.api as sms\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from statsmodels.stats.weightstats import DescrStatsW\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HRJncBBWyVZt"
      },
      "source": [
        "# Funções Auxiliares\n",
        "\n",
        "describe_dataset() : realiza o cálculo das proporções de classes do dataset original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KutB_XTYyVZu",
        "colab": {}
      },
      "source": [
        "def describe_dataset(X, y, k):\n",
        "    # get dataset rows: instances , columns: features\n",
        "    rows, columns = X.shape\n",
        "    # get proportion from target\n",
        "    (unique, counts) = np.unique(y, return_counts=True) \n",
        "    # calculate proportion\n",
        "    prop_neg = int(counts[0]/rows*100)\n",
        "    prop_pos = int(counts[1]/rows*100)\n",
        "\n",
        "    print(\"k = {}, Dataset: {} positivas, {} negativas ({}% x {}%)\".format(k, counts[1], counts[0], prop_pos, prop_neg))\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4Z4wMlsnyVZz"
      },
      "source": [
        "get_classes_from_index() : realiza o cálculo das proporções de classes dos folds criados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xEZ4jxJKyVZ0",
        "colab": {}
      },
      "source": [
        "def get_classes_from_index(y, skf):\n",
        "    _, y_idx, y_inv = np.unique(y, return_index=True, return_inverse=True)\n",
        "    y_counts = np.bincount(y_inv)\n",
        "    _, class_perm = np.unique(y_idx, return_inverse=True)\n",
        "    y_encoded = class_perm[y_inv]\n",
        "    y_order = np.sort(y_encoded)\n",
        "    n_classes = len(y_idx)\n",
        "    allocation = np.asarray(\n",
        "            [np.bincount(y_order[i::skf.n_splits], minlength=n_classes)\n",
        "             for i in range(skf.n_splits)])\n",
        "\n",
        "    for idx, f in enumerate(allocation):\n",
        "        count_neg = int(f[0])\n",
        "        count_pos = int(f[1])\n",
        "        total = count_neg+count_pos\n",
        "        prop_temp_neg = int(count_neg/total*100)\n",
        "        prop_temp_pos = int(count_pos/total*100)\n",
        "        print(\"Fold {}: Pos: {}, Neg: {}, Total: {}, Proporção: {}% x {}%\".format(idx, count_pos, count_neg, total, prop_temp_pos, prop_temp_neg))\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnTH2MMbXYb8",
        "colab_type": "text"
      },
      "source": [
        "get_ic(): realiza o cálculo do indice de confiança"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdWzmJ5LXYb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ic(data, alpha):\n",
        "    \n",
        "    mean_c = []\n",
        "    for result in lista_result:\n",
        "        \n",
        "        c = result[0]\n",
        "        result_c = result[1]\n",
        "        \n",
        "        # Calcula a média das medidas do parametro c\n",
        "        precision_mean = result_c['precision'].mean()\n",
        "        recall_mean = result_c['recall'].mean()\n",
        "        f1_score_mean = result_c['f1-score'].mean()\n",
        "        support_mean = result_c['support'].mean()\n",
        "        accuracy_mean = result_c['accuracy'].mean()\n",
        "\n",
        "        # Calcula as ic das medidas\n",
        "        precision_ic = sms.DescrStatsW(result_c['precision']).tconfint_mean(alpha)\n",
        "        recall_ic = sms.DescrStatsW(result_c['recall']).tconfint_mean(alpha)\n",
        "        f1_score_ic = sms.DescrStatsW(result_c['f1-score']).tconfint_mean(alpha)\n",
        "        support_ic = sms.DescrStatsW(result_c['support']).tconfint_mean(alpha)\n",
        "        accuracy_ic = sms.DescrStatsW(result_c['accuracy']).tconfint_mean(alpha)\n",
        "\n",
        "        ic = {'recall_ic' : recall_ic, 'support_ic' : support_ic, 'accuracy_ic': accuracy_ic }\n",
        "        ic = pd.DataFrame(ic, index=['inf','sup'])\n",
        "\n",
        "        # Armazena a média das medidas do parametro c\n",
        "        mean_c.append([c, precision_mean, recall_mean, f1_score_mean, support_mean, accuracy_mean])\n",
        "    \n",
        "    name_columns = ['c', 'precision_mean', 'recall_mean', 'f1_score_mean', 'support_mean', 'accuracy_mean']\n",
        "    mean_c = pd.DataFrame(mean_c, columns=name_columns)\n",
        "    return mean_c, ic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7M_cAJuXYcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ic(data, alpha):\n",
        "\n",
        "    # Calcula as ic das medidas\n",
        "    accuracy_ic = sms.DescrStatsW(data['accuracy']).tconfint_mean(alpha)\n",
        "    precision_ic = sms.DescrStatsW(data['precision']).tconfint_mean(alpha)\n",
        "    recall_ic = sms.DescrStatsW(data['recall']).tconfint_mean(alpha)\n",
        "    fscore_ic = sms.DescrStatsW(data['fscore']).tconfint_mean(alpha)\n",
        "    \n",
        "    ic = [accuracy_ic, precision_ic, recall_ic, fscore_ic]\n",
        "\n",
        "    return ic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VETmxrTIXYcM",
        "colab_type": "text"
      },
      "source": [
        "# 1. Naive Bayes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OefDdR7WyVaD"
      },
      "source": [
        "##### Parâmetros de execução do Naive Bayes\n",
        "* list_c : valores do parâmetro de ajuste de probabilidade \n",
        "\n",
        "* k_folds : número de folds para a estratificação do dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mss4hXMgyVaE",
        "colab": {}
      },
      "source": [
        "list_c = [0.001, 0.10, 0.25, 0.50, 0.75, 1]\n",
        "# list_c = [0.001]\n",
        "k_folds = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YezZQsp7yVZ5",
        "colab": {}
      },
      "source": [
        "def execute_NB(X, y, list_c, k, dataSet):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------    \n",
        "           X : array-like, shape (n_samples, n_features)\n",
        "               Training data, where n_samples is the number of samples\n",
        "               and n_features is the number of features.\n",
        "           y : array-like, of length n_samples\n",
        "               The target variable for supervised learning problems.\n",
        "           k : int\n",
        "               Determines the number of folds.\n",
        "     dataSet : method selection (string)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ### Estratifica o dataset em k folds\n",
        "    skf = StratifiedKFold(n_splits=k)\n",
        "    describe_dataset(X, y, k)\n",
        "    get_classes_from_index(y, skf) \n",
        "    \n",
        "    \n",
        "    ### result_c: armazena a média dos k resultados para cada c e o índice de confiança\n",
        "    result_c = []\n",
        "    result_ic = []\n",
        "    \n",
        "    \n",
        "    ### Executa o treino e teste para cada valor do parametro c\n",
        "    for c in list_c:\n",
        "        print(\"c =  {}\" .format(c))\n",
        "\n",
        "        ### create naive bayes classifier\n",
        "        clf = GaussianNB(var_smoothing = c)\n",
        "                        \n",
        "        ### resultado do fold-k\n",
        "        result_k = []\n",
        "        \n",
        "        ### Executa o treino e teste para k folds\n",
        "        fold_k = 1\n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            \n",
        "            ### print(\"fold_k: {}\" .format(fold_k))\n",
        "            ### print(\"\\nTRAIN: {}  TEST: {}\".format(len(train_index), len(test_index)))\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            ### train classifier\n",
        "            clf.fit(X_train, y_train)\n",
        "            \n",
        "            ### calculate metrics\n",
        "            y_predicted = clf.predict(X_test)\n",
        "            report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
        "            report_str = metrics.classification_report(y_test, y_predicted)\n",
        "            ### print(report_str)\n",
        "            \n",
        "            all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
        "            accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
        "            precision = all_metrics[0]\n",
        "            recall = all_metrics[1]\n",
        "            fscore = all_metrics[2]\n",
        "                        \n",
        "            ### Armazena o resultado do fold k\n",
        "            result_k.append([c, fold_k, accuracy, precision, recall, fscore])\n",
        "            \n",
        "            fold_k = fold_k + 1\n",
        "                \n",
        "        \n",
        "        result_k = pd.DataFrame(result_k, columns=['c', 'fold', 'accuracy','precision','recall','fscore'])\n",
        "        print(result_k)\n",
        "        print(\"\")\n",
        "        \n",
        "        ### calcula a média das métricas dos k-folds      \n",
        "        accuracy_avg = result_k['accuracy'].mean()\n",
        "        precision_avg = result_k['precision'].mean()\n",
        "        recall_avg = result_k['recall'].mean()\n",
        "        fscore_avg = result_k['fscore'].mean()\n",
        "        \n",
        "        ### Calcula o índice de confiança dos k-folds\n",
        "        alpha = 0.05\n",
        "        ic_c = get_ic(result_k, alpha)\n",
        "        \n",
        "        ### Armazena a média dos resultados dos k-folds e o índice de confiança de cada métrica\n",
        "        result_c.append([c, accuracy_avg, precision_avg, recall_avg, fscore_avg])\n",
        "        result_ic.append(ic_c)\n",
        "        \n",
        "    ### Converte em DataFrame\n",
        "    result_c = pd.DataFrame(result_c, columns=['c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    result_ic = pd.DataFrame(result_ic, columns=['accuracy_ic', 'precision_ic', 'recall_ic', 'fscore_ic'])\n",
        "    print(\"Média dos resultados de cada teste:\")\n",
        "    print(result_c)\n",
        "    print(\"\")    \n",
        "    \n",
        "    ### Armazena apenas as métricas da melhor acurácia média    \n",
        "    result = [] \n",
        "    result.append(result_c.iloc[result_c['accuracy_avg'].argmax()])    \n",
        "    result = pd.DataFrame(result, columns=['c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'], index=[dataSet])\n",
        "    \n",
        "    ### Armazena o indice de confiança da melhor acuracia\n",
        "    ic = result_ic.iloc[result_c['accuracy_avg'].argmax()]\n",
        "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
        "    ic = pd.DataFrame(ic, index=['inf','sup'])\n",
        "        \n",
        "    ### Retorna as métricas com a melhor acurácia e o índice de confiança\n",
        "    return result, ic\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3RsPfCv4yVZ4"
      },
      "source": [
        "### 1.1. Naive Bayes: All Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHKrCam0XYcc",
        "colab_type": "code",
        "outputId": "ed660bd2-4651-40ca-cda4-c41a481f0b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = pd.read_csv('results/dataset-normalizado.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "result_NB_all, ic_NB_all = execute_NB(X, y, list_c, k=k_folds, dataSet='All Features')\n",
        "print(\"Melhor resultado:\")\n",
        "result_NB_all"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "c =  0.001\n",
            "       c  fold  accuracy  precision    recall    fscore\n",
            "0  0.001     1  0.569231   0.669231  0.569231  0.473250\n",
            "1  0.001     2  0.646154   0.662330  0.646154  0.624929\n",
            "2  0.001     3  0.769231   0.769906  0.769231  0.767900\n",
            "3  0.001     4  0.676923   0.680045  0.676923  0.670273\n",
            "4  0.001     5  0.723077   0.723866  0.723077  0.720671\n",
            "5  0.001     6  0.800000   0.805000  0.800000  0.797576\n",
            "6  0.001     7  0.876923   0.881657  0.876923  0.875854\n",
            "7  0.001     8  0.661538   0.661538  0.661538  0.661538\n",
            "8  0.001     9  0.676923   0.753592  0.676923  0.660773\n",
            "9  0.001    10  0.656250   0.671938  0.656250  0.653554\n",
            "\n",
            "c =  0.1\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.1     1  0.584615   0.690004  0.584615  0.500114\n",
            "1  0.1     2  0.676923   0.713846  0.676923  0.651584\n",
            "2  0.1     3  0.753846   0.755424  0.753846  0.751708\n",
            "3  0.1     4  0.692308   0.705128  0.692308  0.680769\n",
            "4  0.1     5  0.707692   0.707377  0.707692  0.706006\n",
            "5  0.1     6  0.830769   0.830681  0.830769  0.830527\n",
            "6  0.1     7  0.907692   0.908821  0.907692  0.907383\n",
            "7  0.1     8  0.692308   0.694493  0.692308  0.692746\n",
            "8  0.1     9  0.630769   0.703054  0.630769  0.609467\n",
            "9  0.1    10  0.671875   0.684904  0.671875  0.670189\n",
            "\n",
            "c =  0.25\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.25     1  0.569231   0.669231  0.569231  0.473250\n",
            "1  0.25     2  0.676923   0.732249  0.676923  0.644624\n",
            "2  0.25     3  0.769231   0.773077  0.769231  0.766434\n",
            "3  0.25     4  0.692308   0.705128  0.692308  0.680769\n",
            "4  0.25     5  0.676923   0.676113  0.676923  0.675060\n",
            "5  0.25     6  0.846154   0.846748  0.846154  0.845638\n",
            "6  0.25     7  0.892308   0.894962  0.892308  0.891687\n",
            "7  0.25     8  0.723077   0.722602  0.723077  0.722149\n",
            "8  0.25     9  0.615385   0.691817  0.615385  0.589992\n",
            "9  0.25    10  0.656250   0.665923  0.656250  0.655242\n",
            "\n",
            "c =  0.5\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.5     1  0.569231   0.669231  0.569231  0.473250\n",
            "1  0.5     2  0.661538   0.748252  0.661538  0.614530\n",
            "2  0.5     3  0.753846   0.759381  0.753846  0.749888\n",
            "3  0.5     4  0.661538   0.677032  0.661538  0.643996\n",
            "4  0.5     5  0.676923   0.677308  0.676923  0.673007\n",
            "5  0.5     6  0.861538   0.863698  0.861538  0.860740\n",
            "6  0.5     7  0.907692   0.908821  0.907692  0.907383\n",
            "7  0.5     8  0.692308   0.692308  0.692308  0.689635\n",
            "8  0.5     9  0.615385   0.674123  0.615385  0.596159\n",
            "9  0.5    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "c =  0.75\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.75     1  0.569231   0.669231  0.569231  0.473250\n",
            "1  0.75     2  0.630769   0.725034  0.630769  0.568034\n",
            "2  0.75     3  0.753846   0.759381  0.753846  0.749888\n",
            "3  0.75     4  0.630769   0.646978  0.630769  0.605351\n",
            "4  0.75     5  0.676923   0.677308  0.676923  0.673007\n",
            "5  0.75     6  0.892308   0.900769  0.892308  0.891002\n",
            "6  0.75     7  0.938462   0.939857  0.938462  0.938255\n",
            "7  0.75     8  0.707692   0.709231  0.707692  0.704149\n",
            "8  0.75     9  0.646154   0.697436  0.646154  0.633287\n",
            "9  0.75    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "c =  1\n",
            "   c  fold  accuracy  precision    recall    fscore\n",
            "0  1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  1     2  0.630769   0.725034  0.630769  0.568034\n",
            "2  1     3  0.738462   0.745819  0.738462  0.733078\n",
            "3  1     4  0.615385   0.630769  0.615385  0.585219\n",
            "4  1     5  0.676923   0.680045  0.676923  0.670273\n",
            "5  1     6  0.876923   0.888837  0.876923  0.874944\n",
            "6  1     7  0.923077   0.926226  0.923077  0.922633\n",
            "7  1     8  0.692308   0.698813  0.692308  0.684418\n",
            "8  1     9  0.692308   0.730530  0.692308  0.686118\n",
            "9  1    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "Média dos resultados de cada teste:\n",
            "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  0.001      0.705625       0.727910    0.705625    0.690632\n",
            "1  0.100      0.714880       0.739373    0.714880    0.700049\n",
            "2  0.250      0.711779       0.737785    0.711779    0.694484\n",
            "3  0.500      0.705625       0.733155    0.705625    0.686484\n",
            "4  0.750      0.710240       0.738662    0.710240    0.689247\n",
            "5  1.000      0.705625       0.732814    0.705625    0.682613\n",
            "\n",
            "Melhor resultado:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.71488</td>\n",
              "      <td>0.739373</td>\n",
              "      <td>0.71488</td>\n",
              "      <td>0.700049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "All Features  0.1       0.71488       0.739373     0.71488    0.700049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV_HDt2SXYcj",
        "colab_type": "text"
      },
      "source": [
        "Índice de Confiança do melhor resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRGrb5XmXYck",
        "colab_type": "code",
        "outputId": "55b1d322-c3d5-4434-fa9e-89ab60bb2408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "ic_NB_all"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_ic</th>\n",
              "      <th>precision_ic</th>\n",
              "      <th>recall_ic</th>\n",
              "      <th>fscore_ic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>inf</th>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.686647</td>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.619341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sup</th>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.780758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
              "inf     0.647212      0.686647   0.647212   0.619341\n",
              "sup     0.782547      0.792099   0.782547   0.780758"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuroGu1gXYcp",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. Naive Bayes: PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ5T9RKiXYcq",
        "colab_type": "code",
        "outputId": "f49233fe-bad2-4a52-c809-6eb6c9e95d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = pd.read_csv('results/dataset-pca.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "result_NB_pca, ic_NB_pca = execute_NB(X, y, list_c, k=k_folds, dataSet='PCA')\n",
        "print(\"Melhor resultado:\")\n",
        "result_NB_pca"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "c =  0.001\n",
            "       c  fold  accuracy  precision    recall    fscore\n",
            "0  0.001     1  0.600000   0.773333  0.600000  0.510875\n",
            "1  0.001     2  0.646154   0.686391  0.646154  0.610779\n",
            "2  0.001     3  0.815385   0.815711  0.815385  0.814766\n",
            "3  0.001     4  0.630769   0.639935  0.630769  0.611632\n",
            "4  0.001     5  0.646154   0.645447  0.646154  0.645647\n",
            "5  0.001     6  0.800000   0.800759  0.800000  0.800190\n",
            "6  0.001     7  0.815385   0.815385  0.815385  0.815385\n",
            "7  0.001     8  0.615385   0.633136  0.615385  0.612095\n",
            "8  0.001     9  0.646154   0.762443  0.646154  0.616199\n",
            "9  0.001    10  0.609375   0.651864  0.609375  0.593160\n",
            "\n",
            "c =  0.1\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.1     1  0.553846   0.759219  0.553846  0.424502\n",
            "1  0.1     2  0.615385   0.676282  0.615385  0.556213\n",
            "2  0.1     3  0.800000   0.811594  0.800000  0.795883\n",
            "3  0.1     4  0.615385   0.640533  0.615385  0.576933\n",
            "4  0.1     5  0.600000   0.598309  0.600000  0.589744\n",
            "5  0.1     6  0.784615   0.784615  0.784615  0.784615\n",
            "6  0.1     7  0.830769   0.830681  0.830769  0.830527\n",
            "7  0.1     8  0.661538   0.663753  0.661538  0.662020\n",
            "8  0.1     9  0.661538   0.724344  0.661538  0.647024\n",
            "9  0.1    10  0.625000   0.645833  0.625000  0.619458\n",
            "\n",
            "c =  0.25\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.25     1  0.538462   0.754808  0.538462  0.392759\n",
            "1  0.25     2  0.615385   0.711254  0.615385  0.543402\n",
            "2  0.25     3  0.784615   0.799317  0.784615  0.779093\n",
            "3  0.25     4  0.584615   0.615385  0.584615  0.520710\n",
            "4  0.25     5  0.615385   0.619257  0.615385  0.598329\n",
            "5  0.25     6  0.784615   0.791745  0.784615  0.781152\n",
            "6  0.25     7  0.830769   0.836923  0.830769  0.828718\n",
            "7  0.25     8  0.723077   0.723866  0.723077  0.720671\n",
            "8  0.25     9  0.692308   0.744755  0.692308  0.682952\n",
            "9  0.25    10  0.656250   0.658203  0.656250  0.656586\n",
            "\n",
            "c =  0.5\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.5     1  0.538462   0.754808  0.538462  0.392759\n",
            "1  0.5     2  0.615385   0.711254  0.615385  0.543402\n",
            "2  0.5     3  0.738462   0.763246  0.738462  0.726864\n",
            "3  0.5     4  0.569231   0.608866  0.569231  0.480633\n",
            "4  0.5     5  0.646154   0.662330  0.646154  0.624929\n",
            "5  0.5     6  0.800000   0.821429  0.800000  0.793745\n",
            "6  0.5     7  0.861538   0.877369  0.861538  0.858688\n",
            "7  0.5     8  0.707692   0.718781  0.707692  0.698551\n",
            "8  0.5     9  0.723077   0.764931  0.723077  0.717507\n",
            "9  0.5    10  0.671875   0.672685  0.671875  0.672116\n",
            "\n",
            "c =  0.75\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.75     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  0.75     2  0.615385   0.711254  0.615385  0.543402\n",
            "2  0.75     3  0.723077   0.751227  0.723077  0.708724\n",
            "3  0.75     4  0.569231   0.608866  0.569231  0.480633\n",
            "4  0.75     5  0.646154   0.672308  0.646154  0.618401\n",
            "5  0.75     6  0.784615   0.810256  0.784615  0.776538\n",
            "6  0.75     7  0.861538   0.889860  0.861538  0.857208\n",
            "7  0.75     8  0.692308   0.705128  0.692308  0.680769\n",
            "8  0.75     9  0.738462   0.763314  0.738462  0.736225\n",
            "9  0.75    10  0.656250   0.656250  0.656250  0.656250\n",
            "\n",
            "c =  1\n",
            "   c  fold  accuracy  precision    recall    fscore\n",
            "0  1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  1     2  0.615385   0.711254  0.615385  0.543402\n",
            "2  1     3  0.707692   0.739065  0.707692  0.690158\n",
            "3  1     4  0.553846   0.573077  0.553846  0.453210\n",
            "4  1     5  0.661538   0.700496  0.661538  0.631485\n",
            "5  1     6  0.753846   0.788325  0.753846  0.741088\n",
            "6  1     7  0.861538   0.889860  0.861538  0.857208\n",
            "7  1     8  0.661538   0.677032  0.661538  0.643996\n",
            "8  1     9  0.769231   0.778388  0.769231  0.769231\n",
            "9  1    10  0.671875   0.671398  0.671875  0.671472\n",
            "\n",
            "Média dos resultados de cada teste:\n",
            "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  0.001      0.682476       0.722440    0.682476    0.663073\n",
            "1  0.100      0.674808       0.713516    0.674808    0.648692\n",
            "2  0.250      0.682548       0.725551    0.682548    0.650437\n",
            "3  0.500      0.687188       0.735570    0.687188    0.650919\n",
            "4  0.750      0.681010       0.684207    0.681010    0.641744\n",
            "5  1.000      0.677957       0.680250    0.677957    0.636054\n",
            "\n",
            "Melhor resultado:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.73557</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.650919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "PCA  0.5      0.687188        0.73557    0.687188    0.650919"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0d-tvxtXYcv",
        "colab_type": "text"
      },
      "source": [
        "Índice de Confiança"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAvglXMXYcv",
        "colab_type": "code",
        "outputId": "ad5930d1-4a32-46ed-932e-0f8b8b1d72e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "ic_NB_pca"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_ic</th>\n",
              "      <th>precision_ic</th>\n",
              "      <th>recall_ic</th>\n",
              "      <th>fscore_ic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>inf</th>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.679282</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.548533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sup</th>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.791858</td>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.753306</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
              "inf     0.615426      0.679282   0.615426   0.548533\n",
              "sup     0.758949      0.791858   0.758949   0.753306"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2l0V4VOXYc1",
        "colab_type": "text"
      },
      "source": [
        "### 1.3. Naive Bayes: Chi Squared (K-Best)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceYFQDGPXYc2",
        "colab_type": "code",
        "outputId": "5bf43831-7434-4dd6-b0d7-7edf35c252e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = pd.read_csv('results/dataset-fs-chi-squared.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "result_NB_chi, ic_NB_chi = execute_NB(X, y, list_c, k=k_folds, dataSet='Chi')\n",
        "print(\"Melhor resultado:\")\n",
        "result_NB_chi"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "c =  0.001\n",
            "       c  fold  accuracy  precision    recall    fscore\n",
            "0  0.001     1  0.584615   0.690004  0.584615  0.500114\n",
            "1  0.001     2  0.692308   0.744021  0.692308  0.664986\n",
            "2  0.001     3  0.815385   0.815711  0.815385  0.814766\n",
            "3  0.001     4  0.723077   0.740171  0.723077  0.712692\n",
            "4  0.001     5  0.707692   0.707377  0.707692  0.706006\n",
            "5  0.001     6  0.861538   0.863698  0.861538  0.860740\n",
            "6  0.001     7  0.907692   0.913215  0.907692  0.906890\n",
            "7  0.001     8  0.723077   0.723077  0.723077  0.723077\n",
            "8  0.001     9  0.707692   0.793326  0.707692  0.693081\n",
            "9  0.001    10  0.687500   0.697917  0.687500  0.686584\n",
            "\n",
            "c =  0.1\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  0.1     2  0.646154   0.686391  0.646154  0.610779\n",
            "2  0.1     3  0.753846   0.753638  0.753846  0.753021\n",
            "3  0.1     4  0.692308   0.705128  0.692308  0.680769\n",
            "4  0.1     5  0.707692   0.707377  0.707692  0.706006\n",
            "5  0.1     6  0.861538   0.863698  0.861538  0.860740\n",
            "6  0.1     7  0.969231   0.969231  0.969231  0.969231\n",
            "7  0.1     8  0.738462   0.742351  0.738462  0.738833\n",
            "8  0.1     9  0.676923   0.777963  0.676923  0.655593\n",
            "9  0.1    10  0.687500   0.697917  0.687500  0.686584\n",
            "\n",
            "c =  0.25\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.25     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  0.25     2  0.615385   0.654753  0.615385  0.567321\n",
            "2  0.25     3  0.753846   0.753638  0.753846  0.753021\n",
            "3  0.25     4  0.692308   0.705128  0.692308  0.680769\n",
            "4  0.25     5  0.707692   0.707377  0.707692  0.706006\n",
            "5  0.25     6  0.830769   0.832434  0.830769  0.829793\n",
            "6  0.25     7  0.969231   0.969231  0.969231  0.969231\n",
            "7  0.25     8  0.753846   0.755973  0.753846  0.754196\n",
            "8  0.25     9  0.692308   0.785633  0.692308  0.674556\n",
            "9  0.25    10  0.656250   0.665923  0.656250  0.655242\n",
            "\n",
            "c =  0.5\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.5     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  0.5     2  0.615385   0.654753  0.615385  0.567321\n",
            "2  0.5     3  0.753846   0.755424  0.753846  0.751708\n",
            "3  0.5     4  0.676923   0.700698  0.676923  0.657543\n",
            "4  0.5     5  0.692308   0.694653  0.692308  0.687359\n",
            "5  0.5     6  0.861538   0.868846  0.861538  0.859860\n",
            "6  0.5     7  0.969231   0.970894  0.969231  0.969128\n",
            "7  0.5     8  0.784615   0.786713  0.784615  0.784922\n",
            "8  0.5     9  0.692308   0.785633  0.692308  0.674556\n",
            "9  0.5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "c =  0.75\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.75     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  0.75     2  0.630769   0.692308  0.630769  0.579487\n",
            "2  0.75     3  0.738462   0.741154  0.738462  0.735291\n",
            "3  0.75     4  0.676923   0.700698  0.676923  0.657543\n",
            "4  0.75     5  0.676923   0.680045  0.676923  0.670273\n",
            "5  0.75     6  0.861538   0.868846  0.861538  0.859860\n",
            "6  0.75     7  0.953846   0.957490  0.953846  0.953580\n",
            "7  0.75     8  0.784615   0.784615  0.784615  0.784615\n",
            "8  0.75     9  0.692308   0.785633  0.692308  0.674556\n",
            "9  0.75    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "c =  1\n",
            "   c  fold  accuracy  precision    recall    fscore\n",
            "0  1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  1     2  0.630769   0.692308  0.630769  0.579487\n",
            "2  1     3  0.723077   0.727017  0.723077  0.718623\n",
            "3  1     4  0.646154   0.672308  0.646154  0.618401\n",
            "4  1     5  0.676923   0.680045  0.676923  0.670273\n",
            "5  1     6  0.861538   0.868846  0.861538  0.859860\n",
            "6  1     7  0.953846   0.957490  0.953846  0.953580\n",
            "7  1     8  0.784615   0.784675  0.784615  0.783893\n",
            "8  1     9  0.676923   0.753592  0.676923  0.660773\n",
            "9  1    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "Média dos resultados de cada teste:\n",
            "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  0.001      0.741058       0.768852    0.741058    0.726894\n",
            "1  0.100      0.728750       0.754436    0.728750    0.710671\n",
            "2  0.250      0.722548       0.747076    0.722548    0.703529\n",
            "3  0.500      0.727187       0.753762    0.727187    0.706903\n",
            "4  0.750      0.722548       0.751285    0.722548    0.701662\n",
            "5  1.000      0.716394       0.743834    0.716394    0.694630\n",
            "\n",
            "Melhor resultado:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.768852</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.726894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "Chi  0.001      0.741058       0.768852    0.741058    0.726894"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdb3wYpGXYc8",
        "colab_type": "text"
      },
      "source": [
        "Índice de Confiança para o dataset Chi-Squared"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3yGSap7XYc9",
        "colab_type": "code",
        "outputId": "7a15587f-bca3-4f50-834c-e195ecaa5968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "ic_NB_chi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_ic</th>\n",
              "      <th>precision_ic</th>\n",
              "      <th>recall_ic</th>\n",
              "      <th>fscore_ic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>inf</th>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.714899</td>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.645429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sup</th>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.822804</td>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.808358</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
              "inf     0.673445      0.714899   0.673445   0.645429\n",
              "sup     0.808670      0.822804   0.808670   0.808358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLrlvN-ZXYdD",
        "colab_type": "text"
      },
      "source": [
        "### 1.4. Naive Bayes: Recursive Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlZN83sBXYdF",
        "colab_type": "code",
        "outputId": "e9dcdc8f-1ab9-4cce-f3a2-cca12480153d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = pd.read_csv('results/dataset-fs-recursive-feature.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "result_NB_rf, ic_NB_rf = execute_NB(X, y, list_c, k=k_folds, dataSet='Recursive')\n",
        "print(\"Melhor resultado:\")\n",
        "result_NB_rf"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "c =  0.001\n",
            "       c  fold  accuracy  precision    recall    fscore\n",
            "0  0.001     1  0.584615   0.768474  0.584615  0.483424\n",
            "1  0.001     2  0.676923   0.713846  0.676923  0.651584\n",
            "2  0.001     3  0.800000   0.811594  0.800000  0.795883\n",
            "3  0.001     4  0.646154   0.650350  0.646154  0.635088\n",
            "4  0.001     5  0.769231   0.787213  0.769231  0.762014\n",
            "5  0.001     6  0.800000   0.811594  0.800000  0.795883\n",
            "6  0.001     7  0.892308   0.900769  0.892308  0.891002\n",
            "7  0.001     8  0.661538   0.670085  0.661538  0.648846\n",
            "8  0.001     9  0.769231   0.785863  0.769231  0.768465\n",
            "9  0.001    10  0.718750   0.720703  0.718750  0.719025\n",
            "\n",
            "c =  0.1\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.1     1  0.538462   0.596361  0.538462  0.415724\n",
            "1  0.1     2  0.676923   0.758612  0.676923  0.636550\n",
            "2  0.1     3  0.753846   0.775214  0.753846  0.744615\n",
            "3  0.1     4  0.676923   0.713846  0.676923  0.651584\n",
            "4  0.1     5  0.769231   0.778707  0.769231  0.764481\n",
            "5  0.1     6  0.830769   0.855644  0.830769  0.825477\n",
            "6  0.1     7  0.892308   0.900769  0.892308  0.891002\n",
            "7  0.1     8  0.676923   0.691252  0.676923  0.662597\n",
            "8  0.1     9  0.769231   0.808787  0.769231  0.765595\n",
            "9  0.1    10  0.703125   0.703904  0.703125  0.703343\n",
            "\n",
            "c =  0.25\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.25     1  0.538462   0.596361  0.538462  0.415724\n",
            "1  0.25     2  0.630769   0.725034  0.630769  0.568034\n",
            "2  0.25     3  0.753846   0.775214  0.753846  0.744615\n",
            "3  0.25     4  0.676923   0.732249  0.676923  0.644624\n",
            "4  0.25     5  0.753846   0.775214  0.753846  0.744615\n",
            "5  0.25     6  0.815385   0.862520  0.815385  0.805816\n",
            "6  0.25     7  0.876923   0.888837  0.876923  0.874944\n",
            "7  0.25     8  0.707692   0.739065  0.707692  0.690158\n",
            "8  0.25     9  0.769231   0.795858  0.769231  0.767257\n",
            "9  0.25    10  0.718750   0.720703  0.718750  0.719025\n",
            "\n",
            "c =  0.5\n",
            "     c  fold  accuracy  precision    recall    fscore\n",
            "0  0.5     1  0.553846   0.759219  0.553846  0.424502\n",
            "1  0.5     2  0.600000   0.694915  0.600000  0.517730\n",
            "2  0.5     3  0.723077   0.766484  0.723077  0.704013\n",
            "3  0.5     4  0.646154   0.706682  0.646154  0.601935\n",
            "4  0.5     5  0.769231   0.815799  0.769231  0.755388\n",
            "5  0.5     6  0.815385   0.862520  0.815385  0.805816\n",
            "6  0.5     7  0.892308   0.910256  0.892308  0.890091\n",
            "7  0.5     8  0.707692   0.739065  0.707692  0.690158\n",
            "8  0.5     9  0.753846   0.766136  0.753846  0.753497\n",
            "9  0.5    10  0.703125   0.703904  0.703125  0.703343\n",
            "\n",
            "c =  0.75\n",
            "      c  fold  accuracy  precision    recall    fscore\n",
            "0  0.75     1  0.553846   0.759219  0.553846  0.424502\n",
            "1  0.75     2  0.600000   0.694915  0.600000  0.517730\n",
            "2  0.75     3  0.723077   0.787546  0.723077  0.698488\n",
            "3  0.75     4  0.646154   0.706682  0.646154  0.601935\n",
            "4  0.75     5  0.753846   0.806319  0.753846  0.736901\n",
            "5  0.75     6  0.800000   0.854167  0.800000  0.788003\n",
            "6  0.75     7  0.892308   0.910256  0.892308  0.890091\n",
            "7  0.75     8  0.692308   0.726648  0.692308  0.671126\n",
            "8  0.75     9  0.753846   0.760035  0.753846  0.754079\n",
            "9  0.75    10  0.687500   0.687500  0.687500  0.687500\n",
            "\n",
            "c =  1\n",
            "   c  fold  accuracy  precision    recall    fscore\n",
            "0  1     1  0.553846   0.759219  0.553846  0.424502\n",
            "1  1     2  0.600000   0.694915  0.600000  0.517730\n",
            "2  1     3  0.723077   0.817126  0.723077  0.692058\n",
            "3  1     4  0.630769   0.692308  0.630769  0.579487\n",
            "4  1     5  0.723077   0.787546  0.723077  0.698488\n",
            "5  1     6  0.800000   0.854167  0.800000  0.788003\n",
            "6  1     7  0.876923   0.899821  0.876923  0.873767\n",
            "7  1     8  0.676923   0.713846  0.676923  0.651584\n",
            "8  1     9  0.769231   0.770034  0.769231  0.769450\n",
            "9  1    10  0.671875   0.671398  0.671875  0.671472\n",
            "\n",
            "Média dos resultados de cada teste:\n",
            "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  0.001      0.731875       0.762049    0.731875    0.715121\n",
            "1  0.100      0.728774       0.758309    0.728774    0.706097\n",
            "2  0.250      0.724183       0.761105    0.724183    0.697481\n",
            "3  0.500      0.716466       0.772498    0.716466    0.684647\n",
            "4  0.750      0.710288       0.769329    0.710288    0.677036\n",
            "5  1.000      0.702572       0.766038    0.702572    0.666654\n",
            "\n",
            "Melhor resultado:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.762049</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.715121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "Recursive  0.001      0.731875       0.762049    0.731875    0.715121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-1UTe46XYdN",
        "colab_type": "text"
      },
      "source": [
        "Índice de Confiança para dataset Recursive-Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SlCXxWNXYdO",
        "colab_type": "code",
        "outputId": "d5cac7cb-5f63-4009-8d88-53629e0b368d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "ic_NB_rf"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy_ic</th>\n",
              "      <th>precision_ic</th>\n",
              "      <th>recall_ic</th>\n",
              "      <th>fscore_ic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>inf</th>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.708537</td>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.633364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sup</th>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.815561</td>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.796879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
              "inf     0.666579      0.708537   0.666579   0.633364\n",
              "sup     0.797171      0.815561   0.797171   0.796879"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRoX2JhXYdV",
        "colab_type": "text"
      },
      "source": [
        "# 2. SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQQ7C2YYXYdW",
        "colab_type": "text"
      },
      "source": [
        "##### Parâmetros de execução do SVM\n",
        "\n",
        "* k_folds:     número de folds para a estratificação do dataset\n",
        "\n",
        "* list_c:      valores do parâmetro de ajuste de probabilidade \n",
        "\n",
        "* list_degree: valores do parâmetro degree utilizado no kernel poly\n",
        "\n",
        "* list_gamma:  valores do parâmetro gamma utilizado no kernel poly\n",
        "\n",
        "* list_coef:   valores do parâmetro coef utilizado no kernel rbf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3SyfgJAXYdW",
        "colab_type": "text"
      },
      "source": [
        "* Função que aplica o SVM para cada Kernel implementado\n",
        "* Em cada kernel é testado vários valores de cada parâmetro.\n",
        "* Com o resultado de cada parâmetro, verifica qual a melhor acurácia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRl-BHnXYdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def execute_SVM(X, y, k, list_c, list_degree, list_gamma, list_coef, dataSet):\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------    \n",
        "              X: array-like, shape (n_samples, n_features)\n",
        "                 Training data, where n_samples is the number of samples\n",
        "                 and n_features is the number of features.\n",
        "              y: array-like, of length n_samples\n",
        "                 The target variable for supervised learning problems.\n",
        "              k: int\n",
        "                 Determines the number of folds.\n",
        "        dataSet: method selection (string)\n",
        "         list_c: values of parameter c\n",
        "    list_degree: values of parameter degree\n",
        "     list_gamma: values of parameter gamma\n",
        "      list_coef: values of parameter coef\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    ### Resultados\n",
        "    result = []              # result:             melhor resultado geral do SVM\n",
        "    result_best_linear = []  # result_best_linear: melhor resultado do kernel linear\n",
        "    result_best_poly = []    # result_best_poly:   melhor resultado do kernel poly\n",
        "    result_best_rbf = []     # result_best_rbf:    melhor resultado do kernel rbf\n",
        "\n",
        "\n",
        "    ### Estratifica o dataset em k folds\n",
        "    skf = StratifiedKFold(n_splits=k)\n",
        "    describe_dataset(X, y, k)\n",
        "    get_classes_from_index(y, skf) \n",
        "    \n",
        "    \n",
        "    #################################################################################################################\n",
        "    # 1. KERNEL LINEAR\n",
        "    #################################################################################################################\n",
        "    result_linear = []\n",
        "    result_linear_ic = []\n",
        "    for C in list_c:\n",
        "        \n",
        "        ### Create a SVM Linear Classifier\n",
        "        model_linear = svm.SVC(kernel='linear', C=C)\n",
        "        kernel = model_linear.kernel\n",
        "        \n",
        "        ### resultado do fold-k\n",
        "        result_k = []\n",
        "        \n",
        "        fold_k = 1\n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "    \n",
        "            ### Train the model\n",
        "            model_linear.fit(X_train, y_train)\n",
        "    \n",
        "            ### Test the model\n",
        "            y_predicted = model_linear.predict(X_test)\n",
        "            \n",
        "            ### calculate metrics\n",
        "            report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
        "            report_str = metrics.classification_report(y_test, y_predicted)        \n",
        "            ### print(report_str)\n",
        "            \n",
        "            all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
        "            accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
        "            precision = all_metrics[0]\n",
        "            recall = all_metrics[1]\n",
        "            fscore = all_metrics[2]\n",
        "                        \n",
        "            ### Armazena o resultado do fold k\n",
        "            result_k.append([kernel, C, fold_k, accuracy, precision, recall, fscore])\n",
        "            \n",
        "            fold_k = fold_k + 1\n",
        "    \n",
        "        result_k = pd.DataFrame(result_k, columns=['kernel', 'c', 'fold', 'accuracy','precision','recall','fscore'])\n",
        "        print(result_k)\n",
        "        print(\"\")\n",
        "        \n",
        "        ### calcula a média das métricas dos k-folds      \n",
        "        accuracy_avg = result_k['accuracy'].mean()\n",
        "        precision_avg = result_k['precision'].mean()\n",
        "        recall_avg = result_k['recall'].mean()\n",
        "        fscore_avg = result_k['fscore'].mean()\n",
        "        \n",
        "        ### Calcula o índice de confiança dos k-folds\n",
        "        alpha = 0.05\n",
        "        ic_c = get_ic(result_k, alpha)\n",
        "        \n",
        "        ### Armazena a média dos resultados dos k-folds e o índice de confiança\n",
        "        result_linear.append([kernel, C, accuracy_avg, precision_avg, recall_avg, fscore_avg]) \n",
        "        result_linear_ic.append(ic_c)\n",
        "\n",
        "    \n",
        "    ### Exibe os resultados de cada valor c\n",
        "    result_linear = pd.DataFrame(result_linear, columns=['kernel', 'c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    result_linear_ic = pd.DataFrame(result_linear_ic, columns=['accuracy_ic','precision_ic','recall_ic','fscore_ic'])\n",
        "    print(\"Média dos resultados do kernel linear\")\n",
        "    print(result_linear)\n",
        "    print(\"\")\n",
        "    \n",
        "    \n",
        "    #################################################################################################################\n",
        "    # 2.KERNEL POLY\n",
        "    #################################################################################################################\n",
        "    result_poly = []\n",
        "    result_poly_ic = []\n",
        "    for C in list_c:\n",
        "        for gamma in list_gamma:\n",
        "            for degree in list_degree:\n",
        "                \n",
        "                ### Create a SVM Linear Classifier\n",
        "                model_poly = svm.SVC(kernel='poly', degree=degree, gamma=gamma, C=C)\n",
        "                kernel = model_poly.kernel\n",
        "                \n",
        "                ### resultado do fold-k\n",
        "                result_k = []\n",
        "                \n",
        "                fold_k = 1\n",
        "                for train_index, test_index in skf.split(X, y):\n",
        "                    X_train, X_test = X[train_index], X[test_index]\n",
        "                    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                    ### Train the model\n",
        "                    model_poly.fit(X_train, y_train)\n",
        "\n",
        "                    ### Test the model\n",
        "                    y_predicted = model_poly.predict(X_test)\n",
        "\n",
        "                    ### calculate metrics\n",
        "                    report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
        "                    report_str = metrics.classification_report(y_test, y_predicted)        \n",
        "                    ### print(report_str)\n",
        "\n",
        "                    all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
        "                    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
        "                    precision = all_metrics[0]\n",
        "                    recall = all_metrics[1]\n",
        "                    fscore = all_metrics[2]\n",
        "\n",
        "                    ### Armazena o resultado do fold k\n",
        "                    result_k.append([kernel, C, gamma, degree, fold_k, accuracy, precision, recall, fscore])\n",
        "\n",
        "                    fold_k = fold_k + 1\n",
        "\n",
        "                result_k = pd.DataFrame(result_k, columns=['kernel', 'c', 'gamma', 'degree', 'fold', 'accuracy','precision','recall','fscore'])\n",
        "                print(result_k)\n",
        "                print(\"\")\n",
        "                \n",
        "                ### calcula a média das métricas dos k-folds      \n",
        "                accuracy_avg = result_k['accuracy'].mean()\n",
        "                precision_avg = result_k['precision'].mean()\n",
        "                recall_avg = result_k['recall'].mean()\n",
        "                fscore_avg = result_k['fscore'].mean()\n",
        "\n",
        "                ### Calcula o índice de confiança dos k-folds\n",
        "                alpha = 0.05\n",
        "                ic_c = get_ic(result_k, alpha)\n",
        "\n",
        "                ### Armazena a média dos resultados dos k-folds e o índice de confiança\n",
        "                result_poly.append([kernel, C, gamma, degree, accuracy_avg, precision_avg, recall_avg, fscore_avg]) \n",
        "                result_poly_ic.append(ic_c)\n",
        "    \n",
        "    ### Exibe os resultados de cada valor c\n",
        "    result_poly = pd.DataFrame(result_poly, columns=['kernel', 'c', 'gamma', 'degree', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    result_poly_ic = pd.DataFrame(result_poly_ic, columns=['accuracy_ic','precision_ic','recall_ic','fscore_ic'])\n",
        "    print(\"Média dos resultados do kernel poly\")\n",
        "    print(result_poly)\n",
        "    print(\"\")            \n",
        "        \n",
        "        \n",
        "    #################################################################################################################\n",
        "    ### 3. KERNEL RBF\n",
        "    #################################################################################################################\n",
        "    result_rbf = []\n",
        "    result_rbf_ic = []\n",
        "    for C in list_c:\n",
        "        for gamma in list_gamma:\n",
        "            ### Create a SVM Linear Classifier\n",
        "            model_rbf = svm.SVC(kernel='rbf', gamma=gamma, C=C)   \n",
        "            kernel = model_rbf.kernel\n",
        "                \n",
        "            ### resultado do fold-k\n",
        "            result_k = []\n",
        "\n",
        "            fold_k = 1\n",
        "            \n",
        "            for train_index, test_index in skf.split(X, y):\n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                ### Train the model\n",
        "                model_rbf.fit(X_train, y_train)\n",
        "\n",
        "                ### Test the model\n",
        "                y_predicted = model_rbf.predict(X_test)\n",
        "\n",
        "                ### calculate metrics\n",
        "                report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
        "                report_str = metrics.classification_report(y_test, y_predicted)        \n",
        "                ### print(report_str)\n",
        "\n",
        "                all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
        "                accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
        "                precision = all_metrics[0]\n",
        "                recall = all_metrics[1]\n",
        "                fscore = all_metrics[2]\n",
        "\n",
        "                ### Armazena o resultado do fold k\n",
        "                result_k.append([kernel, C, gamma, fold_k, accuracy, precision, recall, fscore])\n",
        "\n",
        "                fold_k = fold_k + 1\n",
        "\n",
        "            result_k = pd.DataFrame(result_k, columns=['kernel', 'c', 'gamma', 'fold', 'accuracy','precision','recall','fscore'])\n",
        "            print(result_k)\n",
        "            print(\"\")           \n",
        "            \n",
        "            ### calcula a média das métricas dos k-folds      \n",
        "            accuracy_avg = result_k['accuracy'].mean()\n",
        "            precision_avg = result_k['precision'].mean()\n",
        "            recall_avg = result_k['recall'].mean()\n",
        "            fscore_avg = result_k['fscore'].mean()\n",
        "\n",
        "            ### Calcula o índice de confiança dos k-folds\n",
        "            alpha = 0.05\n",
        "            ic_c = get_ic(result_k, alpha)\n",
        "\n",
        "            ### Armazena a média dos resultados dos k-folds e o índice de confiança\n",
        "            result_rbf.append([kernel, C, gamma, accuracy_avg, precision_avg, recall_avg, fscore_avg]) \n",
        "            result_rbf_ic.append(ic_c)\n",
        "    \n",
        "    ### Exibe os resultados de cada valor c\n",
        "    result_rbf = pd.DataFrame(result_rbf, columns=['kernel', 'c', 'gamma', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    result_rbf_ic = pd.DataFrame(result_rbf_ic, columns=['accuracy_ic','precision_ic','recall_ic','fscore_ic'])\n",
        "    print(\"Média dos resultados do kernel rbf\")\n",
        "    print(result_rbf)\n",
        "    print(\"\")            \n",
        "           \n",
        "    \n",
        "    \n",
        "    #################################################################################################################\n",
        "    ### ARMAZENA OS MELHORES RESULTADOS \n",
        "    #################################################################################################################\n",
        "    \n",
        "    ### Armazena apenas as métricas da melhor acurácia média do MODELO LINEAR e o seu indice de confiança\n",
        "    result_best_linear.append(result_linear.iloc[result_linear['accuracy_avg'].argmax()])\n",
        "    result_best_linear = pd.DataFrame(result_best_linear, columns=['kernel', 'c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    # print(result_best_linear)\n",
        "    print(\"\")\n",
        "    \n",
        "    ic = result_linear_ic.iloc[result_linear['accuracy_avg'].argmax()]\n",
        "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
        "    ic_best_linear = pd.DataFrame(ic, index=['inf','sup'])\n",
        "    \n",
        "    \n",
        "    ### Armazena apenas as métricas da melhor acurácia média do MODELO POLY e o seu respectivo indice de confiança\n",
        "    result_best_poly.append(result_poly.iloc[result_poly['accuracy_avg'].argmax()])\n",
        "    result_best_poly = pd.DataFrame(result_best_poly, columns=['kernel', 'c', 'gamma', 'degree', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    # print(result_best_poly)\n",
        "    print(\"\")\n",
        "    \n",
        "    ic = result_poly_ic.iloc[result_poly['accuracy_avg'].argmax()]\n",
        "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
        "    ic_best_poly = pd.DataFrame(ic, index=['inf','sup'])\n",
        "    \n",
        "    \n",
        "    ### Armazena apenas as métricas da melhor acurácia média do MODELO RBF e seu índice de confiança\n",
        "    result_best_rbf.append(result_rbf.iloc[result_rbf['accuracy_avg'].argmax()])\n",
        "    result_best_rbf = pd.DataFrame(result_best_rbf, columns=['kernel', 'c', 'gamma', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
        "    # print(result_best_rbf)\n",
        "    print(\"\")\n",
        "    \n",
        "    ic = result_rbf_ic.iloc[result_rbf['accuracy_avg'].argmax()]\n",
        "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
        "    ic_best_rbf = pd.DataFrame(ic, index=['inf','sup'])\n",
        "    \n",
        "    \n",
        "    ### Retorna o melhor resultado de cada kernel e seus respectivos índices de confiança \n",
        "    return result_best_linear, result_best_poly, result_best_rbf, ic_best_linear, ic_best_poly, ic_best_rbf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWggVTGVXYdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list_c = [0.001, 0.10, 0.25, 0.50, 0.75, 1]\n",
        "list_c = [0.001, 0.10]\n",
        "list_gamma = [0.001, 0.1, 0.5, 1]\n",
        "list_degree = [1, 2, 3, 4, 5]\n",
        "\n",
        "list_coef = [0.01]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkUiX3QMXYdg",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. SVM: all features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GhPrp6blXYdh",
        "colab_type": "code",
        "outputId": "cc6e7818-8c27-4a2a-be22-60c75737dffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = pd.read_csv('results/dataset-normalizado.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "\n",
        "result_linear_all, result_poly_all, result_rbf_all, ic_linear_all, ic_poly_all, ic_rbf_all = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, list_coef, dataSet='All Features')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "   kernel      c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "   kernel    c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.1     1  0.584615   0.768474  0.584615  0.483424\n",
            "1  linear  0.1     2  0.676923   0.758612  0.676923  0.636550\n",
            "2  linear  0.1     3  0.800000   0.805000  0.800000  0.797576\n",
            "3  linear  0.1     4  0.646154   0.686391  0.646154  0.610779\n",
            "4  linear  0.1     5  0.738462   0.752997  0.738462  0.730282\n",
            "5  linear  0.1     6  0.738462   0.745819  0.738462  0.733078\n",
            "6  linear  0.1     7  0.907692   0.908821  0.907692  0.907383\n",
            "7  linear  0.1     8  0.661538   0.660750  0.661538  0.658598\n",
            "8  linear  0.1     9  0.584615   0.781377  0.584615  0.518660\n",
            "9  linear  0.1    10  0.640625   0.677291  0.640625  0.630153\n",
            "\n",
            "Média dos resultados do kernel linear\n",
            "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1  linear  0.100      0.697909       0.754553    0.697909    0.670648\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       2     2  0.538462   0.521368  0.538462  0.402473\n",
            "2   poly  0.001    0.5       2     3  0.600000   0.657895  0.600000  0.532037\n",
            "3   poly  0.001    0.5       2     4  0.553846   0.602978  0.553846  0.433422\n",
            "4   poly  0.001    0.5       2     5  0.584615   0.636036  0.584615  0.506874\n",
            "5   poly  0.001    0.5       2     6  0.676923   0.798077  0.676923  0.627219\n",
            "6   poly  0.001    0.5       2     7  0.723077   0.817126  0.723077  0.692058\n",
            "7   poly  0.001    0.5       2     8  0.615385   0.676282  0.615385  0.556213\n",
            "8   poly  0.001    0.5       2     9  0.815385   0.815385  0.815385  0.815385\n",
            "9   poly  0.001    0.5       2    10  0.656250   0.657813  0.656250  0.651089\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       3     1  0.538462   0.596361  0.538462  0.415724\n",
            "1   poly  0.001    0.5       3     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.001    0.5       3     3  0.738462   0.752997  0.738462  0.730282\n",
            "3   poly  0.001    0.5       3     4  0.630769   0.692308  0.630769  0.579487\n",
            "4   poly  0.001    0.5       3     5  0.707692   0.718781  0.707692  0.698551\n",
            "5   poly  0.001    0.5       3     6  0.800000   0.821429  0.800000  0.793745\n",
            "6   poly  0.001    0.5       3     7  0.876923   0.888837  0.876923  0.874944\n",
            "7   poly  0.001    0.5       3     8  0.676923   0.677308  0.676923  0.673007\n",
            "8   poly  0.001    0.5       3     9  0.584615   0.692550  0.584615  0.540532\n",
            "9   poly  0.001    0.5       3    10  0.687500   0.704706  0.687500  0.685049\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       4     1  0.569231   0.607509  0.569231  0.503419\n",
            "1   poly  0.001    0.5       4     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.001    0.5       4     3  0.769231   0.778707  0.769231  0.764481\n",
            "3   poly  0.001    0.5       4     4  0.615385   0.623963  0.615385  0.592314\n",
            "4   poly  0.001    0.5       4     5  0.692308   0.692308  0.692308  0.689635\n",
            "5   poly  0.001    0.5       4     6  0.815385   0.832818  0.815385  0.810651\n",
            "6   poly  0.001    0.5       4     7  0.861538   0.862210  0.861538  0.861670\n",
            "7   poly  0.001    0.5       4     8  0.630769   0.629492  0.630769  0.629531\n",
            "8   poly  0.001    0.5       4     9  0.584615   0.667421  0.584615  0.549451\n",
            "9   poly  0.001    0.5       4    10  0.671875   0.684904  0.671875  0.670189\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       5     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.001    0.5       5     2  0.707692   0.718781  0.707692  0.698551\n",
            "2   poly  0.001    0.5       5     3  0.723077   0.727017  0.723077  0.718623\n",
            "3   poly  0.001    0.5       5     4  0.538462   0.531306  0.538462  0.526627\n",
            "4   poly  0.001    0.5       5     5  0.707692   0.707377  0.707692  0.706006\n",
            "5   poly  0.001    0.5       5     6  0.738462   0.738064  0.738462  0.738087\n",
            "6   poly  0.001    0.5       5     7  0.769231   0.778388  0.769231  0.769231\n",
            "7   poly  0.001    0.5       5     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.001    0.5       5     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.001    0.5       5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       2     1  0.538462   0.596361  0.538462  0.415724\n",
            "1   poly  0.001      1       2     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.001      1       2     3  0.753846   0.765816  0.753846  0.747535\n",
            "3   poly  0.001      1       2     4  0.600000   0.657895  0.600000  0.532037\n",
            "4   poly  0.001      1       2     5  0.661538   0.670085  0.661538  0.648846\n",
            "5   poly  0.001      1       2     6  0.815385   0.832818  0.815385  0.810651\n",
            "6   poly  0.001      1       2     7  0.907692   0.913215  0.907692  0.906890\n",
            "7   poly  0.001      1       2     8  0.707692   0.707377  0.707692  0.706006\n",
            "8   poly  0.001      1       2     9  0.630769   0.754438  0.630769  0.595685\n",
            "9   poly  0.001      1       2    10  0.671875   0.692212  0.671875  0.668248\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       3     1  0.600000   0.669841  0.600000  0.538889\n",
            "1   poly  0.001      1       3     2  0.738462   0.752997  0.738462  0.730282\n",
            "2   poly  0.001      1       3     3  0.784615   0.799317  0.784615  0.779093\n",
            "3   poly  0.001      1       3     4  0.646154   0.662330  0.646154  0.624929\n",
            "4   poly  0.001      1       3     5  0.692308   0.694653  0.692308  0.687359\n",
            "5   poly  0.001      1       3     6  0.846154   0.856473  0.846154  0.843680\n",
            "6   poly  0.001      1       3     7  0.907692   0.908821  0.907692  0.907383\n",
            "7   poly  0.001      1       3     8  0.630769   0.629492  0.630769  0.629531\n",
            "8   poly  0.001      1       3     9  0.600000   0.680000  0.600000  0.570000\n",
            "9   poly  0.001      1       3    10  0.656250   0.665923  0.656250  0.655242\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       4     1  0.553846   0.564417  0.553846  0.503995\n",
            "1   poly  0.001      1       4     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.001      1       4     3  0.676923   0.676113  0.676923  0.675060\n",
            "3   poly  0.001      1       4     4  0.538462   0.532833  0.538462  0.531039\n",
            "4   poly  0.001      1       4     5  0.692308   0.691565  0.692308  0.691276\n",
            "5   poly  0.001      1       4     6  0.707692   0.708583  0.707692  0.707970\n",
            "6   poly  0.001      1       4     7  0.784615   0.790979  0.784615  0.784819\n",
            "7   poly  0.001      1       4     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.001      1       4     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.001      1       4    10  0.640625   0.652559  0.640625  0.638778\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       5     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.001      1       5     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.001      1       5     3  0.738462   0.741154  0.738462  0.735291\n",
            "3   poly  0.001      1       5     4  0.523077   0.515608  0.523077  0.513260\n",
            "4   poly  0.001      1       5     5  0.707692   0.707377  0.707692  0.706006\n",
            "5   poly  0.001      1       5     6  0.738462   0.738064  0.738462  0.738087\n",
            "6   poly  0.001      1       5     7  0.769231   0.778388  0.769231  0.769231\n",
            "7   poly  0.001      1       5     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.001      1       5     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.001      1       5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       1     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.1    0.1       1     2  0.615385   0.711254  0.615385  0.543402\n",
            "2   poly  0.1    0.1       1     3  0.738462   0.745819  0.738462  0.733078\n",
            "3   poly  0.1    0.1       1     4  0.615385   0.676282  0.615385  0.556213\n",
            "4   poly  0.1    0.1       1     5  0.646154   0.662330  0.646154  0.624929\n",
            "5   poly  0.1    0.1       1     6  0.846154   0.856473  0.846154  0.843680\n",
            "6   poly  0.1    0.1       1     7  0.907692   0.913215  0.907692  0.906890\n",
            "7   poly  0.1    0.1       1     8  0.676923   0.684565  0.676923  0.666819\n",
            "8   poly  0.1    0.1       1     9  0.661538   0.770256  0.661538  0.636154\n",
            "9   poly  0.1    0.1       1    10  0.640625   0.658942  0.640625  0.636653\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       2     1  0.538462   0.596361  0.538462  0.415724\n",
            "1   poly  0.1    0.1       2     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.1       2     3  0.753846   0.765816  0.753846  0.747535\n",
            "3   poly  0.1    0.1       2     4  0.600000   0.657895  0.600000  0.532037\n",
            "4   poly  0.1    0.1       2     5  0.661538   0.670085  0.661538  0.648846\n",
            "5   poly  0.1    0.1       2     6  0.815385   0.832818  0.815385  0.810651\n",
            "6   poly  0.1    0.1       2     7  0.907692   0.913215  0.907692  0.906890\n",
            "7   poly  0.1    0.1       2     8  0.707692   0.707377  0.707692  0.706006\n",
            "8   poly  0.1    0.1       2     9  0.630769   0.754438  0.630769  0.595685\n",
            "9   poly  0.1    0.1       2    10  0.671875   0.692212  0.671875  0.668248\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       3     1  0.538462   0.596361  0.538462  0.415724\n",
            "1   poly  0.1    0.1       3     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.1       3     3  0.753846   0.765816  0.753846  0.747535\n",
            "3   poly  0.1    0.1       3     4  0.630769   0.692308  0.630769  0.579487\n",
            "4   poly  0.1    0.1       3     5  0.707692   0.718781  0.707692  0.698551\n",
            "5   poly  0.1    0.1       3     6  0.800000   0.821429  0.800000  0.793745\n",
            "6   poly  0.1    0.1       3     7  0.876923   0.888837  0.876923  0.874944\n",
            "7   poly  0.1    0.1       3     8  0.692308   0.694653  0.692308  0.687359\n",
            "8   poly  0.1    0.1       3     9  0.584615   0.692550  0.584615  0.540532\n",
            "9   poly  0.1    0.1       3    10  0.687500   0.704706  0.687500  0.685049\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       4     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.1    0.1       4     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.1       4     3  0.753846   0.765816  0.753846  0.747535\n",
            "3   poly  0.1    0.1       4     4  0.630769   0.671263  0.630769  0.589411\n",
            "4   poly  0.1    0.1       4     5  0.692308   0.705128  0.692308  0.680769\n",
            "5   poly  0.1    0.1       4     6  0.800000   0.821429  0.800000  0.793745\n",
            "6   poly  0.1    0.1       4     7  0.846154   0.856473  0.846154  0.843680\n",
            "7   poly  0.1    0.1       4     8  0.646154   0.645385  0.646154  0.641865\n",
            "8   poly  0.1    0.1       4     9  0.630769   0.725128  0.630769  0.603077\n",
            "9   poly  0.1    0.1       4    10  0.687500   0.697917  0.687500  0.686584\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       5     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.1    0.1       5     2  0.661538   0.748252  0.661538  0.614530\n",
            "2   poly  0.1    0.1       5     3  0.738462   0.763246  0.738462  0.726864\n",
            "3   poly  0.1    0.1       5     4  0.615385   0.654753  0.615385  0.567321\n",
            "4   poly  0.1    0.1       5     5  0.692308   0.714130  0.692308  0.676360\n",
            "5   poly  0.1    0.1       5     6  0.784615   0.810256  0.784615  0.776538\n",
            "6   poly  0.1    0.1       5     7  0.830769   0.836923  0.830769  0.828718\n",
            "7   poly  0.1    0.1       5     8  0.630769   0.629925  0.630769  0.624831\n",
            "8   poly  0.1    0.1       5     9  0.615385   0.714932  0.615385  0.582825\n",
            "9   poly  0.1    0.1       5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       1     1  0.584615   0.768474  0.584615  0.483424\n",
            "1   poly  0.1    0.5       1     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.5       1     3  0.769231   0.778707  0.769231  0.764481\n",
            "3   poly  0.1    0.5       1     4  0.630769   0.692308  0.630769  0.579487\n",
            "4   poly  0.1    0.5       1     5  0.738462   0.745819  0.738462  0.733078\n",
            "5   poly  0.1    0.5       1     6  0.815385   0.818540  0.815385  0.813781\n",
            "6   poly  0.1    0.5       1     7  0.907692   0.908821  0.907692  0.907383\n",
            "7   poly  0.1    0.5       1     8  0.661538   0.660750  0.661538  0.658598\n",
            "8   poly  0.1    0.5       1     9  0.600000   0.737374  0.600000  0.552795\n",
            "9   poly  0.1    0.5       1    10  0.640625   0.677291  0.640625  0.630153\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       2     1  0.584615   0.651350  0.584615  0.514624\n",
            "1   poly  0.1    0.5       2     2  0.738462   0.763246  0.738462  0.726864\n",
            "2   poly  0.1    0.5       2     3  0.800000   0.821429  0.800000  0.793745\n",
            "3   poly  0.1    0.5       2     4  0.661538   0.670085  0.661538  0.648846\n",
            "4   poly  0.1    0.5       2     5  0.692308   0.694653  0.692308  0.687359\n",
            "5   poly  0.1    0.5       2     6  0.846154   0.850099  0.846154  0.844817\n",
            "6   poly  0.1    0.5       2     7  0.907692   0.908821  0.907692  0.907383\n",
            "7   poly  0.1    0.5       2     8  0.600000   0.598456  0.600000  0.598659\n",
            "8   poly  0.1    0.5       2     9  0.615385   0.691817  0.615385  0.589992\n",
            "9   poly  0.1    0.5       2    10  0.640625   0.647629  0.640625  0.640186\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       3     1  0.569231   0.585207  0.569231  0.526199\n",
            "1   poly  0.1    0.5       3     2  0.707692   0.709231  0.707692  0.704149\n",
            "2   poly  0.1    0.5       3     3  0.707692   0.707191  0.707692  0.707274\n",
            "3   poly  0.1    0.5       3     4  0.569231   0.565197  0.569231  0.562303\n",
            "4   poly  0.1    0.5       3     5  0.723077   0.723866  0.723077  0.720671\n",
            "5   poly  0.1    0.5       3     6  0.676923   0.680726  0.676923  0.677382\n",
            "6   poly  0.1    0.5       3     7  0.769231   0.773164  0.769231  0.769559\n",
            "7   poly  0.1    0.5       3     8  0.553846   0.549615  0.553846  0.548438\n",
            "8   poly  0.1    0.5       3     9  0.630769   0.703054  0.630769  0.609467\n",
            "9   poly  0.1    0.5       3    10  0.609375   0.625673  0.609375  0.605057\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       4     1  0.553846   0.564417  0.553846  0.503995\n",
            "1   poly  0.1    0.5       4     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.1    0.5       4     3  0.692308   0.691565  0.692308  0.691276\n",
            "3   poly  0.1    0.5       4     4  0.538462   0.532833  0.538462  0.531039\n",
            "4   poly  0.1    0.5       4     5  0.692308   0.691565  0.692308  0.691276\n",
            "5   poly  0.1    0.5       4     6  0.707692   0.708583  0.707692  0.707970\n",
            "6   poly  0.1    0.5       4     7  0.784615   0.790979  0.784615  0.784819\n",
            "7   poly  0.1    0.5       4     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.1    0.5       4     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.1    0.5       4    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       5     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.1    0.5       5     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.1    0.5       5     3  0.738462   0.741154  0.738462  0.735291\n",
            "3   poly  0.1    0.5       5     4  0.523077   0.515608  0.523077  0.513260\n",
            "4   poly  0.1    0.5       5     5  0.707692   0.707377  0.707692  0.706006\n",
            "5   poly  0.1    0.5       5     6  0.738462   0.738064  0.738462  0.738087\n",
            "6   poly  0.1    0.5       5     7  0.769231   0.778388  0.769231  0.769231\n",
            "7   poly  0.1    0.5       5     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.1    0.5       5     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.1    0.5       5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       1     1  0.584615   0.768474  0.584615  0.483424\n",
            "1   poly  0.1      1       1     2  0.676923   0.758612  0.676923  0.636550\n",
            "2   poly  0.1      1       1     3  0.800000   0.805000  0.800000  0.797576\n",
            "3   poly  0.1      1       1     4  0.646154   0.686391  0.646154  0.610779\n",
            "4   poly  0.1      1       1     5  0.738462   0.752997  0.738462  0.730282\n",
            "5   poly  0.1      1       1     6  0.738462   0.745819  0.738462  0.733078\n",
            "6   poly  0.1      1       1     7  0.907692   0.908821  0.907692  0.907383\n",
            "7   poly  0.1      1       1     8  0.661538   0.660750  0.661538  0.658598\n",
            "8   poly  0.1      1       1     9  0.584615   0.781377  0.584615  0.518660\n",
            "9   poly  0.1      1       1    10  0.640625   0.677291  0.640625  0.630153\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       2     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.1      1       2     2  0.723077   0.740171  0.723077  0.712692\n",
            "2   poly  0.1      1       2     3  0.615385   0.616406  0.615385  0.615750\n",
            "3   poly  0.1      1       2     4  0.630769   0.635043  0.630769  0.616923\n",
            "4   poly  0.1      1       2     5  0.661538   0.660529  0.661538  0.660404\n",
            "5   poly  0.1      1       2     6  0.753846   0.753846  0.753846  0.753846\n",
            "6   poly  0.1      1       2     7  0.830769   0.831484  0.830769  0.830930\n",
            "7   poly  0.1      1       2     8  0.630769   0.629492  0.630769  0.629531\n",
            "8   poly  0.1      1       2     9  0.584615   0.648744  0.584615  0.557191\n",
            "9   poly  0.1      1       2    10  0.656250   0.665923  0.656250  0.655242\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       3     1  0.584615   0.604029  0.584615  0.547692\n",
            "1   poly  0.1      1       3     2  0.753846   0.759381  0.753846  0.749888\n",
            "2   poly  0.1      1       3     3  0.692308   0.692308  0.692308  0.692308\n",
            "3   poly  0.1      1       3     4  0.523077   0.519793  0.523077  0.520326\n",
            "4   poly  0.1      1       3     5  0.676923   0.676113  0.676923  0.675060\n",
            "5   poly  0.1      1       3     6  0.676923   0.680726  0.676923  0.677382\n",
            "6   poly  0.1      1       3     7  0.815385   0.817453  0.815385  0.815647\n",
            "7   poly  0.1      1       3     8  0.553846   0.549615  0.553846  0.548438\n",
            "8   poly  0.1      1       3     9  0.630769   0.703054  0.630769  0.609467\n",
            "9   poly  0.1      1       3    10  0.593750   0.601935  0.593750  0.592559\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       4     1  0.553846   0.564417  0.553846  0.503995\n",
            "1   poly  0.1      1       4     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.1      1       4     3  0.692308   0.691565  0.692308  0.691276\n",
            "3   poly  0.1      1       4     4  0.538462   0.532833  0.538462  0.531039\n",
            "4   poly  0.1      1       4     5  0.692308   0.691565  0.692308  0.691276\n",
            "5   poly  0.1      1       4     6  0.707692   0.708583  0.707692  0.707970\n",
            "6   poly  0.1      1       4     7  0.784615   0.790979  0.784615  0.784819\n",
            "7   poly  0.1      1       4     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.1      1       4     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.1      1       4    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       5     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.1      1       5     2  0.692308   0.705128  0.692308  0.680769\n",
            "2   poly  0.1      1       5     3  0.738462   0.741154  0.738462  0.735291\n",
            "3   poly  0.1      1       5     4  0.523077   0.515608  0.523077  0.513260\n",
            "4   poly  0.1      1       5     5  0.707692   0.707377  0.707692  0.706006\n",
            "5   poly  0.1      1       5     6  0.738462   0.738064  0.738462  0.738087\n",
            "6   poly  0.1      1       5     7  0.769231   0.778388  0.769231  0.769231\n",
            "7   poly  0.1      1       5     8  0.553846   0.551057  0.553846  0.551273\n",
            "8   poly  0.1      1       5     9  0.600000   0.661765  0.600000  0.576923\n",
            "9   poly  0.1      1       5    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "Média dos resultados do kernel poly\n",
            "   kernel      c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
            "0    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "1    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "2    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "3    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "4    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "5    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "6    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "7    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "8    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "9    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "10   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "11   poly  0.001  0.500  ...       0.645657    0.628702    0.557605\n",
            "12   poly  0.001  0.500  ...       0.728246    0.688750    0.658304\n",
            "13   poly  0.001  0.500  ...       0.708446    0.690264    0.675211\n",
            "14   poly  0.001  0.500  ...       0.663156    0.654880    0.644915\n",
            "15   poly  0.001  1.000  ...       0.287536    0.536202    0.374329\n",
            "16   poly  0.001  1.000  ...       0.732740    0.693341    0.662334\n",
            "17   poly  0.001  1.000  ...       0.731985    0.710240    0.696639\n",
            "18   poly  0.001  1.000  ...       0.653500    0.644062    0.634190\n",
            "19   poly  0.001  1.000  ...       0.661634    0.653341    0.643467\n",
            "20   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "21   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "22   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "23   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "24   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "25   poly  0.100  0.100  ...       0.743836    0.690216    0.657232\n",
            "26   poly  0.100  0.100  ...       0.732740    0.693341    0.662334\n",
            "27   poly  0.100  0.100  ...       0.731262    0.691827    0.661464\n",
            "28   poly  0.100  0.100  ...       0.738494    0.688750    0.660288\n",
            "29   poly  0.100  0.100  ...       0.731098    0.679495    0.649396\n",
            "30   poly  0.100  0.500  ...       0.752526    0.699447    0.671490\n",
            "31   poly  0.100  0.500  ...       0.729758    0.708678    0.695248\n",
            "32   poly  0.100  0.500  ...       0.662292    0.651707    0.643050\n",
            "33   poly  0.100  0.500  ...       0.655929    0.647163    0.637559\n",
            "34   poly  0.100  0.500  ...       0.661634    0.653341    0.643467\n",
            "35   poly  0.100  1.000  ...       0.754553    0.697909    0.670648\n",
            "36   poly  0.100  1.000  ...       0.672010    0.662548    0.652487\n",
            "37   poly  0.100  1.000  ...       0.660441    0.650144    0.642877\n",
            "38   poly  0.100  1.000  ...       0.655929    0.647163    0.637559\n",
            "39   poly  0.100  1.000  ...       0.661634    0.653341    0.643467\n",
            "\n",
            "[40 rows x 8 columns]\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.1     1  0.523077   0.512454  0.523077  0.384812\n",
            "1    rbf  0.1    0.1     2  0.615385   0.711254  0.615385  0.543402\n",
            "2    rbf  0.1    0.1     3  0.707692   0.755385  0.707692  0.684766\n",
            "3    rbf  0.1    0.1     4  0.584615   0.636036  0.584615  0.506874\n",
            "4    rbf  0.1    0.1     5  0.630769   0.646978  0.630769  0.605351\n",
            "5    rbf  0.1    0.1     6  0.815385   0.845299  0.815385  0.808462\n",
            "6    rbf  0.1    0.1     7  0.830769   0.871237  0.830769  0.823265\n",
            "7    rbf  0.1    0.1     8  0.661538   0.686813  0.661538  0.638239\n",
            "8    rbf  0.1    0.1     9  0.692308   0.744755  0.692308  0.682952\n",
            "9    rbf  0.1    0.1    10  0.671875   0.672685  0.671875  0.672116\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "Média dos resultados do kernel rbf\n",
            "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
            "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "5    rbf  0.100  0.100      0.673341       0.708290    0.673341    0.635024\n",
            "6    rbf  0.100  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "7    rbf  0.100  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvbAxtIYXYdl",
        "colab_type": "code",
        "outputId": "8c0a58b2-09cd-4301-f623-f8e430059044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel Linear\n",
        "print(ic_linear_all)\n",
        "result_linear_all = result_linear_all.rename(index={result_linear_all.index[0]:'All Features'})\n",
        "result_linear_all"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.625931      0.702986   0.625931   0.580070\n",
            "sup     0.769886      0.806120   0.769886   0.761227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.754553</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.670648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "All Features  linear  0.1      0.697909       0.754553    0.697909    0.670648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XBSlfCtXYdp",
        "colab_type": "code",
        "outputId": "48400b97-6699-47d6-d096-a877113359b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel Polynomial\n",
        "print(ic_poly_all)\n",
        "result_poly_all = result_poly_all.rename(index={result_poly_all.index[0]:'All Features'})\n",
        "result_poly_all"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.634177      0.664784   0.634177   0.611885\n",
            "sup     0.786304      0.799185   0.786304   0.781393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.71024</td>\n",
              "      <td>0.731985</td>\n",
              "      <td>0.71024</td>\n",
              "      <td>0.696639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             kernel      c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "All Features   poly  0.001    1.0  ...       0.731985     0.71024    0.696639\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai5JE1lgXYdt",
        "colab_type": "code",
        "outputId": "b14848e6-1f1e-4e89-a641-544c207f8406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do Kernel RBF\n",
        "print(ic_rbf_all)\n",
        "result_rbf_all = result_rbf_all.rename(index={result_rbf_all.index[0]:'All Features'})\n",
        "result_rbf_all"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.604949      0.633665   0.604949   0.539650\n",
            "sup     0.741734      0.782914   0.741734   0.730398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.70829</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.635024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "All Features    rbf  0.1    0.1  ...        0.70829    0.673341    0.635024\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAvBSpgoXYdy",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. SVM: PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "USU96y9LXYdy",
        "colab_type": "code",
        "outputId": "14f72ce1-7374-4d85-c839-15d6570eccf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "df = pd.read_csv('results/dataset-pca.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "\n",
        "result_linear_pca, result_poly_pca, result_rbf_pca, ic_linear_pca, ic_poly_pca, ic_rbf_pca = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, list_coef, dataSet='PCA')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "   kernel      c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "   kernel    c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.1     1  0.584615   0.768474  0.584615  0.483424\n",
            "1  linear  0.1     2  0.646154   0.706682  0.646154  0.601935\n",
            "2  linear  0.1     3  0.769231   0.773077  0.769231  0.766434\n",
            "3  linear  0.1     4  0.569231   0.569920  0.569231  0.530981\n",
            "4  linear  0.1     5  0.707692   0.712932  0.707692  0.701676\n",
            "5  linear  0.1     6  0.830769   0.830681  0.830769  0.830527\n",
            "6  linear  0.1     7  0.876923   0.876923  0.876923  0.876923\n",
            "7  linear  0.1     8  0.738462   0.738064  0.738462  0.738087\n",
            "8  linear  0.1     9  0.600000   0.704142  0.600000  0.561992\n",
            "9  linear  0.1    10  0.671875   0.701584  0.671875  0.665632\n",
            "\n",
            "Média dos resultados do kernel linear\n",
            "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1  linear  0.100      0.699495       0.738248    0.699495    0.675761\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       5     4  0.553846   0.756010  0.553846  0.410507\n",
            "4   poly  0.001    0.5       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       5     6  0.569231   0.760684  0.569231  0.442308\n",
            "6   poly  0.001    0.5       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       5     8  0.553846   0.756010  0.553846  0.410507\n",
            "8   poly  0.001    0.5       5     9  0.507692   0.282051  0.507692  0.362637\n",
            "9   poly  0.001    0.5       5    10  0.546875   0.599898  0.546875  0.425897\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001      1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001      1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001      1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001      1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001      1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001      1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001      1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001      1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       3     1  0.538462   0.754808  0.538462  0.392759\n",
            "1   poly  0.001      1       3     2  0.584615   0.765509  0.584615  0.472497\n",
            "2   poly  0.001      1       3     3  0.630769   0.725034  0.630769  0.568034\n",
            "3   poly  0.001      1       3     4  0.569231   0.646280  0.569231  0.462858\n",
            "4   poly  0.001      1       3     5  0.600000   0.657895  0.600000  0.532037\n",
            "5   poly  0.001      1       3     6  0.707692   0.778107  0.707692  0.678469\n",
            "6   poly  0.001      1       3     7  0.800000   0.854167  0.800000  0.788003\n",
            "7   poly  0.001      1       3     8  0.630769   0.671263  0.630769  0.589411\n",
            "8   poly  0.001      1       3     9  0.676923   0.676319  0.676923  0.676460\n",
            "9   poly  0.001      1       3    10  0.656250   0.657813  0.656250  0.651089\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       4     1  0.523077   0.512454  0.523077  0.384812\n",
            "1   poly  0.001      1       4     2  0.584615   0.674359  0.584615  0.490920\n",
            "2   poly  0.001      1       4     3  0.630769   0.639935  0.630769  0.611632\n",
            "3   poly  0.001      1       4     4  0.584615   0.615385  0.584615  0.520710\n",
            "4   poly  0.001      1       4     5  0.553846   0.547263  0.553846  0.534062\n",
            "5   poly  0.001      1       4     6  0.676923   0.713846  0.676923  0.651584\n",
            "6   poly  0.001      1       4     7  0.707692   0.712932  0.707692  0.701676\n",
            "7   poly  0.001      1       4     8  0.600000   0.607143  0.600000  0.572464\n",
            "8   poly  0.001      1       4     9  0.630769   0.640584  0.630769  0.630245\n",
            "9   poly  0.001      1       4    10  0.687500   0.695076  0.687500  0.679909\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       5     1  0.492308   0.444973  0.492308  0.406762\n",
            "1   poly  0.001      1       5     2  0.584615   0.636036  0.584615  0.506874\n",
            "2   poly  0.001      1       5     3  0.661538   0.665311  0.661538  0.652860\n",
            "3   poly  0.001      1       5     4  0.600000   0.636364  0.600000  0.544444\n",
            "4   poly  0.001      1       5     5  0.600000   0.597561  0.600000  0.593567\n",
            "5   poly  0.001      1       5     6  0.692308   0.691565  0.692308  0.691276\n",
            "6   poly  0.001      1       5     7  0.769231   0.770034  0.769231  0.769450\n",
            "7   poly  0.001      1       5     8  0.523077   0.511266  0.523077  0.501928\n",
            "8   poly  0.001      1       5     9  0.630769   0.685971  0.630769  0.614935\n",
            "9   poly  0.001      1       5    10  0.656250   0.658203  0.656250  0.656586\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       1     1  0.538462   0.596361  0.538462  0.415724\n",
            "1   poly  0.1    0.1       1     2  0.630769   0.725034  0.630769  0.568034\n",
            "2   poly  0.1    0.1       1     3  0.707692   0.718781  0.707692  0.698551\n",
            "3   poly  0.1    0.1       1     4  0.538462   0.523617  0.538462  0.460042\n",
            "4   poly  0.1    0.1       1     5  0.615385   0.623963  0.615385  0.592314\n",
            "5   poly  0.1    0.1       1     6  0.846154   0.856473  0.846154  0.843680\n",
            "6   poly  0.1    0.1       1     7  0.907692   0.913215  0.907692  0.906890\n",
            "7   poly  0.1    0.1       1     8  0.784615   0.786982  0.784615  0.782744\n",
            "8   poly  0.1    0.1       1     9  0.676923   0.753592  0.676923  0.660773\n",
            "9   poly  0.1    0.1       1    10  0.656250   0.671938  0.656250  0.653554\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.5       1     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.5       1     3  0.769231   0.773077  0.769231  0.766434\n",
            "3   poly  0.1    0.5       1     4  0.615385   0.630769  0.615385  0.585219\n",
            "4   poly  0.1    0.5       1     5  0.676923   0.680045  0.676923  0.670273\n",
            "5   poly  0.1    0.5       1     6  0.830769   0.830681  0.830769  0.830527\n",
            "6   poly  0.1    0.5       1     7  0.876923   0.877784  0.876923  0.876510\n",
            "7   poly  0.1    0.5       1     8  0.784615   0.784675  0.784615  0.783893\n",
            "8   poly  0.1    0.5       1     9  0.646154   0.762443  0.646154  0.616199\n",
            "9   poly  0.1    0.5       1    10  0.609375   0.632523  0.609375  0.601943\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       2     1  0.507692   0.488008  0.507692  0.446420\n",
            "1   poly  0.1    0.5       2     2  0.676923   0.732249  0.676923  0.644624\n",
            "2   poly  0.1    0.5       2     3  0.569231   0.564807  0.569231  0.558185\n",
            "3   poly  0.1    0.5       2     4  0.600000   0.607143  0.600000  0.572464\n",
            "4   poly  0.1    0.5       2     5  0.492308   0.493505  0.492308  0.492790\n",
            "5   poly  0.1    0.5       2     6  0.707692   0.707191  0.707692  0.707274\n",
            "6   poly  0.1    0.5       2     7  0.676923   0.677857  0.676923  0.677230\n",
            "7   poly  0.1    0.5       2     8  0.600000   0.605313  0.600000  0.600379\n",
            "8   poly  0.1    0.5       2     9  0.615385   0.622711  0.615385  0.615385\n",
            "9   poly  0.1    0.5       2    10  0.609375   0.608713  0.609375  0.608895\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       3     1  0.476923   0.420513  0.476923  0.397009\n",
            "1   poly  0.1    0.5       3     2  0.553846   0.554487  0.553846  0.485207\n",
            "2   poly  0.1    0.5       3     3  0.676923   0.677308  0.676923  0.673007\n",
            "3   poly  0.1    0.5       3     4  0.600000   0.600000  0.600000  0.585000\n",
            "4   poly  0.1    0.5       3     5  0.584615   0.582321  0.584615  0.582220\n",
            "5   poly  0.1    0.5       3     6  0.738462   0.738064  0.738462  0.738087\n",
            "6   poly  0.1    0.5       3     7  0.676923   0.690748  0.676923  0.675852\n",
            "7   poly  0.1    0.5       3     8  0.569231   0.567419  0.569231  0.567787\n",
            "8   poly  0.1    0.5       3     9  0.646154   0.713857  0.646154  0.628466\n",
            "9   poly  0.1    0.5       3    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       4     1  0.446154   0.398225  0.446154  0.390828\n",
            "1   poly  0.1    0.5       4     2  0.615385   0.630769  0.615385  0.585219\n",
            "2   poly  0.1    0.5       4     3  0.553846   0.547702  0.553846  0.539893\n",
            "3   poly  0.1    0.5       4     4  0.553846   0.548817  0.553846  0.509243\n",
            "4   poly  0.1    0.5       4     5  0.538462   0.536383  0.538462  0.536914\n",
            "5   poly  0.1    0.5       4     6  0.615385   0.613585  0.615385  0.613166\n",
            "6   poly  0.1    0.5       4     7  0.615385   0.619100  0.615385  0.615931\n",
            "7   poly  0.1    0.5       4     8  0.461538   0.449833  0.461538  0.450455\n",
            "8   poly  0.1    0.5       4     9  0.646154   0.674015  0.646154  0.640579\n",
            "9   poly  0.1    0.5       4    10  0.578125   0.584206  0.578125  0.577610\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       5     1  0.507692   0.482845  0.507692  0.432479\n",
            "1   poly  0.1    0.5       5     2  0.615385   0.676282  0.615385  0.556213\n",
            "2   poly  0.1    0.5       5     3  0.630769   0.629925  0.630769  0.624831\n",
            "3   poly  0.1    0.5       5     4  0.646154   0.686391  0.646154  0.610779\n",
            "4   poly  0.1    0.5       5     5  0.600000   0.597561  0.600000  0.593567\n",
            "5   poly  0.1    0.5       5     6  0.692308   0.691565  0.692308  0.691276\n",
            "6   poly  0.1    0.5       5     7  0.753846   0.755973  0.753846  0.754196\n",
            "7   poly  0.1    0.5       5     8  0.523077   0.511266  0.523077  0.501928\n",
            "8   poly  0.1    0.5       5     9  0.646154   0.697436  0.646154  0.633287\n",
            "9   poly  0.1    0.5       5    10  0.640625   0.647629  0.640625  0.640186\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       1     1  0.584615   0.768474  0.584615  0.483424\n",
            "1   poly  0.1      1       1     2  0.646154   0.706682  0.646154  0.601935\n",
            "2   poly  0.1      1       1     3  0.769231   0.773077  0.769231  0.766434\n",
            "3   poly  0.1      1       1     4  0.569231   0.569920  0.569231  0.530981\n",
            "4   poly  0.1      1       1     5  0.707692   0.712932  0.707692  0.701676\n",
            "5   poly  0.1      1       1     6  0.830769   0.830681  0.830769  0.830527\n",
            "6   poly  0.1      1       1     7  0.876923   0.876923  0.876923  0.876923\n",
            "7   poly  0.1      1       1     8  0.738462   0.738064  0.738462  0.738087\n",
            "8   poly  0.1      1       1     9  0.600000   0.704142  0.600000  0.561992\n",
            "9   poly  0.1      1       1    10  0.671875   0.701584  0.671875  0.665632\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       2     1  0.476923   0.452308  0.476923  0.435770\n",
            "1   poly  0.1      1       2     2  0.676923   0.700698  0.676923  0.657543\n",
            "2   poly  0.1      1       2     3  0.569231   0.565197  0.569231  0.562303\n",
            "3   poly  0.1      1       2     4  0.661538   0.662289  0.661538  0.656095\n",
            "4   poly  0.1      1       2     5  0.584615   0.585681  0.584615  0.585010\n",
            "5   poly  0.1      1       2     6  0.707692   0.716117  0.707692  0.707692\n",
            "6   poly  0.1      1       2     7  0.738462   0.738064  0.738462  0.738087\n",
            "7   poly  0.1      1       2     8  0.630769   0.636257  0.630769  0.631119\n",
            "8   poly  0.1      1       2     9  0.630769   0.646124  0.630769  0.628667\n",
            "9   poly  0.1      1       2    10  0.593750   0.598407  0.593750  0.593750\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       3     1  0.538462   0.536821  0.538462  0.502150\n",
            "1   poly  0.1      1       3     2  0.661538   0.686813  0.661538  0.638239\n",
            "2   poly  0.1      1       3     3  0.676923   0.676319  0.676923  0.676460\n",
            "3   poly  0.1      1       3     4  0.538462   0.529915  0.538462  0.521154\n",
            "4   poly  0.1      1       3     5  0.600000   0.598456  0.600000  0.598659\n",
            "5   poly  0.1      1       3     6  0.630769   0.640584  0.630769  0.630245\n",
            "6   poly  0.1      1       3     7  0.646154   0.653846  0.646154  0.646154\n",
            "7   poly  0.1      1       3     8  0.584615   0.582321  0.584615  0.582220\n",
            "8   poly  0.1      1       3     9  0.584615   0.667421  0.584615  0.549451\n",
            "9   poly  0.1      1       3    10  0.578125   0.587869  0.578125  0.575957\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       4     1  0.446154   0.398225  0.446154  0.390828\n",
            "1   poly  0.1      1       4     2  0.615385   0.623963  0.615385  0.592314\n",
            "2   poly  0.1      1       4     3  0.553846   0.547702  0.553846  0.539893\n",
            "3   poly  0.1      1       4     4  0.584615   0.589231  0.584615  0.552036\n",
            "4   poly  0.1      1       4     5  0.507692   0.505346  0.507692  0.506042\n",
            "5   poly  0.1      1       4     6  0.615385   0.614574  0.615385  0.614834\n",
            "6   poly  0.1      1       4     7  0.646154   0.653846  0.646154  0.646154\n",
            "7   poly  0.1      1       4     8  0.461538   0.449833  0.461538  0.450455\n",
            "8   poly  0.1      1       4     9  0.600000   0.636364  0.600000  0.587838\n",
            "9   poly  0.1      1       4    10  0.609375   0.612628  0.609375  0.609661\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       5     1  0.507692   0.482845  0.507692  0.432479\n",
            "1   poly  0.1      1       5     2  0.630769   0.692308  0.630769  0.579487\n",
            "2   poly  0.1      1       5     3  0.630769   0.629925  0.630769  0.624831\n",
            "3   poly  0.1      1       5     4  0.615385   0.640533  0.615385  0.576933\n",
            "4   poly  0.1      1       5     5  0.600000   0.597561  0.600000  0.593567\n",
            "5   poly  0.1      1       5     6  0.692308   0.691565  0.692308  0.691276\n",
            "6   poly  0.1      1       5     7  0.707692   0.711538  0.707692  0.708108\n",
            "7   poly  0.1      1       5     8  0.523077   0.511266  0.523077  0.501928\n",
            "8   poly  0.1      1       5     9  0.600000   0.647597  0.600000  0.582846\n",
            "9   poly  0.1      1       5    10  0.640625   0.647629  0.640625  0.640186\n",
            "\n",
            "Média dos resultados do kernel poly\n",
            "   kernel      c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
            "0    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "1    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "2    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "3    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "4    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "5    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "6    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "7    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "8    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "9    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "10   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "11   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "12   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "13   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "14   poly  0.001  0.500  ...       0.458802    0.540841    0.391883\n",
            "15   poly  0.001  1.000  ...       0.287536    0.536202    0.374329\n",
            "16   poly  0.001  1.000  ...       0.287536    0.536202    0.374329\n",
            "17   poly  0.001  1.000  ...       0.718719    0.639471    0.581162\n",
            "18   poly  0.001  1.000  ...       0.635898    0.617981    0.577801\n",
            "19   poly  0.001  1.000  ...       0.629728    0.621010    0.593868\n",
            "20   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "21   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "22   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "23   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "24   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "25   poly  0.100  0.100  ...       0.716996    0.690240    0.658231\n",
            "26   poly  0.100  0.100  ...       0.287536    0.536202    0.374329\n",
            "27   poly  0.100  0.100  ...       0.287536    0.536202    0.374329\n",
            "28   poly  0.100  0.100  ...       0.287536    0.536202    0.374329\n",
            "29   poly  0.100  0.100  ...       0.287536    0.536202    0.374329\n",
            "30   poly  0.100  0.500  ...       0.734984    0.700937    0.676787\n",
            "31   poly  0.100  0.500  ...       0.610750    0.605553    0.592365\n",
            "32   poly  0.100  0.500  ...       0.620611    0.617933    0.598888\n",
            "33   poly  0.100  0.500  ...       0.560263    0.562428    0.545984\n",
            "34   poly  0.100  0.500  ...       0.637687    0.625601    0.603874\n",
            "35   poly  0.100  1.000  ...       0.738248    0.699495    0.675761\n",
            "36   poly  0.100  1.000  ...       0.630114    0.627067    0.619604\n",
            "37   poly  0.100  1.000  ...       0.616036    0.603966    0.592069\n",
            "38   poly  0.100  1.000  ...       0.563171    0.564014    0.549005\n",
            "39   poly  0.100  1.000  ...       0.625277    0.614832    0.593164\n",
            "\n",
            "[40 rows x 8 columns]\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.1     1  0.523077   0.512454  0.523077  0.384812\n",
            "1    rbf  0.1    0.1     2  0.661538   0.748252  0.661538  0.614530\n",
            "2    rbf  0.1    0.1     3  0.692308   0.705128  0.692308  0.680769\n",
            "3    rbf  0.1    0.1     4  0.553846   0.550894  0.553846  0.498092\n",
            "4    rbf  0.1    0.1     5  0.600000   0.600000  0.600000  0.585000\n",
            "5    rbf  0.1    0.1     6  0.830769   0.844482  0.830769  0.827286\n",
            "6    rbf  0.1    0.1     7  0.892308   0.910256  0.892308  0.890091\n",
            "7    rbf  0.1    0.1     8  0.738462   0.745819  0.738462  0.733078\n",
            "8    rbf  0.1    0.1     9  0.676923   0.734615  0.676923  0.665175\n",
            "9    rbf  0.1    0.1    10  0.671875   0.684904  0.671875  0.670189\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "Média dos resultados do kernel rbf\n",
            "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
            "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "5    rbf  0.100  0.100      0.684111       0.703680    0.684111    0.654902\n",
            "6    rbf  0.100  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "7    rbf  0.100  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8XhR4AKXYd6",
        "colab_type": "code",
        "outputId": "9d5c2d77-fc90-4fe6-ecba-55b383076354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel Linear\n",
        "print(ic_linear_pca)\n",
        "result_linear_pca = result_linear_pca.rename(index={result_linear_pca.index[0]:'PCA'})\n",
        "result_linear_pca"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf      0.62453      0.678692    0.62453   0.582293\n",
            "sup      0.77446      0.797804    0.77446   0.769229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.738248</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.675761</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "PCA  linear  0.1      0.699495       0.738248    0.699495    0.675761"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q--RHDuYXYd-",
        "colab_type": "code",
        "outputId": "3c03c492-3d57-4335-e211-d17aaacdd32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel poly\n",
        "print(ic_poly_pca)\n",
        "result_poly_pca = result_poly_pca.rename(index={result_poly_pca.index[0]:'PCA'})\n",
        "result_poly_pca"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.624257      0.673032   0.624257   0.580924\n",
            "sup     0.777618      0.796937   0.777618   0.772650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.734984</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.676787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "PCA   poly  0.1    0.5  ...       0.734984    0.700937    0.676787\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8YRx2dOXYeC",
        "colab_type": "code",
        "outputId": "f2b36cc5-8e82-48e3-8912-0ff3709ec12d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel rbf\n",
        "print(ic_rbf_pca)\n",
        "result_rbf_pca = result_rbf_pca.rename(index={result_rbf_pca.index[0]:'PCA'})\n",
        "result_rbf_pca"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.602005      0.615024   0.602005   0.549280\n",
            "sup     0.766217      0.792336   0.766217   0.760524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.70368</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.654902</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    kernel    c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "PCA    rbf  0.1    0.1      0.684111        0.70368    0.684111    0.654902"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ10y9FEXYeI",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. SVM: Chi Squared (k-Best)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNe5wTvZXYeJ",
        "colab_type": "code",
        "outputId": "65e2da2f-bb05-463e-8b44-dbd628778c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = pd.read_csv('results/dataset-fs-chi-squared.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "\n",
        "result_linear_chi, result_poly_chi, result_rbf_chi, ic_linear_chi, ic_poly_chi, ic_rbf_chi = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, list_coef, dataSet='chi')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "   kernel      c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "   kernel    c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  linear  0.1     2  0.646154   0.706682  0.646154  0.601935\n",
            "2  linear  0.1     3  0.815385   0.824109  0.815385  0.812416\n",
            "3  linear  0.1     4  0.646154   0.686391  0.646154  0.610779\n",
            "4  linear  0.1     5  0.723077   0.740171  0.723077  0.712692\n",
            "5  linear  0.1     6  0.830769   0.844482  0.830769  0.827286\n",
            "6  linear  0.1     7  0.938462   0.939857  0.938462  0.938255\n",
            "7  linear  0.1     8  0.630769   0.629925  0.630769  0.624831\n",
            "8  linear  0.1     9  0.569231   0.717643  0.569231  0.507074\n",
            "9  linear  0.1    10  0.656250   0.717844  0.656250  0.639550\n",
            "\n",
            "Média dos resultados do kernel linear\n",
            "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1  linear  0.100      0.701010       0.744777    0.701010    0.671998\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       3     3  0.553846   0.756010  0.553846  0.410507\n",
            "3   poly  0.001    0.5       3     4  0.553846   0.756010  0.553846  0.410507\n",
            "4   poly  0.001    0.5       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       3     6  0.615385   0.775641  0.615385  0.528629\n",
            "6   poly  0.001    0.5       3     7  0.584615   0.765509  0.584615  0.472497\n",
            "7   poly  0.001    0.5       3     8  0.584615   0.765509  0.584615  0.472497\n",
            "8   poly  0.001    0.5       3     9  0.600000   0.622642  0.600000  0.555195\n",
            "9   poly  0.001    0.5       3    10  0.578125   0.633067  0.578125  0.500316\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       4     2  0.538462   0.521368  0.538462  0.402473\n",
            "2   poly  0.001    0.5       4     3  0.600000   0.770492  0.600000  0.501225\n",
            "3   poly  0.001    0.5       4     4  0.538462   0.521368  0.538462  0.402473\n",
            "4   poly  0.001    0.5       4     5  0.553846   0.602978  0.553846  0.433422\n",
            "5   poly  0.001    0.5       4     6  0.676923   0.798077  0.676923  0.627219\n",
            "6   poly  0.001    0.5       4     7  0.692308   0.804196  0.692308  0.649573\n",
            "7   poly  0.001    0.5       4     8  0.615385   0.676282  0.615385  0.556213\n",
            "8   poly  0.001    0.5       4     9  0.646154   0.647157  0.646154  0.638871\n",
            "9   poly  0.001    0.5       4    10  0.640625   0.658675  0.640625  0.619763\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       5     2  0.569231   0.646280  0.569231  0.462858\n",
            "2   poly  0.001    0.5       5     3  0.600000   0.770492  0.600000  0.501225\n",
            "3   poly  0.001    0.5       5     4  0.538462   0.521368  0.538462  0.402473\n",
            "4   poly  0.001    0.5       5     5  0.538462   0.522068  0.538462  0.424491\n",
            "5   poly  0.001    0.5       5     6  0.723077   0.817126  0.723077  0.692058\n",
            "6   poly  0.001    0.5       5     7  0.753846   0.831071  0.753846  0.731989\n",
            "7   poly  0.001    0.5       5     8  0.646154   0.706682  0.646154  0.601935\n",
            "8   poly  0.001    0.5       5     9  0.661538   0.660529  0.661538  0.660404\n",
            "9   poly  0.001    0.5       5    10  0.703125   0.709272  0.703125  0.697374\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       2     2  0.553846   0.602978  0.553846  0.433422\n",
            "2   poly  0.001      1       2     3  0.600000   0.694915  0.600000  0.517730\n",
            "3   poly  0.001      1       2     4  0.538462   0.521368  0.538462  0.402473\n",
            "4   poly  0.001      1       2     5  0.553846   0.560818  0.553846  0.470346\n",
            "5   poly  0.001      1       2     6  0.723077   0.817126  0.723077  0.692058\n",
            "6   poly  0.001      1       2     7  0.738462   0.823964  0.738462  0.712315\n",
            "7   poly  0.001      1       2     8  0.630769   0.692308  0.630769  0.579487\n",
            "8   poly  0.001      1       2     9  0.753846   0.753638  0.753846  0.753021\n",
            "9   poly  0.001      1       2    10  0.671875   0.671453  0.671875  0.670172\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       3     1  0.538462   0.754808  0.538462  0.392759\n",
            "1   poly  0.001      1       3     2  0.584615   0.674359  0.584615  0.490920\n",
            "2   poly  0.001      1       3     3  0.646154   0.686391  0.646154  0.610779\n",
            "3   poly  0.001      1       3     4  0.569231   0.646280  0.569231  0.462858\n",
            "4   poly  0.001      1       3     5  0.569231   0.608866  0.569231  0.480633\n",
            "5   poly  0.001      1       3     6  0.800000   0.854167  0.800000  0.788003\n",
            "6   poly  0.001      1       3     7  0.846154   0.880342  0.846154  0.840385\n",
            "7   poly  0.001      1       3     8  0.630769   0.635043  0.630769  0.616923\n",
            "8   poly  0.001      1       3     9  0.707692   0.754838  0.707692  0.700386\n",
            "9   poly  0.001      1       3    10  0.703125   0.706653  0.703125  0.703342\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       4     1  0.523077   0.512454  0.523077  0.384812\n",
            "1   poly  0.001      1       4     2  0.600000   0.694915  0.600000  0.517730\n",
            "2   poly  0.001      1       4     3  0.753846   0.806319  0.753846  0.736901\n",
            "3   poly  0.001      1       4     4  0.553846   0.573077  0.553846  0.453210\n",
            "4   poly  0.001      1       4     5  0.584615   0.615385  0.584615  0.520710\n",
            "5   poly  0.001      1       4     6  0.769231   0.787213  0.769231  0.762014\n",
            "6   poly  0.001      1       4     7  0.846154   0.856473  0.846154  0.843680\n",
            "7   poly  0.001      1       4     8  0.630769   0.639935  0.630769  0.611632\n",
            "8   poly  0.001      1       4     9  0.661538   0.708625  0.661538  0.651247\n",
            "9   poly  0.001      1       4    10  0.656250   0.661397  0.656250  0.656250\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       5     1  0.553846   0.601651  0.553846  0.463085\n",
            "1   poly  0.001      1       5     2  0.646154   0.706682  0.646154  0.601935\n",
            "2   poly  0.001      1       5     3  0.723077   0.727017  0.723077  0.718623\n",
            "3   poly  0.001      1       5     4  0.553846   0.573077  0.553846  0.453210\n",
            "4   poly  0.001      1       5     5  0.507692   0.487637  0.507692  0.473802\n",
            "5   poly  0.001      1       5     6  0.738462   0.741154  0.738462  0.735291\n",
            "6   poly  0.001      1       5     7  0.800000   0.801170  0.800000  0.798846\n",
            "7   poly  0.001      1       5     8  0.615385   0.613585  0.615385  0.613166\n",
            "8   poly  0.001      1       5     9  0.676923   0.734615  0.676923  0.665175\n",
            "9   poly  0.001      1       5    10  0.671875   0.675312  0.671875  0.672115\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.1       1     2  0.630769   0.725034  0.630769  0.568034\n",
            "2   poly  0.1    0.1       1     3  0.738462   0.777432  0.738462  0.722773\n",
            "3   poly  0.1    0.1       1     4  0.600000   0.657895  0.600000  0.532037\n",
            "4   poly  0.1    0.1       1     5  0.615385   0.619257  0.615385  0.598329\n",
            "5   poly  0.1    0.1       1     6  0.815385   0.845299  0.815385  0.808462\n",
            "6   poly  0.1    0.1       1     7  0.892308   0.910256  0.892308  0.890091\n",
            "7   poly  0.1    0.1       1     8  0.738462   0.738641  0.738462  0.736953\n",
            "8   poly  0.1    0.1       1     9  0.676923   0.753592  0.676923  0.660773\n",
            "9   poly  0.1    0.1       1    10  0.687500   0.692892  0.687500  0.687500\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       2     2  0.553846   0.602978  0.553846  0.433422\n",
            "2   poly  0.1    0.1       2     3  0.600000   0.694915  0.600000  0.517730\n",
            "3   poly  0.1    0.1       2     4  0.538462   0.521368  0.538462  0.402473\n",
            "4   poly  0.1    0.1       2     5  0.553846   0.560818  0.553846  0.470346\n",
            "5   poly  0.1    0.1       2     6  0.723077   0.817126  0.723077  0.692058\n",
            "6   poly  0.1    0.1       2     7  0.738462   0.823964  0.738462  0.712315\n",
            "7   poly  0.1    0.1       2     8  0.630769   0.692308  0.630769  0.579487\n",
            "8   poly  0.1    0.1       2     9  0.753846   0.753638  0.753846  0.753021\n",
            "9   poly  0.1    0.1       2    10  0.671875   0.671453  0.671875  0.670172\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       3     3  0.553846   0.756010  0.553846  0.410507\n",
            "3   poly  0.1    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       3     6  0.600000   0.770492  0.600000  0.501225\n",
            "6   poly  0.1    0.1       3     7  0.553846   0.756010  0.553846  0.410507\n",
            "7   poly  0.1    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       3     9  0.553846   0.573077  0.553846  0.453210\n",
            "9   poly  0.1    0.1       3    10  0.546875   0.599898  0.546875  0.425897\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       4     9  0.553846   0.756010  0.553846  0.410507\n",
            "9   poly  0.1    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.5       1     2  0.630769   0.725034  0.630769  0.568034\n",
            "2   poly  0.1    0.5       1     3  0.800000   0.811594  0.800000  0.795883\n",
            "3   poly  0.1    0.5       1     4  0.630769   0.671263  0.630769  0.589411\n",
            "4   poly  0.1    0.5       1     5  0.723077   0.740171  0.723077  0.712692\n",
            "5   poly  0.1    0.5       1     6  0.846154   0.856473  0.846154  0.843680\n",
            "6   poly  0.1    0.5       1     7  0.907692   0.913215  0.907692  0.906890\n",
            "7   poly  0.1    0.5       1     8  0.676923   0.676113  0.676923  0.675060\n",
            "8   poly  0.1    0.5       1     9  0.584615   0.727972  0.584615  0.530317\n",
            "9   poly  0.1    0.5       1    10  0.625000   0.678140  0.625000  0.606781\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       2     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.1    0.5       2     2  0.630769   0.725034  0.630769  0.568034\n",
            "2   poly  0.1    0.5       2     3  0.753846   0.775214  0.753846  0.744615\n",
            "3   poly  0.1    0.5       2     4  0.615385   0.676282  0.615385  0.556213\n",
            "4   poly  0.1    0.5       2     5  0.676923   0.700698  0.676923  0.657543\n",
            "5   poly  0.1    0.5       2     6  0.861538   0.877369  0.861538  0.858688\n",
            "6   poly  0.1    0.5       2     7  0.892308   0.900769  0.892308  0.891002\n",
            "7   poly  0.1    0.5       2     8  0.661538   0.662289  0.661538  0.656095\n",
            "8   poly  0.1    0.5       2     9  0.569231   0.717643  0.569231  0.507074\n",
            "9   poly  0.1    0.5       2    10  0.656250   0.671938  0.656250  0.653554\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       3     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.5       3     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1    0.5       3     3  0.769231   0.778707  0.769231  0.764481\n",
            "3   poly  0.1    0.5       3     4  0.600000   0.657895  0.600000  0.532037\n",
            "4   poly  0.1    0.5       3     5  0.584615   0.585596  0.584615  0.559699\n",
            "5   poly  0.1    0.5       3     6  0.800000   0.805000  0.800000  0.797576\n",
            "6   poly  0.1    0.5       3     7  0.846154   0.846748  0.846154  0.845638\n",
            "7   poly  0.1    0.5       3     8  0.615385   0.614270  0.615385  0.607468\n",
            "8   poly  0.1    0.5       3     9  0.661538   0.770256  0.661538  0.636154\n",
            "9   poly  0.1    0.5       3    10  0.671875   0.675312  0.671875  0.672115\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       4     1  0.553846   0.601651  0.553846  0.463085\n",
            "1   poly  0.1    0.5       4     2  0.661538   0.748252  0.661538  0.614530\n",
            "2   poly  0.1    0.5       4     3  0.738462   0.738064  0.738462  0.738087\n",
            "3   poly  0.1    0.5       4     4  0.569231   0.590756  0.569231  0.496039\n",
            "4   poly  0.1    0.5       4     5  0.569231   0.565739  0.569231  0.546904\n",
            "5   poly  0.1    0.5       4     6  0.707692   0.709231  0.707692  0.704149\n",
            "6   poly  0.1    0.5       4     7  0.846154   0.846748  0.846154  0.845638\n",
            "7   poly  0.1    0.5       4     8  0.661538   0.661538  0.661538  0.661538\n",
            "8   poly  0.1    0.5       4     9  0.707692   0.754838  0.707692  0.700386\n",
            "9   poly  0.1    0.5       4    10  0.687500   0.692892  0.687500  0.687500\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       5     1  0.569231   0.594095  0.569231  0.515618\n",
            "1   poly  0.1    0.5       5     2  0.661538   0.719884  0.661538  0.623626\n",
            "2   poly  0.1    0.5       5     3  0.738462   0.738064  0.738462  0.738087\n",
            "3   poly  0.1    0.5       5     4  0.584615   0.602823  0.584615  0.532707\n",
            "4   poly  0.1    0.5       5     5  0.492308   0.479271  0.492308  0.476430\n",
            "5   poly  0.1    0.5       5     6  0.707692   0.709231  0.707692  0.704149\n",
            "6   poly  0.1    0.5       5     7  0.784615   0.791745  0.784615  0.781152\n",
            "7   poly  0.1    0.5       5     8  0.661538   0.660750  0.661538  0.658598\n",
            "8   poly  0.1    0.5       5     9  0.646154   0.684420  0.646154  0.637310\n",
            "9   poly  0.1    0.5       5    10  0.656250   0.658203  0.656250  0.656586\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1      1       1     2  0.646154   0.706682  0.646154  0.601935\n",
            "2   poly  0.1      1       1     3  0.815385   0.824109  0.815385  0.812416\n",
            "3   poly  0.1      1       1     4  0.646154   0.686391  0.646154  0.610779\n",
            "4   poly  0.1      1       1     5  0.723077   0.740171  0.723077  0.712692\n",
            "5   poly  0.1      1       1     6  0.830769   0.844482  0.830769  0.827286\n",
            "6   poly  0.1      1       1     7  0.938462   0.939857  0.938462  0.938255\n",
            "7   poly  0.1      1       1     8  0.630769   0.629925  0.630769  0.624831\n",
            "8   poly  0.1      1       1     9  0.569231   0.717643  0.569231  0.507074\n",
            "9   poly  0.1      1       1    10  0.656250   0.717844  0.656250  0.639550\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       2     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1      1       2     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.1      1       2     3  0.800000   0.821429  0.800000  0.793745\n",
            "3   poly  0.1      1       2     4  0.646154   0.706682  0.646154  0.601935\n",
            "4   poly  0.1      1       2     5  0.692308   0.698813  0.692308  0.684418\n",
            "5   poly  0.1      1       2     6  0.830769   0.844482  0.830769  0.827286\n",
            "6   poly  0.1      1       2     7  0.923077   0.923298  0.923077  0.922967\n",
            "7   poly  0.1      1       2     8  0.676923   0.684565  0.676923  0.666819\n",
            "8   poly  0.1      1       2     9  0.646154   0.762443  0.646154  0.616199\n",
            "9   poly  0.1      1       2    10  0.671875   0.679341  0.671875  0.671474\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       3     1  0.538462   0.545177  0.538462  0.467949\n",
            "1   poly  0.1      1       3     2  0.676923   0.732249  0.676923  0.644624\n",
            "2   poly  0.1      1       3     3  0.738462   0.742351  0.738462  0.738833\n",
            "3   poly  0.1      1       3     4  0.600000   0.613445  0.600000  0.564482\n",
            "4   poly  0.1      1       3     5  0.630769   0.629191  0.630769  0.627562\n",
            "5   poly  0.1      1       3     6  0.676923   0.677308  0.676923  0.673007\n",
            "6   poly  0.1      1       3     7  0.861538   0.861553  0.861538  0.861340\n",
            "7   poly  0.1      1       3     8  0.661538   0.661538  0.661538  0.661538\n",
            "8   poly  0.1      1       3     9  0.692308   0.744755  0.692308  0.682952\n",
            "9   poly  0.1      1       3    10  0.671875   0.675312  0.671875  0.672115\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       4     1  0.615385   0.629569  0.615385  0.595228\n",
            "1   poly  0.1      1       4     2  0.646154   0.662330  0.646154  0.624929\n",
            "2   poly  0.1      1       4     3  0.753846   0.766136  0.753846  0.753497\n",
            "3   poly  0.1      1       4     4  0.584615   0.585596  0.584615  0.559699\n",
            "4   poly  0.1      1       4     5  0.661538   0.663753  0.661538  0.662020\n",
            "5   poly  0.1      1       4     6  0.661538   0.660750  0.661538  0.658598\n",
            "6   poly  0.1      1       4     7  0.723077   0.723077  0.723077  0.723077\n",
            "7   poly  0.1      1       4     8  0.523077   0.524230  0.523077  0.523530\n",
            "8   poly  0.1      1       4     9  0.676923   0.734615  0.676923  0.665175\n",
            "9   poly  0.1      1       4    10  0.750000   0.752024  0.750000  0.748016\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       5     1  0.600000   0.613725  0.600000  0.575813\n",
            "1   poly  0.1      1       5     2  0.615385   0.616134  0.615385  0.603356\n",
            "2   poly  0.1      1       5     3  0.661538   0.667202  0.661538  0.661859\n",
            "3   poly  0.1      1       5     4  0.569231   0.564957  0.569231  0.553077\n",
            "4   poly  0.1      1       5     5  0.692308   0.694493  0.692308  0.692746\n",
            "5   poly  0.1      1       5     6  0.630769   0.630769  0.630769  0.630769\n",
            "6   poly  0.1      1       5     7  0.769231   0.773164  0.769231  0.769559\n",
            "7   poly  0.1      1       5     8  0.492308   0.493505  0.492308  0.492790\n",
            "8   poly  0.1      1       5     9  0.707692   0.754838  0.707692  0.700386\n",
            "9   poly  0.1      1       5    10  0.703125   0.705288  0.703125  0.699798\n",
            "\n",
            "Média dos resultados do kernel poly\n",
            "   kernel      c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
            "0    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "1    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "2    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "3    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "4    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "5    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "6    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "7    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "8    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "9    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "10   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "11   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "12   poly  0.001  0.500  ...       0.592788    0.567043    0.446328\n",
            "13   poly  0.001  0.500  ...       0.627420    0.602524    0.519052\n",
            "14   poly  0.001  0.500  ...       0.645850    0.625697    0.553409\n",
            "15   poly  0.001  1.000  ...       0.287536    0.536202    0.374329\n",
            "16   poly  0.001  1.000  ...       0.641218    0.628726    0.559031\n",
            "17   poly  0.001  1.000  ...       0.720175    0.659543    0.608699\n",
            "18   poly  0.001  1.000  ...       0.685579    0.657933    0.613819\n",
            "19   poly  0.001  1.000  ...       0.666190    0.648726    0.619525\n",
            "20   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "21   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "22   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "23   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "24   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "25   poly  0.100  0.100  ...       0.736097    0.694904    0.665011\n",
            "26   poly  0.100  0.100  ...       0.641218    0.628726    0.559031\n",
            "27   poly  0.100  0.100  ...       0.488886    0.548534    0.406832\n",
            "28   poly  0.100  0.100  ...       0.334143    0.537740    0.377688\n",
            "29   poly  0.100  0.100  ...       0.287536    0.536202    0.374329\n",
            "30   poly  0.100  0.500  ...       0.744064    0.697885    0.667391\n",
            "31   poly  0.100  0.500  ...       0.746645    0.687163    0.651732\n",
            "32   poly  0.100  0.500  ...       0.711163    0.674880    0.645204\n",
            "33   poly  0.100  0.500  ...       0.690971    0.670288    0.645786\n",
            "34   poly  0.100  0.500  ...       0.663848    0.650240    0.632426\n",
            "35   poly  0.100  1.000  ...       0.744777    0.701010    0.671998\n",
            "36   poly  0.100  1.000  ...       0.749890    0.708726    0.682172\n",
            "37   poly  0.100  1.000  ...       0.688288    0.674880    0.659440\n",
            "38   poly  0.100  1.000  ...       0.670208    0.659615    0.651377\n",
            "39   poly  0.100  1.000  ...       0.651408    0.644159    0.638015\n",
            "\n",
            "[40 rows x 8 columns]\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1    rbf  0.1    0.1     2  0.630769   0.725034  0.630769  0.568034\n",
            "2    rbf  0.1    0.1     3  0.723077   0.740171  0.723077  0.712692\n",
            "3    rbf  0.1    0.1     4  0.646154   0.706682  0.646154  0.601935\n",
            "4    rbf  0.1    0.1     5  0.646154   0.650350  0.646154  0.635088\n",
            "5    rbf  0.1    0.1     6  0.876923   0.888837  0.876923  0.874944\n",
            "6    rbf  0.1    0.1     7  0.969231   0.970894  0.969231  0.969128\n",
            "7    rbf  0.1    0.1     8  0.784615   0.784615  0.784615  0.784615\n",
            "8    rbf  0.1    0.1     9  0.615385   0.746130  0.615385  0.574567\n",
            "9    rbf  0.1    0.1    10  0.671875   0.701584  0.671875  0.665632\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.5     1  0.553846   0.640668  0.553846  0.445159\n",
            "1    rbf  0.1    0.5     2  0.661538   0.748252  0.661538  0.614530\n",
            "2    rbf  0.1    0.5     3  0.738462   0.741154  0.738462  0.735291\n",
            "3    rbf  0.1    0.5     4  0.661538   0.686813  0.661538  0.638239\n",
            "4    rbf  0.1    0.5     5  0.676923   0.680045  0.676923  0.670273\n",
            "5    rbf  0.1    0.5     6  0.907692   0.913215  0.907692  0.906890\n",
            "6    rbf  0.1    0.5     7  0.938462   0.939857  0.938462  0.938255\n",
            "7    rbf  0.1    0.5     8  0.753846   0.755973  0.753846  0.754196\n",
            "8    rbf  0.1    0.5     9  0.569231   0.717643  0.569231  0.507074\n",
            "9    rbf  0.1    0.5    10  0.656250   0.717844  0.656250  0.639550\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "Média dos resultados do kernel rbf\n",
            "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
            "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "5    rbf  0.100  0.100      0.711803       0.755496    0.711803    0.683179\n",
            "6    rbf  0.100  0.500      0.711779       0.754147    0.711779    0.684946\n",
            "7    rbf  0.100  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVq5Bhv5XYeN",
        "colab_type": "code",
        "outputId": "db9c7318-4895-4863-b93a-7622919ac010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel Linear\n",
        "print(ic_linear_chi)\n",
        "result_linear_chi = result_linear_chi.rename(index={result_linear_chi.index[0]:'Chi'})\n",
        "result_linear_chi"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.612182      0.675395   0.612182   0.563516\n",
            "sup     0.789837      0.814160   0.789837   0.780479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.70101</td>\n",
              "      <td>0.744777</td>\n",
              "      <td>0.70101</td>\n",
              "      <td>0.671998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "Chi  linear  0.1       0.70101       0.744777     0.70101    0.671998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA_ju72JXYeT",
        "colab_type": "code",
        "outputId": "59d3baea-7778-4f33-f045-d3f7627d04f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel Poly\n",
        "print(ic_poly_chi)\n",
        "result_poly_chi = result_poly_chi.rename(index={result_poly_chi.index[0]:'Chi'})\n",
        "result_poly_chi"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.630528      0.686755   0.630528   0.584729\n",
            "sup     0.786924      0.813026   0.786924   0.779615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.74989</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.682172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "Chi   poly  0.1    1.0  ...        0.74989    0.708726    0.682172\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdnq2CDJXYea",
        "colab_type": "code",
        "outputId": "66176b8b-7351-4507-b19f-ef8a2842cff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel RBF\n",
        "print(ic_rbf_chi)\n",
        "result_rbf_chi = result_rbf_chi.rename(index={result_rbf_chi.index[0]:'Chi'})\n",
        "result_rbf_chi"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.619454      0.681690   0.619454   0.571175\n",
            "sup     0.804152      0.829303   0.804152   0.795184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.755496</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.683179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    kernel    c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "Chi    rbf  0.1    0.1      0.711803       0.755496    0.711803    0.683179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Qa8UIHXYef",
        "colab_type": "text"
      },
      "source": [
        "### 2.4. SVM: Recursive Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWM879b8XYef",
        "colab_type": "code",
        "outputId": "4bca880e-b291-4cfd-db4c-43459d7494ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = pd.read_csv('results/dataset-fs-recursive-feature.csv', header = 0)\n",
        "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
        "y = df['is_approved'].to_numpy() # target\n",
        "\n",
        "result_linear_rf, result_poly_rf, result_rbf_rf, ic_linear_rf, ic_poly_rf, ic_rbf_rf = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, \n",
        "                                                                 list_coef, dataSet='recursive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
            "\n",
            "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
            "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
            "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
            "\n",
            "   kernel      c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "   kernel    c  fold  accuracy  precision    recall    fscore\n",
            "0  linear  0.1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1  linear  0.1     2  0.676923   0.758612  0.676923  0.636550\n",
            "2  linear  0.1     3  0.769231   0.799243  0.769231  0.758998\n",
            "3  linear  0.1     4  0.661538   0.700496  0.661538  0.631485\n",
            "4  linear  0.1     5  0.784615   0.810256  0.784615  0.776538\n",
            "5  linear  0.1     6  0.876923   0.881657  0.876923  0.875854\n",
            "6  linear  0.1     7  0.938462   0.939857  0.938462  0.938255\n",
            "7  linear  0.1     8  0.738462   0.741154  0.738462  0.735291\n",
            "8  linear  0.1     9  0.569231   0.777188  0.569231  0.494172\n",
            "9  linear  0.1    10  0.625000   0.654221  0.625000  0.616071\n",
            "\n",
            "Média dos resultados do kernel linear\n",
            "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1  linear  0.100      0.719423       0.770335    0.719423    0.690837\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001    0.5       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001    0.5       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001    0.5       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001    0.5       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001    0.5       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001    0.5       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001    0.5       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001    0.5       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001    0.5       3     3  0.615385   0.775641  0.615385  0.528629\n",
            "3   poly  0.001    0.5       3     4  0.569231   0.760684  0.569231  0.442308\n",
            "4   poly  0.001    0.5       3     5  0.584615   0.765509  0.584615  0.472497\n",
            "5   poly  0.001    0.5       3     6  0.630769   0.780965  0.630769  0.554828\n",
            "6   poly  0.001    0.5       3     7  0.630769   0.780965  0.630769  0.554828\n",
            "7   poly  0.001    0.5       3     8  0.676923   0.798077  0.676923  0.627219\n",
            "8   poly  0.001    0.5       3     9  0.769231   0.773077  0.769231  0.766434\n",
            "9   poly  0.001    0.5       3    10  0.718750   0.748641  0.718750  0.704688\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       4     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.001    0.5       4     2  0.584615   0.674359  0.584615  0.490920\n",
            "2   poly  0.001    0.5       4     3  0.661538   0.792173  0.661538  0.604031\n",
            "3   poly  0.001    0.5       4     4  0.569231   0.646280  0.569231  0.462858\n",
            "4   poly  0.001    0.5       4     5  0.615385   0.711254  0.615385  0.543402\n",
            "5   poly  0.001    0.5       4     6  0.723077   0.787546  0.723077  0.698488\n",
            "6   poly  0.001    0.5       4     7  0.784615   0.846154  0.784615  0.769788\n",
            "7   poly  0.001    0.5       4     8  0.738462   0.777432  0.738462  0.722773\n",
            "8   poly  0.001    0.5       4     9  0.738462   0.763314  0.738462  0.736225\n",
            "9   poly  0.001    0.5       4    10  0.640625   0.639733  0.640625  0.638760\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001    0.5       5     1  0.569231   0.763772  0.569231  0.454676\n",
            "1   poly  0.001    0.5       5     2  0.630769   0.725034  0.630769  0.568034\n",
            "2   poly  0.001    0.5       5     3  0.692308   0.804196  0.692308  0.649573\n",
            "3   poly  0.001    0.5       5     4  0.569231   0.646280  0.569231  0.462858\n",
            "4   poly  0.001    0.5       5     5  0.630769   0.692308  0.630769  0.579487\n",
            "5   poly  0.001    0.5       5     6  0.769231   0.838462  0.769231  0.751131\n",
            "6   poly  0.001    0.5       5     7  0.784615   0.825423  0.784615  0.773452\n",
            "7   poly  0.001    0.5       5     8  0.723077   0.766484  0.723077  0.704013\n",
            "8   poly  0.001    0.5       5     9  0.723077   0.752308  0.723077  0.719780\n",
            "9   poly  0.001    0.5       5    10  0.640625   0.640055  0.640625  0.640184\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       2     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.001      1       2     2  0.569231   0.760684  0.569231  0.442308\n",
            "2   poly  0.001      1       2     3  0.630769   0.780965  0.630769  0.554828\n",
            "3   poly  0.001      1       2     4  0.569231   0.760684  0.569231  0.442308\n",
            "4   poly  0.001      1       2     5  0.600000   0.770492  0.600000  0.501225\n",
            "5   poly  0.001      1       2     6  0.723077   0.817126  0.723077  0.692058\n",
            "6   poly  0.001      1       2     7  0.753846   0.831071  0.753846  0.731989\n",
            "7   poly  0.001      1       2     8  0.661538   0.719884  0.661538  0.623626\n",
            "8   poly  0.001      1       2     9  0.769231   0.773164  0.769231  0.769559\n",
            "9   poly  0.001      1       2    10  0.671875   0.671453  0.671875  0.670172\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       3     1  0.569231   0.763772  0.569231  0.454676\n",
            "1   poly  0.001      1       3     2  0.646154   0.737179  0.646154  0.591716\n",
            "2   poly  0.001      1       3     3  0.738462   0.796923  0.738462  0.717949\n",
            "3   poly  0.001      1       3     4  0.600000   0.694915  0.600000  0.517730\n",
            "4   poly  0.001      1       3     5  0.676923   0.732249  0.676923  0.644624\n",
            "5   poly  0.001      1       3     6  0.830769   0.855644  0.830769  0.825477\n",
            "6   poly  0.001      1       3     7  0.830769   0.855644  0.830769  0.825477\n",
            "7   poly  0.001      1       3     8  0.723077   0.740171  0.723077  0.712692\n",
            "8   poly  0.001      1       3     9  0.676923   0.809955  0.676923  0.649573\n",
            "9   poly  0.001      1       3    10  0.640625   0.647629  0.640625  0.640186\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       4     1  0.538462   0.565128  0.538462  0.435625\n",
            "1   poly  0.001      1       4     2  0.676923   0.758612  0.676923  0.636550\n",
            "2   poly  0.001      1       4     3  0.769231   0.787213  0.769231  0.762014\n",
            "3   poly  0.001      1       4     4  0.615385   0.654753  0.615385  0.567321\n",
            "4   poly  0.001      1       4     5  0.707692   0.755385  0.707692  0.684766\n",
            "5   poly  0.001      1       4     6  0.769231   0.799243  0.769231  0.758998\n",
            "6   poly  0.001      1       4     7  0.815385   0.832818  0.815385  0.810651\n",
            "7   poly  0.001      1       4     8  0.676923   0.691252  0.676923  0.662597\n",
            "8   poly  0.001      1       4     9  0.630769   0.754438  0.630769  0.595685\n",
            "9   poly  0.001      1       4    10  0.671875   0.675312  0.671875  0.672115\n",
            "\n",
            "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.001      1       5     1  0.538462   0.536821  0.538462  0.502150\n",
            "1   poly  0.001      1       5     2  0.692308   0.726648  0.692308  0.671126\n",
            "2   poly  0.001      1       5     3  0.753846   0.775214  0.753846  0.744615\n",
            "3   poly  0.001      1       5     4  0.584615   0.615385  0.584615  0.520710\n",
            "4   poly  0.001      1       5     5  0.692308   0.694653  0.692308  0.687359\n",
            "5   poly  0.001      1       5     6  0.661538   0.670085  0.661538  0.648846\n",
            "6   poly  0.001      1       5     7  0.769231   0.787213  0.769231  0.762014\n",
            "7   poly  0.001      1       5     8  0.661538   0.665311  0.661538  0.652860\n",
            "8   poly  0.001      1       5     9  0.630769   0.685971  0.630769  0.614935\n",
            "9   poly  0.001      1       5    10  0.578125   0.604893  0.578125  0.565831\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       1     1  0.538462   0.754808  0.538462  0.392759\n",
            "1   poly  0.1    0.1       1     2  0.584615   0.674359  0.584615  0.490920\n",
            "2   poly  0.1    0.1       1     3  0.692308   0.804196  0.692308  0.649573\n",
            "3   poly  0.1    0.1       1     4  0.569231   0.608866  0.569231  0.480633\n",
            "4   poly  0.1    0.1       1     5  0.692308   0.804196  0.692308  0.649573\n",
            "5   poly  0.1    0.1       1     6  0.800000   0.854167  0.800000  0.788003\n",
            "6   poly  0.1    0.1       1     7  0.907692   0.921201  0.907692  0.906208\n",
            "7   poly  0.1    0.1       1     8  0.738462   0.777432  0.738462  0.722773\n",
            "8   poly  0.1    0.1       1     9  0.646154   0.713857  0.646154  0.628466\n",
            "9   poly  0.1    0.1       1    10  0.671875   0.675312  0.671875  0.672115\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       2     1  0.553846   0.759219  0.553846  0.424502\n",
            "1   poly  0.1    0.1       2     2  0.569231   0.760684  0.569231  0.442308\n",
            "2   poly  0.1    0.1       2     3  0.630769   0.780965  0.630769  0.554828\n",
            "3   poly  0.1    0.1       2     4  0.569231   0.760684  0.569231  0.442308\n",
            "4   poly  0.1    0.1       2     5  0.600000   0.770492  0.600000  0.501225\n",
            "5   poly  0.1    0.1       2     6  0.723077   0.817126  0.723077  0.692058\n",
            "6   poly  0.1    0.1       2     7  0.753846   0.831071  0.753846  0.731989\n",
            "7   poly  0.1    0.1       2     8  0.661538   0.719884  0.661538  0.623626\n",
            "8   poly  0.1    0.1       2     9  0.769231   0.773164  0.769231  0.769559\n",
            "9   poly  0.1    0.1       2    10  0.671875   0.671453  0.671875  0.670172\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       3     3  0.553846   0.756010  0.553846  0.410507\n",
            "3   poly  0.1    0.1       3     4  0.569231   0.760684  0.569231  0.442308\n",
            "4   poly  0.1    0.1       3     5  0.553846   0.756010  0.553846  0.410507\n",
            "5   poly  0.1    0.1       3     6  0.630769   0.780965  0.630769  0.554828\n",
            "6   poly  0.1    0.1       3     7  0.615385   0.775641  0.615385  0.528629\n",
            "7   poly  0.1    0.1       3     8  0.630769   0.780965  0.630769  0.554828\n",
            "8   poly  0.1    0.1       3     9  0.661538   0.700496  0.661538  0.631485\n",
            "9   poly  0.1    0.1       3    10  0.609375   0.709352  0.609375  0.537329\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       4     6  0.600000   0.770492  0.600000  0.501225\n",
            "6   poly  0.1    0.1       4     7  0.569231   0.760684  0.569231  0.442308\n",
            "7   poly  0.1    0.1       4     8  0.553846   0.756010  0.553846  0.410507\n",
            "8   poly  0.1    0.1       4     9  0.584615   0.765509  0.584615  0.472497\n",
            "9   poly  0.1    0.1       4    10  0.546875   0.755456  0.546875  0.402665\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1   poly  0.1    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2   poly  0.1    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3   poly  0.1    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4   poly  0.1    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5   poly  0.1    0.1       5     6  0.584615   0.765509  0.584615  0.472497\n",
            "6   poly  0.1    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7   poly  0.1    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8   poly  0.1    0.1       5     9  0.569231   0.760684  0.569231  0.442308\n",
            "9   poly  0.1    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.5       1     2  0.661538   0.748252  0.661538  0.614530\n",
            "2   poly  0.1    0.5       1     3  0.769231   0.799243  0.769231  0.758998\n",
            "3   poly  0.1    0.5       1     4  0.615385   0.654753  0.615385  0.567321\n",
            "4   poly  0.1    0.5       1     5  0.753846   0.788325  0.753846  0.741088\n",
            "5   poly  0.1    0.5       1     6  0.892308   0.900769  0.892308  0.891002\n",
            "6   poly  0.1    0.5       1     7  0.923077   0.926226  0.923077  0.922633\n",
            "7   poly  0.1    0.5       1     8  0.738462   0.741154  0.738462  0.735291\n",
            "8   poly  0.1    0.5       1     9  0.584615   0.781377  0.584615  0.518660\n",
            "9   poly  0.1    0.5       1    10  0.640625   0.690241  0.640625  0.625708\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       2     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1    0.5       2     2  0.676923   0.758612  0.676923  0.636550\n",
            "2   poly  0.1    0.5       2     3  0.784615   0.810256  0.784615  0.776538\n",
            "3   poly  0.1    0.5       2     4  0.661538   0.686813  0.661538  0.638239\n",
            "4   poly  0.1    0.5       2     5  0.769231   0.799243  0.769231  0.758998\n",
            "5   poly  0.1    0.5       2     6  0.846154   0.856473  0.846154  0.843680\n",
            "6   poly  0.1    0.5       2     7  0.923077   0.926226  0.923077  0.922633\n",
            "7   poly  0.1    0.5       2     8  0.707692   0.718781  0.707692  0.698551\n",
            "8   poly  0.1    0.5       2     9  0.630769   0.794872  0.630769  0.587195\n",
            "9   poly  0.1    0.5       2    10  0.625000   0.645833  0.625000  0.619458\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       3     1  0.569231   0.629254  0.569231  0.489386\n",
            "1   poly  0.1    0.5       3     2  0.676923   0.758612  0.676923  0.636550\n",
            "2   poly  0.1    0.5       3     3  0.800000   0.821429  0.800000  0.793745\n",
            "3   poly  0.1    0.5       3     4  0.646154   0.672308  0.646154  0.618401\n",
            "4   poly  0.1    0.5       3     5  0.784615   0.825423  0.784615  0.773452\n",
            "5   poly  0.1    0.5       3     6  0.753846   0.775214  0.753846  0.744615\n",
            "6   poly  0.1    0.5       3     7  0.876923   0.888837  0.876923  0.874944\n",
            "7   poly  0.1    0.5       3     8  0.692308   0.714130  0.692308  0.676360\n",
            "8   poly  0.1    0.5       3     9  0.615385   0.714932  0.615385  0.582825\n",
            "9   poly  0.1    0.5       3    10  0.640625   0.652559  0.640625  0.638778\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       4     1  0.538462   0.538462  0.538462  0.492356\n",
            "1   poly  0.1    0.5       4     2  0.661538   0.686813  0.661538  0.638239\n",
            "2   poly  0.1    0.5       4     3  0.753846   0.765816  0.753846  0.747535\n",
            "3   poly  0.1    0.5       4     4  0.584615   0.594675  0.584615  0.543088\n",
            "4   poly  0.1    0.5       4     5  0.676923   0.680045  0.676923  0.670273\n",
            "5   poly  0.1    0.5       4     6  0.723077   0.740171  0.723077  0.712692\n",
            "6   poly  0.1    0.5       4     7  0.815385   0.832818  0.815385  0.810651\n",
            "7   poly  0.1    0.5       4     8  0.661538   0.665311  0.661538  0.652860\n",
            "8   poly  0.1    0.5       4     9  0.600000   0.680000  0.600000  0.570000\n",
            "9   poly  0.1    0.5       4    10  0.562500   0.578125  0.562500  0.556034\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1    0.5       5     1  0.523077   0.516694  0.523077  0.498083\n",
            "1   poly  0.1    0.5       5     2  0.630769   0.635043  0.630769  0.616923\n",
            "2   poly  0.1    0.5       5     3  0.723077   0.723866  0.723077  0.720671\n",
            "3   poly  0.1    0.5       5     4  0.538462   0.526395  0.538462  0.497479\n",
            "4   poly  0.1    0.5       5     5  0.692308   0.698813  0.692308  0.684418\n",
            "5   poly  0.1    0.5       5     6  0.661538   0.660750  0.661538  0.658598\n",
            "6   poly  0.1    0.5       5     7  0.753846   0.765816  0.753846  0.747535\n",
            "7   poly  0.1    0.5       5     8  0.630769   0.629191  0.630769  0.627562\n",
            "8   poly  0.1    0.5       5     9  0.661538   0.724344  0.661538  0.647024\n",
            "9   poly  0.1    0.5       5    10  0.531250   0.553125  0.531250  0.514827\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       1     1  0.553846   0.640668  0.553846  0.445159\n",
            "1   poly  0.1      1       1     2  0.676923   0.758612  0.676923  0.636550\n",
            "2   poly  0.1      1       1     3  0.769231   0.799243  0.769231  0.758998\n",
            "3   poly  0.1      1       1     4  0.661538   0.700496  0.661538  0.631485\n",
            "4   poly  0.1      1       1     5  0.784615   0.810256  0.784615  0.776538\n",
            "5   poly  0.1      1       1     6  0.876923   0.881657  0.876923  0.875854\n",
            "6   poly  0.1      1       1     7  0.938462   0.939857  0.938462  0.938255\n",
            "7   poly  0.1      1       1     8  0.738462   0.741154  0.738462  0.735291\n",
            "8   poly  0.1      1       1     9  0.569231   0.777188  0.569231  0.494172\n",
            "9   poly  0.1      1       1    10  0.625000   0.654221  0.625000  0.616071\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       2     1  0.553846   0.601651  0.553846  0.463085\n",
            "1   poly  0.1      1       2     2  0.707692   0.778107  0.707692  0.678469\n",
            "2   poly  0.1      1       2     3  0.830769   0.855644  0.830769  0.825477\n",
            "3   poly  0.1      1       2     4  0.661538   0.686813  0.661538  0.638239\n",
            "4   poly  0.1      1       2     5  0.769231   0.799243  0.769231  0.758998\n",
            "5   poly  0.1      1       2     6  0.784615   0.791745  0.784615  0.781152\n",
            "6   poly  0.1      1       2     7  0.923077   0.926226  0.923077  0.922633\n",
            "7   poly  0.1      1       2     8  0.661538   0.665311  0.661538  0.652860\n",
            "8   poly  0.1      1       2     9  0.630769   0.794872  0.630769  0.587195\n",
            "9   poly  0.1      1       2    10  0.656250   0.665923  0.656250  0.655242\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       3     1  0.553846   0.559707  0.553846  0.514188\n",
            "1   poly  0.1      1       3     2  0.646154   0.662330  0.646154  0.624929\n",
            "2   poly  0.1      1       3     3  0.723077   0.727017  0.723077  0.718623\n",
            "3   poly  0.1      1       3     4  0.569231   0.565739  0.569231  0.546904\n",
            "4   poly  0.1      1       3     5  0.692308   0.694653  0.692308  0.687359\n",
            "5   poly  0.1      1       3     6  0.707692   0.707377  0.707692  0.706006\n",
            "6   poly  0.1      1       3     7  0.815385   0.824109  0.815385  0.812416\n",
            "7   poly  0.1      1       3     8  0.630769   0.629925  0.630769  0.624831\n",
            "8   poly  0.1      1       3     9  0.646154   0.713857  0.646154  0.628466\n",
            "9   poly  0.1      1       3    10  0.593750   0.611979  0.593750  0.587746\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       4     1  0.569231   0.571766  0.569231  0.549846\n",
            "1   poly  0.1      1       4     2  0.646154   0.645385  0.646154  0.641865\n",
            "2   poly  0.1      1       4     3  0.738462   0.738064  0.738462  0.738087\n",
            "3   poly  0.1      1       4     4  0.553846   0.547702  0.553846  0.539893\n",
            "4   poly  0.1      1       4     5  0.646154   0.647157  0.646154  0.638871\n",
            "5   poly  0.1      1       4     6  0.584615   0.582321  0.584615  0.582220\n",
            "6   poly  0.1      1       4     7  0.738462   0.741154  0.738462  0.735291\n",
            "7   poly  0.1      1       4     8  0.600000   0.598456  0.600000  0.598659\n",
            "8   poly  0.1      1       4     9  0.646154   0.713857  0.646154  0.628466\n",
            "9   poly  0.1      1       4    10  0.484375   0.494400  0.484375  0.474564\n",
            "\n",
            "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
            "0   poly  0.1      1       5     1  0.492308   0.481966  0.492308  0.472902\n",
            "1   poly  0.1      1       5     2  0.600000   0.597633  0.600000  0.596525\n",
            "2   poly  0.1      1       5     3  0.753846   0.753638  0.753846  0.753021\n",
            "3   poly  0.1      1       5     4  0.584615   0.581538  0.584615  0.579580\n",
            "4   poly  0.1      1       5     5  0.661538   0.660529  0.661538  0.660404\n",
            "5   poly  0.1      1       5     6  0.646154   0.645447  0.646154  0.645647\n",
            "6   poly  0.1      1       5     7  0.753846   0.753846  0.753846  0.753846\n",
            "7   poly  0.1      1       5     8  0.538462   0.540793  0.538462  0.539118\n",
            "8   poly  0.1      1       5     9  0.646154   0.684420  0.646154  0.637310\n",
            "9   poly  0.1      1       5    10  0.515625   0.520782  0.515625  0.515034\n",
            "\n",
            "Média dos resultados do kernel poly\n",
            "   kernel      c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
            "0    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "1    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "2    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "3    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "4    poly  0.001  0.001  ...       0.287536    0.536202    0.374329\n",
            "5    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "6    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "7    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "8    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "9    poly  0.001  0.100  ...       0.287536    0.536202    0.374329\n",
            "10   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "11   poly  0.001  0.500  ...       0.287536    0.536202    0.374329\n",
            "12   poly  0.001  0.500  ...       0.674711    0.625721    0.538764\n",
            "13   poly  0.001  0.500  ...       0.739746    0.660986    0.609175\n",
            "14   poly  0.001  0.500  ...       0.745432    0.673293    0.630319\n",
            "15   poly  0.001  1.000  ...       0.287536    0.536202    0.374329\n",
            "16   poly  0.001  1.000  ...       0.764474    0.650264    0.585258\n",
            "17   poly  0.001  1.000  ...       0.763408    0.693293    0.658010\n",
            "18   poly  0.001  1.000  ...       0.727415    0.687188    0.658632\n",
            "19   poly  0.001  1.000  ...       0.676219    0.656274    0.637045\n",
            "20   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "21   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "22   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "23   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "24   poly  0.100  0.001  ...       0.287536    0.536202    0.374329\n",
            "25   poly  0.100  0.100  ...       0.758839    0.684111    0.638102\n",
            "26   poly  0.100  0.100  ...       0.764474    0.650264    0.585258\n",
            "27   poly  0.100  0.100  ...       0.658367    0.588630    0.480663\n",
            "28   poly  0.100  0.100  ...       0.524152    0.553149    0.409618\n",
            "29   poly  0.100  0.100  ...       0.382167    0.543894    0.390425\n",
            "30   poly  0.100  0.500  ...       0.767101    0.713293    0.682039\n",
            "31   poly  0.100  0.500  ...       0.763778    0.717885    0.692700\n",
            "32   poly  0.100  0.500  ...       0.745270    0.705601    0.682906\n",
            "33   poly  0.100  0.500  ...       0.676224    0.657788    0.639373\n",
            "34   poly  0.100  0.500  ...       0.643404    0.634663    0.621312\n",
            "35   poly  0.100  1.000  ...       0.770335    0.719423    0.690837\n",
            "36   poly  0.100  1.000  ...       0.756554    0.717933    0.696335\n",
            "37   poly  0.100  1.000  ...       0.669669    0.657837    0.645147\n",
            "38   poly  0.100  1.000  ...       0.628026    0.620745    0.612776\n",
            "39   poly  0.100  1.000  ...       0.622059    0.619255    0.615339\n",
            "\n",
            "[40 rows x 8 columns]\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
            "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
            "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
            "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.1     1  0.553846   0.759219  0.553846  0.424502\n",
            "1    rbf  0.1    0.1     2  0.615385   0.711254  0.615385  0.543402\n",
            "2    rbf  0.1    0.1     3  0.738462   0.823964  0.738462  0.712315\n",
            "3    rbf  0.1    0.1     4  0.600000   0.657895  0.600000  0.532037\n",
            "4    rbf  0.1    0.1     5  0.738462   0.777432  0.738462  0.722773\n",
            "5    rbf  0.1    0.1     6  0.876923   0.899821  0.876923  0.873767\n",
            "6    rbf  0.1    0.1     7  0.923077   0.932692  0.923077  0.922145\n",
            "7    rbf  0.1    0.1     8  0.738462   0.752997  0.738462  0.730282\n",
            "8    rbf  0.1    0.1     9  0.630769   0.754438  0.630769  0.595685\n",
            "9    rbf  0.1    0.1    10  0.609375   0.625673  0.609375  0.605057\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1    0.5     1  0.553846   0.640668  0.553846  0.445159\n",
            "1    rbf  0.1    0.5     2  0.676923   0.758612  0.676923  0.636550\n",
            "2    rbf  0.1    0.5     3  0.753846   0.775214  0.753846  0.744615\n",
            "3    rbf  0.1    0.5     4  0.646154   0.706682  0.646154  0.601935\n",
            "4    rbf  0.1    0.5     5  0.753846   0.765816  0.753846  0.747535\n",
            "5    rbf  0.1    0.5     6  0.892308   0.894962  0.892308  0.891687\n",
            "6    rbf  0.1    0.5     7  0.907692   0.913215  0.907692  0.906890\n",
            "7    rbf  0.1    0.5     8  0.753846   0.753638  0.753846  0.753021\n",
            "8    rbf  0.1    0.5     9  0.523077   0.765448  0.523077  0.414765\n",
            "9    rbf  0.1    0.5    10  0.578125   0.719381  0.578125  0.517527\n",
            "\n",
            "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
            "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
            "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
            "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
            "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
            "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
            "5    rbf  0.1      1     6  0.553846   0.756010  0.553846  0.410507\n",
            "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
            "7    rbf  0.1      1     8  0.569231   0.760684  0.569231  0.442308\n",
            "8    rbf  0.1      1     9  0.707692   0.708583  0.707692  0.707970\n",
            "9    rbf  0.1      1    10  0.671875   0.680752  0.671875  0.662099\n",
            "\n",
            "Média dos resultados do kernel rbf\n",
            "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
            "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
            "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
            "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
            "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
            "5    rbf  0.100  0.100      0.702476       0.769539    0.702476    0.666196\n",
            "6    rbf  0.100  0.500      0.703966       0.769364    0.703966    0.665968\n",
            "7    rbf  0.100  1.000      0.571803       0.462934    0.571803    0.446678\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jz4oGIuXYem",
        "colab_type": "code",
        "outputId": "f4c7b4f1-457e-4b5a-d58c-749eda10cf18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel Linear\n",
        "print(ic_linear_rf)\n",
        "result_linear_rf = result_linear_rf.rename(index={result_linear_rf.index[0]:'Recursive'})\n",
        "result_linear_rf"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.628961      0.702988   0.628961   0.578864\n",
            "sup     0.809885      0.837682   0.809885   0.802811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.690837</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
              "Recursive  linear  0.1      0.719423       0.770335    0.719423    0.690837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5o8JoHuXYer",
        "colab_type": "code",
        "outputId": "1014e6a3-d769-4164-9dec-95cd0652dc56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel Poly\n",
        "print(ic_poly_rf)\n",
        "result_poly_rf = result_poly_rf.rename(index={result_poly_rf.index[0]:'Recursive'})\n",
        "result_poly_rf"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.628961      0.702988   0.628961   0.578864\n",
            "sup     0.809885      0.837682   0.809885   0.802811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.690837</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "Recursive   poly  0.1    1.0  ...       0.770335    0.719423    0.690837\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNm7Gtf2XYe1",
        "colab_type": "code",
        "outputId": "7fb95637-629b-46ba-81b3-b44b5cacdcc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Exibe o resultado do kernel RBF\n",
        "print(ic_rbf_rf)\n",
        "result_rbf_rf = result_rbf_rf.rename(index={result_rbf_rf.index[0]:'Recursive'})\n",
        "result_rbf_rf"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
            "inf     0.608703      0.711012   0.608703   0.542463\n",
            "sup     0.799230      0.827715   0.799230   0.789474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>gamma</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>fscore_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.769364</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.665968</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          kernel    c  gamma  ...  precision_avg  recall_avg  fscore_avg\n",
              "Recursive    rbf  0.1    0.5  ...       0.769364    0.703966    0.665968\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xd-pQsZXYe7",
        "colab_type": "text"
      },
      "source": [
        "# Resultados do Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmXwx6DMXYe8",
        "colab_type": "text"
      },
      "source": [
        "##### Imprime os resultados com os respectivos parametros e intervalos de confiança"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "_dVoheAABROt",
        "colab": {}
      },
      "source": [
        "r  = ['result_NB_all','result_NB_pca','result_NB_chi','result_NB_rf']\n",
        "i  = ['ic_NB_all','ic_NB_pca','ic_NB_chi','ic_NB_rf']\n",
        "j  = ['accuracy_avg','precision_avg','recall_avg','fscore_avg']\n",
        "k  = ['accuracy_ic','precision_ic','recall_ic','fscore_ic']\n",
        "for x,y in zip(r,i):\n",
        "  for w,z in zip(j,k):\n",
        "    exec(\"{r}.insert({r}.columns.get_loc('{j}')+1,'{k}_inf',{i}['{k}'][0],False)\".format(r=x,i=y,j=w,k=z))\n",
        "    exec(\"{r}.insert({r}.columns.get_loc('{j}')+2,'{k}_sup',{i}['{k}'][1],False)\".format(r=x,i=y,j=w,k=z))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mmgQ4ydd_wD",
        "colab_type": "code",
        "outputId": "f6588528-11bd-4e62-8f2f-1981faf069f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "g_NB = pd.concat([result_NB_all,result_NB_pca,result_NB_chi,result_NB_rf],axis=0)\n",
        "g_NB['Classificador'] = 'NB'\n",
        "g_NB"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>accuracy_ic_inf</th>\n",
              "      <th>accuracy_ic_sup</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>precision_ic_inf</th>\n",
              "      <th>precision_ic_sup</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>recall_ic_inf</th>\n",
              "      <th>recall_ic_sup</th>\n",
              "      <th>fscore_avg</th>\n",
              "      <th>fscore_ic_inf</th>\n",
              "      <th>fscore_ic_sup</th>\n",
              "      <th>Classificador</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.714880</td>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.739373</td>\n",
              "      <td>0.686647</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.714880</td>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.700049</td>\n",
              "      <td>0.619341</td>\n",
              "      <td>0.780758</td>\n",
              "      <td>NB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.735570</td>\n",
              "      <td>0.679282</td>\n",
              "      <td>0.791858</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.650919</td>\n",
              "      <td>0.548533</td>\n",
              "      <td>0.753306</td>\n",
              "      <td>NB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.768852</td>\n",
              "      <td>0.714899</td>\n",
              "      <td>0.822804</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.726894</td>\n",
              "      <td>0.645429</td>\n",
              "      <td>0.808358</td>\n",
              "      <td>NB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.762049</td>\n",
              "      <td>0.708537</td>\n",
              "      <td>0.815561</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.715121</td>\n",
              "      <td>0.633364</td>\n",
              "      <td>0.796879</td>\n",
              "      <td>NB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  c  accuracy_avg  ...  fscore_ic_sup  Classificador\n",
              "All Features  0.100      0.714880  ...       0.780758             NB\n",
              "PCA           0.500      0.687188  ...       0.753306             NB\n",
              "Chi           0.001      0.741058  ...       0.808358             NB\n",
              "Recursive     0.001      0.731875  ...       0.796879             NB\n",
              "\n",
              "[4 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kcz3wFzZ2w1",
        "colab_type": "text"
      },
      "source": [
        "# Resultados do SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuE8vK5waAzV",
        "colab_type": "text"
      },
      "source": [
        "Imprime os resultados com os respectivos parametros e intervalos de confiança"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjtqTFINaAE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r  = ['result_linear_all', 'result_poly_all', 'result_rbf_all','result_linear_pca', 'result_poly_pca', 'result_rbf_pca','result_linear_chi', 'result_poly_chi', 'result_rbf_chi','result_linear_rf', 'result_poly_rf', 'result_rbf_rf']\n",
        "i  = ['ic_linear_all', 'ic_poly_all', 'ic_rbf_all','ic_linear_pca', 'ic_poly_pca', 'ic_rbf_pca','ic_linear_chi', 'ic_poly_chi', 'ic_rbf_chi','ic_linear_rf', 'ic_poly_rf', 'ic_rbf_rf']\n",
        "j  = ['accuracy_avg','precision_avg','recall_avg','fscore_avg']\n",
        "k  = ['accuracy_ic','precision_ic','recall_ic','fscore_ic']\n",
        "for x,y in zip(r,i):\n",
        "  for w,z in zip(j,k):\n",
        "    exec(\"{r}.insert({r}.columns.get_loc('{j}')+1,'{k}_inf',{i}['{k}'][0],False)\".format(r=x,i=y,j=w,k=z))\n",
        "    exec(\"{r}.insert({r}.columns.get_loc('{j}')+2,'{k}_sup',{i}['{k}'][1],False)\".format(r=x,i=y,j=w,k=z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bGukg8VeH9c",
        "colab_type": "code",
        "outputId": "957445ac-d0b5-4d92-f593-a2ee8578ceb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "g_SVM = pd.concat([result_linear_all, result_poly_all, result_rbf_all,result_linear_pca, result_poly_pca, result_rbf_pca,result_linear_chi, result_poly_chi, result_rbf_chi,result_linear_rf, result_poly_rf, result_rbf_rf],axis=0)\n",
        "g_SVM['Classificador'] = 'SVM'\n",
        "g_SVM\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kernel</th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>accuracy_ic_inf</th>\n",
              "      <th>accuracy_ic_sup</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>precision_ic_inf</th>\n",
              "      <th>precision_ic_sup</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>recall_ic_inf</th>\n",
              "      <th>recall_ic_sup</th>\n",
              "      <th>fscore_avg</th>\n",
              "      <th>fscore_ic_inf</th>\n",
              "      <th>fscore_ic_sup</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>Classificador</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.625931</td>\n",
              "      <td>0.769886</td>\n",
              "      <td>0.754553</td>\n",
              "      <td>0.702986</td>\n",
              "      <td>0.806120</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.625931</td>\n",
              "      <td>0.769886</td>\n",
              "      <td>0.670648</td>\n",
              "      <td>0.580070</td>\n",
              "      <td>0.761227</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.710240</td>\n",
              "      <td>0.634177</td>\n",
              "      <td>0.786304</td>\n",
              "      <td>0.731985</td>\n",
              "      <td>0.664784</td>\n",
              "      <td>0.799185</td>\n",
              "      <td>0.710240</td>\n",
              "      <td>0.634177</td>\n",
              "      <td>0.786304</td>\n",
              "      <td>0.696639</td>\n",
              "      <td>0.611885</td>\n",
              "      <td>0.781393</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.604949</td>\n",
              "      <td>0.741734</td>\n",
              "      <td>0.708290</td>\n",
              "      <td>0.633665</td>\n",
              "      <td>0.782914</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.604949</td>\n",
              "      <td>0.741734</td>\n",
              "      <td>0.635024</td>\n",
              "      <td>0.539650</td>\n",
              "      <td>0.730398</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.624530</td>\n",
              "      <td>0.774460</td>\n",
              "      <td>0.738248</td>\n",
              "      <td>0.678692</td>\n",
              "      <td>0.797804</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.624530</td>\n",
              "      <td>0.774460</td>\n",
              "      <td>0.675761</td>\n",
              "      <td>0.582293</td>\n",
              "      <td>0.769229</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.624257</td>\n",
              "      <td>0.777618</td>\n",
              "      <td>0.734984</td>\n",
              "      <td>0.673032</td>\n",
              "      <td>0.796937</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.624257</td>\n",
              "      <td>0.777618</td>\n",
              "      <td>0.676787</td>\n",
              "      <td>0.580924</td>\n",
              "      <td>0.772650</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.602005</td>\n",
              "      <td>0.766217</td>\n",
              "      <td>0.703680</td>\n",
              "      <td>0.615024</td>\n",
              "      <td>0.792336</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.602005</td>\n",
              "      <td>0.766217</td>\n",
              "      <td>0.654902</td>\n",
              "      <td>0.549280</td>\n",
              "      <td>0.760524</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.701010</td>\n",
              "      <td>0.612182</td>\n",
              "      <td>0.789837</td>\n",
              "      <td>0.744777</td>\n",
              "      <td>0.675395</td>\n",
              "      <td>0.814160</td>\n",
              "      <td>0.701010</td>\n",
              "      <td>0.612182</td>\n",
              "      <td>0.789837</td>\n",
              "      <td>0.671998</td>\n",
              "      <td>0.563516</td>\n",
              "      <td>0.780479</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.630528</td>\n",
              "      <td>0.786924</td>\n",
              "      <td>0.749890</td>\n",
              "      <td>0.686755</td>\n",
              "      <td>0.813026</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.630528</td>\n",
              "      <td>0.786924</td>\n",
              "      <td>0.682172</td>\n",
              "      <td>0.584729</td>\n",
              "      <td>0.779615</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.619454</td>\n",
              "      <td>0.804152</td>\n",
              "      <td>0.755496</td>\n",
              "      <td>0.681690</td>\n",
              "      <td>0.829303</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.619454</td>\n",
              "      <td>0.804152</td>\n",
              "      <td>0.683179</td>\n",
              "      <td>0.571175</td>\n",
              "      <td>0.795184</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>linear</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.702988</td>\n",
              "      <td>0.837682</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.690837</td>\n",
              "      <td>0.578864</td>\n",
              "      <td>0.802811</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>poly</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.702988</td>\n",
              "      <td>0.837682</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.690837</td>\n",
              "      <td>0.578864</td>\n",
              "      <td>0.802811</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>rbf</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.608703</td>\n",
              "      <td>0.799230</td>\n",
              "      <td>0.769364</td>\n",
              "      <td>0.711012</td>\n",
              "      <td>0.827715</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.608703</td>\n",
              "      <td>0.799230</td>\n",
              "      <td>0.665968</td>\n",
              "      <td>0.542463</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SVM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              kernel      c  accuracy_avg  ...  gamma  degree  Classificador\n",
              "All Features  linear  0.100      0.697909  ...    NaN     NaN            SVM\n",
              "All Features    poly  0.001      0.710240  ...    1.0     3.0            SVM\n",
              "All Features     rbf  0.100      0.673341  ...    0.1     NaN            SVM\n",
              "PCA           linear  0.100      0.699495  ...    NaN     NaN            SVM\n",
              "PCA             poly  0.100      0.700937  ...    0.5     1.0            SVM\n",
              "PCA              rbf  0.100      0.684111  ...    0.1     NaN            SVM\n",
              "Chi           linear  0.100      0.701010  ...    NaN     NaN            SVM\n",
              "Chi             poly  0.100      0.708726  ...    1.0     2.0            SVM\n",
              "Chi              rbf  0.100      0.711803  ...    0.1     NaN            SVM\n",
              "Recursive     linear  0.100      0.719423  ...    NaN     NaN            SVM\n",
              "Recursive       poly  0.100      0.719423  ...    1.0     1.0            SVM\n",
              "Recursive        rbf  0.100      0.703966  ...    0.5     NaN            SVM\n",
              "\n",
              "[12 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6v8AgPoERhT",
        "colab_type": "code",
        "outputId": "29de29ea-efef-4869-e04e-72b9118d2868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "G = pd.concat([g_NB,g_SVM],axis=0)\n",
        "G['Features'] = G.index\n",
        "G"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>accuracy_avg</th>\n",
              "      <th>accuracy_ic_inf</th>\n",
              "      <th>accuracy_ic_sup</th>\n",
              "      <th>precision_avg</th>\n",
              "      <th>precision_ic_inf</th>\n",
              "      <th>precision_ic_sup</th>\n",
              "      <th>recall_avg</th>\n",
              "      <th>recall_ic_inf</th>\n",
              "      <th>recall_ic_sup</th>\n",
              "      <th>fscore_avg</th>\n",
              "      <th>fscore_ic_inf</th>\n",
              "      <th>fscore_ic_sup</th>\n",
              "      <th>Classificador</th>\n",
              "      <th>kernel</th>\n",
              "      <th>gamma</th>\n",
              "      <th>degree</th>\n",
              "      <th>Features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.714880</td>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.739373</td>\n",
              "      <td>0.686647</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.714880</td>\n",
              "      <td>0.647212</td>\n",
              "      <td>0.782547</td>\n",
              "      <td>0.700049</td>\n",
              "      <td>0.619341</td>\n",
              "      <td>0.780758</td>\n",
              "      <td>NB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All Features</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.735570</td>\n",
              "      <td>0.679282</td>\n",
              "      <td>0.791858</td>\n",
              "      <td>0.687188</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.758949</td>\n",
              "      <td>0.650919</td>\n",
              "      <td>0.548533</td>\n",
              "      <td>0.753306</td>\n",
              "      <td>NB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.768852</td>\n",
              "      <td>0.714899</td>\n",
              "      <td>0.822804</td>\n",
              "      <td>0.741058</td>\n",
              "      <td>0.673445</td>\n",
              "      <td>0.808670</td>\n",
              "      <td>0.726894</td>\n",
              "      <td>0.645429</td>\n",
              "      <td>0.808358</td>\n",
              "      <td>NB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.762049</td>\n",
              "      <td>0.708537</td>\n",
              "      <td>0.815561</td>\n",
              "      <td>0.731875</td>\n",
              "      <td>0.666579</td>\n",
              "      <td>0.797171</td>\n",
              "      <td>0.715121</td>\n",
              "      <td>0.633364</td>\n",
              "      <td>0.796879</td>\n",
              "      <td>NB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Recursive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.625931</td>\n",
              "      <td>0.769886</td>\n",
              "      <td>0.754553</td>\n",
              "      <td>0.702986</td>\n",
              "      <td>0.806120</td>\n",
              "      <td>0.697909</td>\n",
              "      <td>0.625931</td>\n",
              "      <td>0.769886</td>\n",
              "      <td>0.670648</td>\n",
              "      <td>0.580070</td>\n",
              "      <td>0.761227</td>\n",
              "      <td>SVM</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All Features</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.710240</td>\n",
              "      <td>0.634177</td>\n",
              "      <td>0.786304</td>\n",
              "      <td>0.731985</td>\n",
              "      <td>0.664784</td>\n",
              "      <td>0.799185</td>\n",
              "      <td>0.710240</td>\n",
              "      <td>0.634177</td>\n",
              "      <td>0.786304</td>\n",
              "      <td>0.696639</td>\n",
              "      <td>0.611885</td>\n",
              "      <td>0.781393</td>\n",
              "      <td>SVM</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>All Features</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Features</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.604949</td>\n",
              "      <td>0.741734</td>\n",
              "      <td>0.708290</td>\n",
              "      <td>0.633665</td>\n",
              "      <td>0.782914</td>\n",
              "      <td>0.673341</td>\n",
              "      <td>0.604949</td>\n",
              "      <td>0.741734</td>\n",
              "      <td>0.635024</td>\n",
              "      <td>0.539650</td>\n",
              "      <td>0.730398</td>\n",
              "      <td>SVM</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All Features</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.624530</td>\n",
              "      <td>0.774460</td>\n",
              "      <td>0.738248</td>\n",
              "      <td>0.678692</td>\n",
              "      <td>0.797804</td>\n",
              "      <td>0.699495</td>\n",
              "      <td>0.624530</td>\n",
              "      <td>0.774460</td>\n",
              "      <td>0.675761</td>\n",
              "      <td>0.582293</td>\n",
              "      <td>0.769229</td>\n",
              "      <td>SVM</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.624257</td>\n",
              "      <td>0.777618</td>\n",
              "      <td>0.734984</td>\n",
              "      <td>0.673032</td>\n",
              "      <td>0.796937</td>\n",
              "      <td>0.700937</td>\n",
              "      <td>0.624257</td>\n",
              "      <td>0.777618</td>\n",
              "      <td>0.676787</td>\n",
              "      <td>0.580924</td>\n",
              "      <td>0.772650</td>\n",
              "      <td>SVM</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>PCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.602005</td>\n",
              "      <td>0.766217</td>\n",
              "      <td>0.703680</td>\n",
              "      <td>0.615024</td>\n",
              "      <td>0.792336</td>\n",
              "      <td>0.684111</td>\n",
              "      <td>0.602005</td>\n",
              "      <td>0.766217</td>\n",
              "      <td>0.654902</td>\n",
              "      <td>0.549280</td>\n",
              "      <td>0.760524</td>\n",
              "      <td>SVM</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PCA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.701010</td>\n",
              "      <td>0.612182</td>\n",
              "      <td>0.789837</td>\n",
              "      <td>0.744777</td>\n",
              "      <td>0.675395</td>\n",
              "      <td>0.814160</td>\n",
              "      <td>0.701010</td>\n",
              "      <td>0.612182</td>\n",
              "      <td>0.789837</td>\n",
              "      <td>0.671998</td>\n",
              "      <td>0.563516</td>\n",
              "      <td>0.780479</td>\n",
              "      <td>SVM</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.630528</td>\n",
              "      <td>0.786924</td>\n",
              "      <td>0.749890</td>\n",
              "      <td>0.686755</td>\n",
              "      <td>0.813026</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>0.630528</td>\n",
              "      <td>0.786924</td>\n",
              "      <td>0.682172</td>\n",
              "      <td>0.584729</td>\n",
              "      <td>0.779615</td>\n",
              "      <td>SVM</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Chi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chi</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.619454</td>\n",
              "      <td>0.804152</td>\n",
              "      <td>0.755496</td>\n",
              "      <td>0.681690</td>\n",
              "      <td>0.829303</td>\n",
              "      <td>0.711803</td>\n",
              "      <td>0.619454</td>\n",
              "      <td>0.804152</td>\n",
              "      <td>0.683179</td>\n",
              "      <td>0.571175</td>\n",
              "      <td>0.795184</td>\n",
              "      <td>SVM</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.702988</td>\n",
              "      <td>0.837682</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.690837</td>\n",
              "      <td>0.578864</td>\n",
              "      <td>0.802811</td>\n",
              "      <td>SVM</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Recursive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.770335</td>\n",
              "      <td>0.702988</td>\n",
              "      <td>0.837682</td>\n",
              "      <td>0.719423</td>\n",
              "      <td>0.628961</td>\n",
              "      <td>0.809885</td>\n",
              "      <td>0.690837</td>\n",
              "      <td>0.578864</td>\n",
              "      <td>0.802811</td>\n",
              "      <td>SVM</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Recursive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recursive</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.608703</td>\n",
              "      <td>0.799230</td>\n",
              "      <td>0.769364</td>\n",
              "      <td>0.711012</td>\n",
              "      <td>0.827715</td>\n",
              "      <td>0.703966</td>\n",
              "      <td>0.608703</td>\n",
              "      <td>0.799230</td>\n",
              "      <td>0.665968</td>\n",
              "      <td>0.542463</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>SVM</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Recursive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  c  accuracy_avg  accuracy_ic_inf  ...  gamma  degree      Features\n",
              "All Features  0.100      0.714880         0.647212  ...    NaN     NaN  All Features\n",
              "PCA           0.500      0.687188         0.615426  ...    NaN     NaN           PCA\n",
              "Chi           0.001      0.741058         0.673445  ...    NaN     NaN           Chi\n",
              "Recursive     0.001      0.731875         0.666579  ...    NaN     NaN     Recursive\n",
              "All Features  0.100      0.697909         0.625931  ...    NaN     NaN  All Features\n",
              "All Features  0.001      0.710240         0.634177  ...    1.0     3.0  All Features\n",
              "All Features  0.100      0.673341         0.604949  ...    0.1     NaN  All Features\n",
              "PCA           0.100      0.699495         0.624530  ...    NaN     NaN           PCA\n",
              "PCA           0.100      0.700937         0.624257  ...    0.5     1.0           PCA\n",
              "PCA           0.100      0.684111         0.602005  ...    0.1     NaN           PCA\n",
              "Chi           0.100      0.701010         0.612182  ...    NaN     NaN           Chi\n",
              "Chi           0.100      0.708726         0.630528  ...    1.0     2.0           Chi\n",
              "Chi           0.100      0.711803         0.619454  ...    0.1     NaN           Chi\n",
              "Recursive     0.100      0.719423         0.628961  ...    NaN     NaN     Recursive\n",
              "Recursive     0.100      0.719423         0.628961  ...    1.0     1.0     Recursive\n",
              "Recursive     0.100      0.703966         0.608703  ...    0.5     NaN     Recursive\n",
              "\n",
              "[16 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5nPWiXY29cEu"
      },
      "source": [
        "# Gerar Graficos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CFhU-Fp2yVbw",
        "outputId": "e7a25857-a876-400b-cfb7-b3b61dbbb472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "\n",
        "df = G.sort_index()\n",
        "df['Parametros'] = df[['Features','Classificador']].fillna('').apply(lambda x: '\\n'.join((x).astype(str)), axis=1)\n",
        "\n",
        "conf = [df['accuracy_ic_sup'].array , df['accuracy_ic_inf'].array]\n",
        "means = df['accuracy_avg'].array\n",
        "ic = [conf[0]-means , means-conf[1]]\n",
        "\n",
        "\n",
        "g = plt.bar(df['Parametros'].array, df['accuracy_avg'].array, yerr=ic,width=0.9,zorder=2,align='center')\n",
        "plt.grid()\n",
        "g[0].set_color('g')\n",
        "g[4].set_color('g')\n",
        "g[8].set_color('g')\n",
        "g[12].set_color('g')\n",
        "plt.title(\"Accuracy_avg\")\n",
        "plt.ylabel('Accuracy_avg')\n",
        "plt.xlabel('Classificador')\n",
        "plt.yticks(np.arange(0, 1.1, .1))\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "plt.show()\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EdqWuhELhsu",
        "colab_type": "code",
        "outputId": "231d1776-371c-42e3-f60f-dc2902700e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "df = G.sort_index()\n",
        "df['Parametros'] = df[['Features','Classificador']].fillna('').apply(lambda x: '\\n'.join((x).astype(str)), axis=1)\n",
        "conf = [df['precision_ic_sup'].array , df['precision_ic_inf'].array]\n",
        "means = df['precision_avg'].array\n",
        "ic = [conf[0]-means , means-conf[1]]\n",
        "g = plt.bar(df['Parametros'].array, df['precision_avg'].array, yerr=ic,width=0.9,zorder=2)\n",
        "plt.grid()\n",
        "g[0].set_color('g')\n",
        "g[4].set_color('g')\n",
        "g[8].set_color('g')\n",
        "g[12].set_color('g')\n",
        "plt.title(\"Precision_avg\")\n",
        "plt.ylabel('Precision_avg')\n",
        "plt.xlabel('Classificador')\n",
        "plt.yticks(np.arange(0, 1.1, .1))\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAJoCAYAAADFzY2AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZgldX33/feHIbihktzqqDACUYyZuNMBl0Qbg/cNLuBCDLgkeGlGfUSjJl7BJwaRLBqNeust3jru0eiAW55RJ6BRGzWLgorogMBIVMCdRTIuwIzf549THQ5N98w0dPXv0PV+XVdfc2o5Vd9fVc3pT1fV+VWqCkmSJC2/3VoXIEmSNFQGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZpxUjylCSf2IX53pzkL5ejJknakdiPmKTlkuRbwGpgO/BT4J+B46pqa8u6JKkVz4hJWm6Prao9gQcCU8BLxycm2b1JVZLUgEFMUhNVdSmjM2L3TlJJnpvkQuBCgCSPSXJ2kiuT/FuS+86+N8maJB9O8qMklyV5Yzf+2CSf714nyeuS/DDJVUm+luTe3bR3JfnrseX9cZItSS5PsjHJXcemVZJnJ7mwq+XkJNlR25LcPcmnu9p+nOQfk+zVTfvzJB+cM//rk7yhe71/ks8m+a8k/9Kt7703aWNLmlgGMUlNJFkDPAr4SjfqccDBwNokDwDeATwL+B/AW4CNSW6RZBXwMeDbwH7A3sCGeVbxP4GHAfcEbg88CbhsnjoeAbyim36Xbrlzl/cY4LeB+3bz/a+dNa9b5l2B3wTWACd20zYAj0py2279q7plvq+b/j7gi127TwSetpN1SboZM4hJWm7/lORK4PPAGcDfduNfUVWXV9XPgXXAW6rqC1W1vareDVwNPAg4iFHAeXFV/bSqflFVn59nPdcCtwXuxeh+2POq6nvzzPcU4B1V9eWquhp4CfDgJPuNzfPKqrqyqr4DfAa4/44aWFVbquqTVXV1Vf0IeC3w8G7at4EvA4/vZn8E8LOq+o8kd2MU+E6oqmu6dm3c0bok3bwZxCQtt8dV1V5VtW9V/T9d8AK4eGyefYE/7S4FXtkFtzWMAtga4NtVtW1HK6mqTwNvBE4GfphkfZLbzTPrXRmdBZt931ZGZ872Hpvn+2OvfwbsuaN1J1mdZEOSS5NcBbwXuMPYLO8DjuleP5nrzobdFbi8qn42Nu/4dpG0whjEJE2K8a9wXwz8TRfYZn9uXVXv76bdbVdu6q+qN1TVgcBaRpcoXzzPbN9lFPwASHIbRpcFL70JbflbRu25T1XdDngqo8uVsz4ATCfZh9GZsdkg9j3g15LcemzeNTehDkkTziAmaRK9FXh2koO7m+5vk+TR3X1VX2QUWF7Zjb9lkofOXUCS3+7e/yuMusr4BfDLedb1fuDpSe6f5BaMQtQXqupbN6H+2wJbgZ8k2Zs5AbC7XDkDvBP4z6o6rxv/beAs4MQkeyR5MPDYm1CHpAlnEJM0carqLOCPGV1avALYAhzbTdvOKJzcA/gOcAnwB/Ms5naMAt0VjC49Xga8ep51/Qvwl8CHGAW8uwNH38QmvJxR9xw/AT4OfHieed4HHMp1Z8NmPQV4cFfvXwOnMLo/TtIKZIeukjTBkpwCfKOqXta6FklLzzNikjRBukuqd0+yW5LDgCOBf2pdl6R+9BrEkryj60zx6wtMT5I3dB0pnpPkgX3WI0lLpXte5dZ5ft58Exd9Z0b3j20F3gA8p6q+ssN3SLrZ6vXSZJKHMfow+Yequvc80x8FPI9Rp44HA6+vqoN7K0iSJGmC9HpGrKo+C1y+g1mOZBTSqqr+A9gryV36rEmSJGlStL5HbG+u31nhJVy/E0VJkqQVa6cdIk6KJOsYPfaEW93qVgeuWbPy+jj85S9/yW67tc7G7Qy9/eA2sP22f8jtB7fBSm3/BRdc8OOquuN801oHsUu5fq/R+7BAb9ZVtR5YDzA1NVVnnXVW/9Uts5mZGaanp1uX0czQ2w9uA9tv+4fcfnAbrNT2J/n2QtNax86NwB923558EPCTBR7KK0mStOL0ekYsyfuBaeAOSS4BXgb8CkBVvRnYxOgbk1sYPUj36X3WI0mSNEl6DWJVdcxOphfw3D5rkCRJmlStL01KkiQNlkFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJKkRg5gkSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJKkRg5gkSVIjBjFJkqRGDGKSJEmNGMQkSZIa6T2IJTksyflJtiQ5fp7p+yb5VJJzkswk2afvmiRJkiZBr0EsySrgZOBwYC1wTJK1c2b7e+Afquq+wEnAK/qsSZIkaVL0fUbsIGBLVV1UVdcAG4Aj58yzFvh09/oz80yXJElakVJV/S08OQo4rKqe2Q0/DTi4qo4bm+d9wBeq6vVJngB8CLhDVV02Z1nrgHUAq1evPnDDhg291d3K1q1b2XPPPVuX0czQ2w9uA9tv+4fcfnAbrNT2H3LIIV+qqqn5pu2+3MXM48+ANyY5FvgscCmwfe5MVbUeWA8wNTVV09PTy1ji8piZmWEltmtXDb394Daw/bZ/yO0Ht8EQ2993ELsUWDM2vE837r9V1XeBJwAk2RN4YlVd2XNdkiRJzfV9j9iZwAFJ9k+yB3A0sHF8hiR3SDJbx0uAd/RckyRJ0kToNYhV1TbgOOB04Dzg1KranOSkJEd0s00D5ye5AFgN/E2fNUmSJE2K3u8Rq6pNwKY5404Ye/1B4IN91yFJkjRp7FlfkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJKkRg5gkSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjezeugBJkqS99tqLbdu2sXXr1talLCvPiEmSJDViEJMkSWrEICZJktSI94hJmgjT09NceeWVnH322a1LkaRlYxCTJEnNbd26lapqXcay89KkJElSIwYxSZKkRrw0KU0I75GSpOHxjJgkSVIjBjFJkqRGDGKSJEmNeI+YJEkTwPtEh8kgJmkifP7znx9kH0KShs1Lk5IkSY0YxCRJkhoxiEmSJDXSexBLcliS85NsSXL8PNPvluQzSb6S5Jwkj+q7Jk2e6elpXvCCF7QuQ5KkZdVrEEuyCjgZOBxYCxyTZO2c2V4KnFpVDwCOBt7UZ02SJEmTou8zYgcBW6rqoqq6BtgAHDlnngJu172+PfDdnmuSJEmaCH13X7E3cPHY8CXAwXPmORH4RJLnAbcBDp1vQUnWAesAVq9ezczMzFLX2tzWrVtXZLt2xZVXXsn27dsH235wG8x2XTHU9sOwPwPA9vsZMMzPgPTZb0+So4DDquqZ3fDTgIOr6rixeV7U1fGaJA8G3g7cu6p+udByp6am6qyzzuqt7lZmZmaYnp5uXUYTe+21F9u2bWPr1q2tS2lm6J057r777lQV27dvb11KM0P+DADb72fAyv0MSPKlqpqab1rfZ8QuBdaMDe/TjRv3DOAwgKr69yS3BO4A/LDn2iRJE8I/xjRUfd8jdiZwQJL9k+zB6Gb8jXPm+Q7wewBJfhO4JfCjnuuSJElqrtczYlW1LclxwOnAKuAdVbU5yUnAWVW1EfhT4K1JXsjoxv1jy+ecSNKgbN261UdcaZB6f9ZkVW0CNs0Zd8LY63OBh/Zdx6Qb+r0B0tD5GSANkz3rS5IkNWIQkyRJasQgJkmS1IhBTJIkqZHeb9aXdoXfmJIkDZFnxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJKkRvzUpSZJuYL/jP76s69v+y2qy3m+98tHLur65DGLSAu7893fmBz/9wfKt8Fujf/LyLN86gdW3Wc33/+z7y7pOSdKIlyalBSxrCGtoKO2UpElkEJMkSWrEICZJktSI94hJkjSPIdwn6j2i7XlGTJKkeQzh/skhtHHSGcQkSZIaMYhJkiQ14j1iWtBydqo31I78JpmdOUpS/zwjJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViP2ILGMIzxsDnjEmS1JJBbAFDef7WUNopaXHs0FdaHgYxSZqHZ8UlLQfvEZOkeQzlbPFQ2ilNKoOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEZ81qQ0KZ7eugBJ0nLzjJgkSVIjnhGTJEnNZY9bti6hCYOYJEmTwNsTBqn3S5NJDktyfpItSY6fZ/rrkpzd/VyQ5Mq+a5IkSZoEvZ4RS7IKOBl4JHAJcGaSjVV17uw8VfXCsfmfBzygz5okSZImRd+XJg8CtlTVRQBJNgBHAucuMP8xwMt6rkkTaKj3BkiSRu72glNbl9BE35cm9wYuHhu+pBt3A0n2BfYHPt1zTZIkSRNhkm7WPxr4YFVtn29iknXAOoDVq1czMzOzjKWtbEPelkNu+7ghb4cht33WkLfBkNs+a+jboHX7+w5ilwJrxob36cbN52jguQstqKrWA+sBpqamanp6eolKXMAZ/S5+kiy4LU/7+LLW0cIOj6OhHwMD2P+wg2PA/b/sdbTgZ8CwfwfATo6BZdD3pckzgQOS7J9kD0Zha+PcmZLcC/hV4N97rkeSJGli9BrEqmobcBxwOnAecGpVbU5yUpIjxmY9GthQVdVnPZIkSZOk93vEqmoTsGnOuBPmDJ/Ydx2SJEmTxmdNSpIkNWIQkyRJamSSuq8YNp8xpoGzU19JQ+QZMUmSpEYMYpIkSY14aVLSRNjjTr/eugRJWnYGMUmaBAO/T9R7BDVUXpqUJElqxDNikibCnZ/8ytYlSNKyM4hJkprzHkENlZcmJUmSGjGISZIkNWIQkyRJasQgJkmS1Ig362sieKOuJGmIPCMmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWpk99YFSAB3fvIrW5cgSdKy84yYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiP2rC9Jas6na2ioPCMmSZLUiEFMkiSpEYOYJElSIwYxSZKkRnoPYkkOS3J+ki1Jjl9gniclOTfJ5iTv67smSZKkSdDrtyaTrAJOBh4JXAKcmWRjVZ07Ns8BwEuAh1bVFUnu1GdNkiRJk6LvM2IHAVuq6qKqugbYABw5Z54/Bk6uqisAquqHPdckSZI0EfruR2xv4OKx4UuAg+fMc0+AJP8KrAJOrKrT5i4oyTpgHcDq1auZmZnpo95BGvK2HHLbxw15Owy57bOGvA2G3PZZQ98Grds/CR267g4cAEwD+wCfTXKfqrpyfKaqWg+sB5iamqrp6el+qzqj38VPkgW35WkfX9Y6WtjhcTT0Y2AA+x92cAy4/5e9jhb8DBj27wDYyTGwDPq+NHkpsGZseJ9u3LhLgI1VdW1V/SdwAaNgJkmStKL1HcTOBA5Isn+SPYCjgY1z5vknRmfDSHIHRpcqL+q5LkmSpOZ6DWJVtQ04DjgdOA84tao2JzkpyRHdbKcDlyU5F/gM8OKquqzPuiRJkiZB7/eIVdUmYNOccSeMvS7gRd2PJEnSYNizviRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJKkRg5gkSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSI7vv6oxJHjjP6J8A366qbUtXkiRJ0jDschAD3gQ8EDgHCHBvYDNw+yTPqapP9FCfJEnSirWYS5PfBR5QVVNVdSDwAOAi4JHAq/ooTpIkaSVbTBC7Z1Vtnh2oqnOBe1XVRUtfliRJ0sq3mEuTm5P8X2BDN/wHwLlJbgFcu+SVSZIkrXCLOSN2LLAFeEH3c1E37lrgkKUuTJIkaaVbzBmxw4E3VtVr5pm2dYnqkSRJGozFnBF7LHBBkvckeUySxYQ4SZIkzbHLQayqng7cA/gAcAzwzSRv66swSZKklW5RZ7Wq6tok/wwUcCvgccAz+yhMkiRppdvlM2JJDk/yLuBC4InA24A791SXJEnSireYM2J/CJwCPKuqru6pHkmSpMHY5SBWVcf0WYgkSdLQLObS5IOSnJlka5JrkmxPclWfxUmSJK1ki+m+4o2Mvi15IaMb9Z8JnNxHUZIkSUOwmCBGVW0BVlXV9qp6J3BYP2VJkiStfIu5Wf9nSfYAzk7yKuB7LDLISZIk6TqLCVJP6+Y/DvgpsIZRNxaSJEm6ERbzrclvdy9/Abx87vQkH6oqg5kkSdIuWspLi7++hMuSJEla8ZYyiNUSLkuSJGnF82Z7SZKkRpYyiGUJlyVJkrTiLWUQ+/MlXJYkSdKKt8vfmkzyUOBEYN/ufQGqqn6d0YtP9FGgJEnSSrWYDl3fDrwQ+BKwvZ9yJEmShmMxQewnVfXPvVUiSZI0MIsJYp9J8mrgw8DVsyOr6stLXpUkSdIALCaIHdz9OzU2roBH7OhNSQ4DXg+sAt5WVa+cM/1Y4NXApd2oN1bV2xZRlyRJ0s3SYh5xdMhiF55kFXAy8EjgEuDMJBur6tw5s55SVcctdvmSJEk3Z7vcfUWS2yd5bZKzup/XJLn9Tt52ELClqi6qqmuADcCRN6VgSZKklWIxlybfAXwdeFI3/DTgncATdvCevYGLx4Yv4bpLnOOemORhwAXAC6vq4rkzJFkHrANYvXo1MzMziyhdOzLkbTnkto8b8nYYcttnDXkbDLnts4a+DVq3fzFB7O5V9cSx4ZcnOXsJavgo8P6qujrJs4B3M899Z1W1HlgPMDU1VdPT00uw6h04o9/FT5IFt+VpH1/WOlrY4XE09GNgAPsfdnAMuP+XvY4W/AwY9u8A2MkxsAwW07P+z5P8zuxA18Hrz3fynkuBNWPD+3DdTfkAVNVlVTX7Lcy3AQcuoiZJkqSbrcWcEXsO8O7uvrAAlwPH7uQ9ZwIHJNmfUQA7Gnjy+AxJ7lJV3+sGjwDOW0RNkiRJN1uL+dbk2cD9ktyuG75qF96zLclxwOmMuq94R1VtTnIScFZVbQSen+QIYBu7Fu4kSZJWhJ0GsSRPrar3JnnRnPEAVNVrd/T+qtoEbJoz7oSx1y8BXrKImiVJklaEXTkjdpvu39v2WYgkSdLQ7DSIVdVbun9f3n85kiRJw7GYDl1fleR2SX4lyaeS/CjJU/ssTpIkaSVbTPcV/7O7Qf8xwLeAewAv7qMoSZKkIVhMEJu9jPlo4ANV9ZMe6pEkSRqMxfQj9rEk32DUietzktwR+EU/ZUmSJK18u3xGrKqOBx4CTFXVtcBP8QHekiRJN9qu9CP2iKr6dJInjI0bn+XDfRQmSZK00u3KpcmHA58GHjvPtMIgJkmSdKPsSj9iL+v+fXr/5UiSJA3HYvoR+9ske40N/2qSv+6nLEmSpJVvMd1XHF5VV84OVNUVwKOWviRJkqRhWEwQW5XkFrMDSW4F3GIH80uSJGkHFtOP2D8Cn0ryzm746cC7l74kSZKkYdjlIFZVf5fkq8Ch3ai/qqrT+ylLkiRp5VvMGTGA84BtVfUvSW6d5LZV9V99FCZJkrTSLeZbk38MfBB4Szdqb+Cf+ihKkiRpCBZzs/5zgYcCVwFU1YXAnfooSpIkaQgWE8SurqprZgeS7M6oZ31JkiTdCIsJYmck+X+BWyV5JPAB4KP9lCVJkrTyLSaI/TnwI+BrwLOATcBL+yhKkiRpCHbpW5NJVgGbq+pewFv7LUmSJGkYdumMWFVtB85Pcree65EkSRqMxfQj9qvA5iRfBH46O7KqjljyqiRJkgZgMUHsL3urQpIkaYB2GsSS3BJ4NnAPRjfqv72qtvVdmCRJ0kq3K/eIvRuYYhTCDgde02tFkiRJA7ErlybXVtV9AJK8HfhivyVJkiQNw66cEbt29oWXJCVJkpbOrpwRu1+Sq7rXYdSz/lXd66qq2/VWnSRJ0gq20yBWVauWoxBJkqShWcwjjiRJkrSEDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1EjvQSzJYUnOT7IlyfE7mO+JSSrJVN81SZIkTYJeg1iSVcDJwOHAWuCYJGvnme+2wJ8AX+izHkmSpEnS9xmxg4AtVXVRVV0DbACOnGe+vwL+DvhFz/VIkiRNjL6D2N7AxWPDl3Tj/luSBwJrqurjPdciSZI0UXZvufIkuwGvBY7dhXnXAesAVq9ezczMTK+1DcmQt+WQ2z5uyNthyG2fNeRtMOS2zxr6Nmjd/r6D2KXAmrHhfbpxs24L3BuYSQJwZ2BjkiOq6qzxBVXVemA9wNTUVE1PT/dYNnBGv4ufJAtuy9NW/knKHR5HQz8GBrD/YQfHgPt/2etowc+AYf8OgJ0cA8ug70uTZwIHJNk/yR7A0cDG2YlV9ZOqukNV7VdV+wH/AdwghEmSJK1EvQaxqtoGHAecDpwHnFpVm5OclOSIPtctSZI06Xq/R6yqNgGb5ow7YYF5p/uuR5IkaVLYs74kSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJKkRg5gkSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWqk9yCW5LAk5yfZkuT4eaY/O8nXkpyd5PNJ1vZdkyRJ0iToNYglWQWcDBwOrAWOmSdova+q7lNV9wdeBby2z5okSZImRd9nxA4CtlTVRVV1DbABOHJ8hqq6amzwNkD1XJMkSdJE2L3n5e8NXDw2fAlw8NyZkjwXeBGwB/CI+RaUZB2wDmD16tXMzMwsda2DNeRtOeS2jxvydhhy22cNeRsMue2zhr4NWre/7yC2S6rqZODkJE8GXgr80TzzrAfWA0xNTdX09HS/RZ3R7+InyYLb8rSPL2sdLezwOBr6MTCA/Q87OAbc/8teRwt+Bgz7dwDs5BhYBn1fmrwUWDM2vE83biEbgMf1WpEkSdKE6DuInQkckGT/JHsARwMbx2dIcsDY4KOBC3uuSZIkaSL0emmyqrYlOQ44HVgFvKOqNic5CTirqjYCxyU5FLgWuIJ5LktKkiStRL3fI1ZVm4BNc8adMPb6T/quQZIkaRLZs74kSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJKkRg5gkSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDXSexBLcliS85NsSXL8PNNflOTcJOck+VSSffuuSZIkaRL0GsSSrAJOBg4H1gLHJFk7Z7avAFNVdV/gg8Cr+qxJkiRpUvR9RuwgYEtVXVRV1wAbgCPHZ6iqz1TVz7rB/wD26bkmSZKkibB7z8vfG7h4bPgS4OAdzP8M4J/nm5BkHbAOYPXq1czMzCxRiRrythxy28cNeTsMue2zhrwNhtz2WUPfBq3b33cQ22VJngpMAQ+fb3pVrQfWA0xNTdX09HS/BZ3R7+InyYLb8rSPL2sdLezwOBr6MTCA/Q87OAbc/8teRwt+Bgz7dwDs5BhYBn0HsUuBNWPD+3TjrifJocBfAA+vqqt7rkmSJGki9H2P2JnAAUn2T7IHcDSwcXyGJA8A3gIcUVU/7LkeSZKkidFrEKuqbcBxwOnAecCpVbU5yUlJjuhmezWwJ/CBJGcn2bjA4iRJklaU3u8Rq6pNwKY5404Ye31o3zVIkiRNInvWlyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJKkRg5gkSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJDL4exoAAA+kSURBVKkRg5gkSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRnoPYkkOS3J+ki1Jjp9n+sOSfDnJtiRH9V2PJEnSpOg1iCVZBZwMHA6sBY5JsnbObN8BjgXe12ctkiRJk2b3npd/ELClqi4CSLIBOBI4d3aGqvpWN+2XPdciSZI0Ufq+NLk3cPHY8CXdOEmSpMHr+4zYkkmyDlgHsHr1amZmZtoWtIIMeVsOue3jhrwdhtz2WUPeBkNu+6yhb4PW7e87iF0KrBkb3qcbt2hVtR5YDzA1NVXT09M3ubgdOqPfxU+SBbflaR9f1jpa2OFxNPRjYAD7H3ZwDLj/l72OFvwMGPbvANjJMbAM+r40eSZwQJL9k+wBHA1s7HmdkiRJNwu9BrGq2gYcB5wOnAecWlWbk5yU5AiAJL+d5BLg94G3JNncZ02SJEmTovd7xKpqE7BpzrgTxl6fyeiSpSRJ0qDYs74kSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJKkRg5gkSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWqk9yCW5LAk5yfZkuT4eabfIskp3fQvJNmv75okSZImQa9BLMkq4GTgcGAtcEyStXNmewZwRVXdA3gd8Hd91iRJkjQp+j4jdhCwpaouqqprgA3AkXPmORJ4d/f6g8DvJUnPdUmSJDWXqupv4clRwGFV9cxu+GnAwVV13Ng8X+/muaQb/mY3z4/nLGsdsK4b/A3g/N4Kb+cOwI93OtfKNfT2g9vA9tv+Ibcf3AYrtf37VtUd55uw+3JXcmNV1Xpgfes6+pTkrKqaal1HK0NvP7gNbL/tH3L7wW0wxPb3fWnyUmDN2PA+3bh550myO3B74LKe65IkSWqu7yB2JnBAkv2T7AEcDWycM89G4I+610cBn64+r5dKkiRNiF4vTVbVtiTHAacDq4B3VNXmJCcBZ1XVRuDtwHuSbAEuZxTWhmpFX3rdBUNvP7gNbP+wDb394DYYXPt7vVlfkiRJC7NnfUmSpEYMYpIkSY0YxHYiyeOSVJJ7jY3br+v/jCTTST42z/umk/wkydndz7/cyPW/IMmtb3wLbpqht78PSe6cZEOSbyb5UpJNSdbNtx27+d82zxMpbraG2v4k27v/C19P8oHZ43qB7XHPsfe9IMkvkty+XfU33Upp/5x2fDTJXg1qmEryhuVeb7fuQbe/DwaxnTsG+Hz372J9rqru3/0ceiPX/wJgUUGk6wZkqQy9/Uuqe2rER4CZqrp7VR0IvARYvdB7quqZVXXuctXYp4G3/+fd/4V7A9cAz97F7XEMo2+gP2HZK15aK6X94+24HHhuXyta6LOsqs6qquf3td6dGHr7l5xBbAeS7An8DqPnYS7JtzmTPDXJF7u/KN6S0fM4SfJ/k5yVZHOSl3fjng/cFfhMks9047aOLeuoJO/qXr8ryZuTfAF4VZK7Jzmt+wvzc7NntJL8fveXzFeTfNb2L7tDgGur6s2zI6rqq8DngD2TfDDJN5L8Y/dLiiQzSVZKB4dDb/+szwH3YIHtUVWfA0hyd2BP4KXcuD+GJtVKaf+/A3vDqNYFPnNWJ/lI95nz1SQPydhVhW6eP0tyYvd6Jsn/TnIW8CfzfWaluxKRZLck3xo/K5Xkwm6dd0zyoSRndj8Ptf2TaWLPHEyII4HTquqCJJclObCqvrSI9/9ukrO71x8APgz8AfDQqro2yZuApwD/APxFVV3eBZNPJblvVb0hyYuAQ+Y+8mkB+wAPqartST4FPLuqLkxyMPAm4BHACcD/qqpLs/NTykNvfx/uDSy0DR8A/BbwXeBfgYcyOhu5kgy9/bN/5R8OnMaOtweM/gDawCi4/EaS1VX1g/6r7M9KaX/3WfV7jLpgglG3C/N95rwBOKOqHt+9Z0/gV3ey+D1me5dP8jUW+Myqql8m+f+AxwPv7Nb77ar6QZL3Aa+rqs8nuRujbqR+cyna3tU16PYvJYPYjh0DvL57vaEbXkwQ+VxVPWZ2IKM+1Q4Ezuz+2L8V8MNu8pMyep7m7sBdgLXAOYus9wNdCNkTeAjwgVz3/PRbdP/+K/CuJKcyCkY7MvT2L7cvjj1z9WxgP1ZgENmBld7+W439YfI5Rr/Anr2T9xwDPL77hfMh4PeBN/ZYY59WSvtn27E3cB7wyZ185jwC+EOAqtoO/CTJzoLIKWOvd/aZdQqjPzDfySi4zr73UGDtWD23S7JnVW294SIWZejtX3IGsQUk+TVGB9B9khSjDmkryYtvymKBd1fVS+asa3/gz4DfrqorMrrcdssFljHe8dvceX7a/bsbcGVV3f8Gb656dvdXw6OBL3VnuW7wSKmht79Hmxk9QWI+V4+93s7K/P855Pb/fO4xmWTB7ZHkPsABjH7RAewB/Cftg8iNtVLa//Oqun9GXzY4ndE9Uu9igc+cBWzj+rcGLfRZNu9n1px5/x24R5I7Ao8D/robvxvwoKr6xS7WtKuG3v4l5z1iCzsKeE9V7VtV+1XVGkYfAr97E5b5KeCoJHeCUdhJsi9wO0YH3k+SrGZ02n7WfwG3HRv+QZLfTLIbo9OxN1BVVwH/meT3u/Ukyf2613evqi9U1QnAj7j+s0DHDb39ffk0cIvu7B9dTfflpm3Xm5Oht3+uebdHkt9ldDboxO7/335VdVfgrt3/mZXiZtv+qvoZ8HzgT4GfscBnDqPPved041dl9O3PHwB3SvI/ktwCeMwNVtDZ2WdWVRWjLzy8Fjhv7A/LTwDPG1vOroakXTL09i8lg9jCjmG0c8d9iJtww2j3za+XAp9Icg7wSeAu3c3KXwG+AbyP0anYWeuB09LdrA4cD3wM+DfgeztY3VOAZyT5KqOzEEd241+d5GsZ3Sj5b8BXF3j/0Nvfi+5D4/HAoRl9XX8z8Arg+8tZRytDb/9cO9keR3PD/4MfYQU9Bu7m3v6q+gqjWyiOYeHPnD8BDsnoXqcvAWur6lrgJOCLjD4Hv7GD1ezKZ9YpwFO5/iW95wNTSc5Jci47vwy8aENv/1LxEUeSJEmNeEZMkiSpEYOYJElSIwaxBjJ6ZNBrxobHO7M7McmlGXV4+o2MOjq92e+nJH+RUWet53Rte1mSV8yZ5/5JzutefyvJ5+ZMPztjnQDeXA1x/4PHwLghHgPu/+u4/4e9/+e62e/cm6mrgSckucMC01/XfQ14LXAf4OHLVlkPkjyY0bdiHlhV92XUv8tnGHXuOu5o4P1jw7dNsqZbxkR2xHcjDWr/g8fAPAZ1DLj/b8D9P+z9fz0GsTa2Mfo24At3Mt8ejPpXuaL3ivp1F+DHVXU1QFX9uKo+C1yRUf8ws57E9f8Tnsp1/1GPmTPt5mxo+x88BuYa2jHg/r8+9/+w9//1GMTaORl4SkZ9qsz1wox6Lv4ecEFVnT3PPDcnnwDWJLkgyZuSzP519366r6IneRBweVVdOPa+D3Hdg34fC3x0uQpeBkPa/+AxMJ8hHQPu/xty/w97//83g1gjXaej/8Cor5O5Zk9L3wm4TZKJ6TfnxugeKXEgsI5Rh3ynJDmWUZ8vR3X3P8w9JQ1wGaO/mI5m9CiNny1b0T0b0v4Hj4H5DOkYcP/fkPt/2Pt/nEGsrf8NPAO4zXwTu07vTgMetpxF9aGqtlfVTFW9DDgOeGJVXcyot/6HA0/k+p3xzTqF0V+OK/GU9GD2P3gMLGAwx4D7f17u/2Hvf8Ag1lRVXc7oGvgz5pueJMBDgW8uZ11LLclvJDlgbNT9gW93r98PvA64qLoHPs/xEeBVjJ5ptqIMZf+Dx8BChnIMuP/n5/4HBrz/ZxnE2nsNMPebM7P3B3yd0cO237TsVS2tPYF3Jzk3o0cbrQVO7KZ9APgtFvhrp6r+q6r+rqquWZZKl98Q9j94DOzIEI4B9//C3P/D3v8+4kiSJKkVz4hJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYxSRMnyZ2TbEjyzSRfSrIpyT2TfH0J13FSkkO717+bZHOSs5PsneSDS7D8/ZayXkkr0+6tC5CkcV0nlh8B3l1Vs8+hux+weinXU1UnjA0+BXhFVb23Gz5qKde1K5LsXlXblnu9ktryjJikSXMIcG1VvXl2RFV9Fbh4drg72/S5JF/ufh7Sjb9Lks92Z7a+3p3pWpXkXd3w15K8sJv3XUmOSvJM4EnAXyX5x/EzWd17/7577zlJnteNPyHJmd349V14JMmBSb6a5KvAc8fqvWWSd3br/0qSQ7rxxybZmOTTwKf63aySJpFnxCRNmnsDX9rJPD8EHllVv+genfJ+YAp4MnB6Vf1NklXArRk9TmXvqro3QJK9xhdUVW9L8jvAx6rqg0n2G5u8DtgPuH9VbUvya934N1bVSd3y3gM8Bvgo8E7guKr6bJJXjy3nuaNV1X2S3Av4RJJ7dtMeCNy3e9yNpIHxjJikm6NfAd6a5GuMHpGytht/JvD0JCcC96mq/wIuAn49yf9Jchhw1SLWcyjwltlLhmNh6ZAkX+jW/wjgt7qAt1dVfbab5z1jy/kd4L3dMr7B6Dl7s0Hsk4YwabgMYpImzWbgwJ3M80LgB8D9GJ0J2wOgC0EPAy4F3pXkD6vqim6+GeDZwNtuSnFJbsno2X9HVdV9gLcCt7wJi/zpTalH0s2bQUzSpPk0cIsk62ZHJLkvsGZsntsD36uqXwJPY/RgZJLsC/ygqt7KKHA9MMkdgN2q6kPASxldCtxVnwSelWT3bvm/xnWh68dJ9qS7sb+qrgSu7C5zwugLALM+NzvcXZK8G3D+IuqQtEIZxCRNlKoq4PHAoV33FZuBVwDfH5vtTcAfdTfF34vrzipNA19N8hXgD4DXA3sDM0nOZnR58CWLKOdtwHeAc7p1PbkLXG8Fvg6czuhy6KynAyd368qcenfrLmWeAhxbVVcvog5JK1RGn3mSJElabp4RkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmSpEYMYpIkSY0YxCRJkhoxiEmSJDXy/wNPsQNbC7UgbAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sgwPunXMHXD",
        "colab_type": "code",
        "outputId": "feee75bb-61f1-4327-e2ea-a8f04daa64fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "df = G.sort_index()\n",
        "df['Parametros'] = df[['Features','Classificador']].fillna('').apply(lambda x: '\\n'.join((x).astype(str)), axis=1)\n",
        "conf = [df['recall_ic_sup'].array , df['recall_ic_inf'].array]\n",
        "means = df['recall_avg'].array\n",
        "ic = [conf[0]-means , means-conf[1]]\n",
        "g = plt.bar(df['Parametros'].array, df['recall_avg'].array, yerr=ic,width=0.9,zorder=2)\n",
        "plt.grid()\n",
        "g[0].set_color('g')\n",
        "g[4].set_color('g')\n",
        "g[8].set_color('g')\n",
        "g[12].set_color('g')\n",
        "plt.title(\"Recall_avg\")\n",
        "plt.ylabel('Recall_avg')\n",
        "plt.xlabel('Classificador')\n",
        "plt.yticks(np.arange(0, 1.1, .1))\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "plt.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}