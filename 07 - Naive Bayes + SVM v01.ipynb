{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/carlaprv/sin5007-reconhecimento-de-padroes/blob/master/06%20-%20k-fold%20cross%20validation%20%2B%20naive%20Bayes%20v05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikayTX9-yVZk"
   },
   "source": [
    "# Naive Bayes + SVM\n",
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KiZnnw89yVZm"
   },
   "source": [
    "# Bibliotecas Necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7xYCeWYlyVZn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import seaborn as sns # visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRJncBBWyVZt"
   },
   "source": [
    "# Funções Auxiliares\n",
    "\n",
    "describe_dataset() : realiza o cálculo das proporções de classes do dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KutB_XTYyVZu"
   },
   "outputs": [],
   "source": [
    "def describe_dataset(X, y, k):\n",
    "    # get dataset rows: instances , columns: features\n",
    "    rows, columns = X.shape\n",
    "    # get proportion from target\n",
    "    (unique, counts) = np.unique(y, return_counts=True) \n",
    "    # calculate proportion\n",
    "    prop_neg = int(counts[0]/rows*100)\n",
    "    prop_pos = int(counts[1]/rows*100)\n",
    "\n",
    "    print(\"k = {}, Dataset: {} positivas, {} negativas ({}% x {}%)\".format(k, counts[1], counts[0], prop_pos, prop_neg))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Z4wMlsnyVZz"
   },
   "source": [
    "get_classes_from_index() : realiza o cálculo das proporções de classes dos folds criados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEZ4jxJKyVZ0"
   },
   "outputs": [],
   "source": [
    "def get_classes_from_index(y, skf):\n",
    "    _, y_idx, y_inv = np.unique(y, return_index=True, return_inverse=True)\n",
    "    y_counts = np.bincount(y_inv)\n",
    "    _, class_perm = np.unique(y_idx, return_inverse=True)\n",
    "    y_encoded = class_perm[y_inv]\n",
    "    y_order = np.sort(y_encoded)\n",
    "    n_classes = len(y_idx)\n",
    "    allocation = np.asarray(\n",
    "            [np.bincount(y_order[i::skf.n_splits], minlength=n_classes)\n",
    "             for i in range(skf.n_splits)])\n",
    "\n",
    "    for idx, f in enumerate(allocation):\n",
    "        count_neg = int(f[0])\n",
    "        count_pos = int(f[1])\n",
    "        total = count_neg+count_pos\n",
    "        prop_temp_neg = int(count_neg/total*100)\n",
    "        prop_temp_pos = int(count_pos/total*100)\n",
    "        print(\"Fold {}: Pos: {}, Neg: {}, Total: {}, Proporção: {}% x {}%\".format(idx, count_pos, count_neg, total, prop_temp_pos, prop_temp_neg))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_ic(): realiza o cálculo do indice de confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ic(data, alpha):\n",
    "    \n",
    "    mean_c = []\n",
    "    for result in lista_result:\n",
    "        \n",
    "        c = result[0]\n",
    "        result_c = result[1]\n",
    "        \n",
    "        # Calcula a média das medidas do parametro c\n",
    "        precision_mean = result_c['precision'].mean()\n",
    "        recall_mean = result_c['recall'].mean()\n",
    "        f1_score_mean = result_c['f1-score'].mean()\n",
    "        support_mean = result_c['support'].mean()\n",
    "        accuracy_mean = result_c['accuracy'].mean()\n",
    "\n",
    "        # Calcula as ic das medidas\n",
    "        precision_ic = sms.DescrStatsW(result_c['precision']).tconfint_mean(alpha)\n",
    "        recall_ic = sms.DescrStatsW(result_c['recall']).tconfint_mean(alpha)\n",
    "        f1_score_ic = sms.DescrStatsW(result_c['f1-score']).tconfint_mean(alpha)\n",
    "        support_ic = sms.DescrStatsW(result_c['support']).tconfint_mean(alpha)\n",
    "        accuracy_ic = sms.DescrStatsW(result_c['accuracy']).tconfint_mean(alpha)\n",
    "\n",
    "        ic = {'recall_ic' : recall_ic, 'support_ic' : support_ic, 'accuracy_ic': accuracy_ic }\n",
    "        ic = pd.DataFrame(ic, index=['inf','sup'])\n",
    "\n",
    "        # Armazena a média das medidas do parametro c\n",
    "        mean_c.append([c, precision_mean, recall_mean, f1_score_mean, support_mean, accuracy_mean])\n",
    "    \n",
    "    name_columns = ['c', 'precision_mean', 'recall_mean', 'f1_score_mean', 'support_mean', 'accuracy_mean']\n",
    "    mean_c = pd.DataFrame(mean_c, columns=name_columns)\n",
    "    return mean_c, ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ic(data, alpha):\n",
    "\n",
    "    # Calcula as ic das medidas\n",
    "    accuracy_ic = sms.DescrStatsW(data['accuracy']).tconfint_mean(alpha)\n",
    "    precision_ic = sms.DescrStatsW(data['precision']).tconfint_mean(alpha)\n",
    "    recall_ic = sms.DescrStatsW(data['recall']).tconfint_mean(alpha)\n",
    "    fscore_ic = sms.DescrStatsW(data['fscore']).tconfint_mean(alpha)\n",
    "    \n",
    "    ic = [accuracy_ic, precision_ic, recall_ic, fscore_ic]\n",
    "\n",
    "    return ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OefDdR7WyVaD"
   },
   "source": [
    "##### Parâmetros de execução do Naive Bayes\n",
    "* list_c : valores do parâmetro de ajuste de probabilidade \n",
    "\n",
    "* k_folds : número de folds para a estratificação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mss4hXMgyVaE"
   },
   "outputs": [],
   "source": [
    "list_c = [0.001, 0.10, 0.25, 0.50, 0.75, 1]\n",
    "# list_c = [0.001]\n",
    "k_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YezZQsp7yVZ5"
   },
   "outputs": [],
   "source": [
    "def execute_NB(X, y, list_c, k, dataSet):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------    \n",
    "           X : array-like, shape (n_samples, n_features)\n",
    "               Training data, where n_samples is the number of samples\n",
    "               and n_features is the number of features.\n",
    "           y : array-like, of length n_samples\n",
    "               The target variable for supervised learning problems.\n",
    "           k : int\n",
    "               Determines the number of folds.\n",
    "     dataSet : method selection (string)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### Estratifica o dataset em k folds\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    describe_dataset(X, y, k)\n",
    "    get_classes_from_index(y, skf) \n",
    "    \n",
    "    \n",
    "    ### result_c: armazena a média dos k resultados para cada c e o índice de confiança\n",
    "    result_c = []\n",
    "    result_ic = []\n",
    "    \n",
    "    \n",
    "    ### Executa o treino e teste para cada valor do parametro c\n",
    "    for c in list_c:\n",
    "        print(\"c =  {}\" .format(c))\n",
    "\n",
    "        ### create naive bayes classifier\n",
    "        clf = GaussianNB(var_smoothing = c)\n",
    "                        \n",
    "        ### resultado do fold-k\n",
    "        result_k = []\n",
    "        \n",
    "        ### Executa o treino e teste para k folds\n",
    "        fold_k = 1\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            \n",
    "            ### print(\"fold_k: {}\" .format(fold_k))\n",
    "            ### print(\"\\nTRAIN: {}  TEST: {}\".format(len(train_index), len(test_index)))\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            ### train classifier\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            ### calculate metrics\n",
    "            y_predicted = clf.predict(X_test)\n",
    "            report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
    "            report_str = metrics.classification_report(y_test, y_predicted)\n",
    "            ### print(report_str)\n",
    "            \n",
    "            all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
    "            accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
    "            precision = all_metrics[0]\n",
    "            recall = all_metrics[1]\n",
    "            fscore = all_metrics[2]\n",
    "                        \n",
    "            ### Armazena o resultado do fold k\n",
    "            result_k.append([c, fold_k, accuracy, precision, recall, fscore])\n",
    "            \n",
    "            fold_k = fold_k + 1\n",
    "                \n",
    "        \n",
    "        result_k = pd.DataFrame(result_k, columns=['c', 'fold', 'accuracy','precision','recall','fscore'])\n",
    "        print(result_k)\n",
    "        print(\"\")\n",
    "        \n",
    "        ### calcula a média das métricas dos k-folds      \n",
    "        accuracy_avg = result_k['accuracy'].mean()\n",
    "        precision_avg = result_k['precision'].mean()\n",
    "        recall_avg = result_k['recall'].mean()\n",
    "        fscore_avg = result_k['fscore'].mean()\n",
    "        \n",
    "        ### Calcula o índice de confiança dos k-folds\n",
    "        alpha = 0.05\n",
    "        ic_c = get_ic(result_k, alpha)\n",
    "        \n",
    "        ### Armazena a média dos resultados dos k-folds e o índice de confiança de cada métrica\n",
    "        result_c.append([c, accuracy_avg, precision_avg, recall_avg, fscore_avg])\n",
    "        result_ic.append(ic_c)\n",
    "        \n",
    "    ### Converte em DataFrame\n",
    "    result_c = pd.DataFrame(result_c, columns=['c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
    "    result_ic = pd.DataFrame(result_ic, columns=['accuracy_ic', 'precision_ic', 'recall_ic', 'fscore_ic'])\n",
    "    print(\"Média dos resultados de cada teste:\")\n",
    "    print(result_c)\n",
    "    print(\"\")    \n",
    "    \n",
    "    ### Armazena apenas as métricas da melhor acurácia média    \n",
    "    result = [] \n",
    "    result.append(result_c.iloc[result_c['accuracy_avg'].argmax()])    \n",
    "    result = pd.DataFrame(result, columns=['c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'], index=[dataSet])\n",
    "    \n",
    "    ### Armazena o indice de confiança da melhor acuracia\n",
    "    ic = result_ic.iloc[result_c['accuracy_avg'].argmax()]\n",
    "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
    "    ic = pd.DataFrame(ic, index=['inf','sup'])\n",
    "        \n",
    "    ### Retorna as métricas com a melhor acurácia e o índice de confiança\n",
    "    return result, ic\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RsPfCv4yVZ4"
   },
   "source": [
    "### 1.1. Naive Bayes: All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "\n",
      "c =  0.001\n",
      "       c  fold  accuracy  precision    recall    fscore\n",
      "0  0.001     1  0.569231   0.669231  0.569231  0.473250\n",
      "1  0.001     2  0.646154   0.662330  0.646154  0.624929\n",
      "2  0.001     3  0.769231   0.769906  0.769231  0.767900\n",
      "3  0.001     4  0.676923   0.680045  0.676923  0.670273\n",
      "4  0.001     5  0.723077   0.723866  0.723077  0.720671\n",
      "5  0.001     6  0.800000   0.805000  0.800000  0.797576\n",
      "6  0.001     7  0.876923   0.881657  0.876923  0.875854\n",
      "7  0.001     8  0.661538   0.661538  0.661538  0.661538\n",
      "8  0.001     9  0.676923   0.753592  0.676923  0.660773\n",
      "9  0.001    10  0.656250   0.671938  0.656250  0.653554\n",
      "\n",
      "c =  0.1\n",
      "     c  fold  accuracy  precision    recall    fscore\n",
      "0  0.1     1  0.584615   0.690004  0.584615  0.500114\n",
      "1  0.1     2  0.676923   0.713846  0.676923  0.651584\n",
      "2  0.1     3  0.753846   0.755424  0.753846  0.751708\n",
      "3  0.1     4  0.692308   0.705128  0.692308  0.680769\n",
      "4  0.1     5  0.707692   0.707377  0.707692  0.706006\n",
      "5  0.1     6  0.830769   0.830681  0.830769  0.830527\n",
      "6  0.1     7  0.907692   0.908821  0.907692  0.907383\n",
      "7  0.1     8  0.692308   0.694493  0.692308  0.692746\n",
      "8  0.1     9  0.630769   0.703054  0.630769  0.609467\n",
      "9  0.1    10  0.671875   0.684904  0.671875  0.670189\n",
      "\n",
      "c =  0.25\n",
      "      c  fold  accuracy  precision    recall    fscore\n",
      "0  0.25     1  0.569231   0.669231  0.569231  0.473250\n",
      "1  0.25     2  0.676923   0.732249  0.676923  0.644624\n",
      "2  0.25     3  0.769231   0.773077  0.769231  0.766434\n",
      "3  0.25     4  0.692308   0.705128  0.692308  0.680769\n",
      "4  0.25     5  0.676923   0.676113  0.676923  0.675060\n",
      "5  0.25     6  0.846154   0.846748  0.846154  0.845638\n",
      "6  0.25     7  0.892308   0.894962  0.892308  0.891687\n",
      "7  0.25     8  0.723077   0.722602  0.723077  0.722149\n",
      "8  0.25     9  0.615385   0.691817  0.615385  0.589992\n",
      "9  0.25    10  0.656250   0.665923  0.656250  0.655242\n",
      "\n",
      "c =  0.5\n",
      "     c  fold  accuracy  precision    recall    fscore\n",
      "0  0.5     1  0.569231   0.669231  0.569231  0.473250\n",
      "1  0.5     2  0.661538   0.748252  0.661538  0.614530\n",
      "2  0.5     3  0.753846   0.759381  0.753846  0.749888\n",
      "3  0.5     4  0.661538   0.677032  0.661538  0.643996\n",
      "4  0.5     5  0.676923   0.677308  0.676923  0.673007\n",
      "5  0.5     6  0.861538   0.863698  0.861538  0.860740\n",
      "6  0.5     7  0.907692   0.908821  0.907692  0.907383\n",
      "7  0.5     8  0.692308   0.692308  0.692308  0.689635\n",
      "8  0.5     9  0.615385   0.674123  0.615385  0.596159\n",
      "9  0.5    10  0.656250   0.661397  0.656250  0.656250\n",
      "\n",
      "c =  0.75\n",
      "      c  fold  accuracy  precision    recall    fscore\n",
      "0  0.75     1  0.569231   0.669231  0.569231  0.473250\n",
      "1  0.75     2  0.630769   0.725034  0.630769  0.568034\n",
      "2  0.75     3  0.753846   0.759381  0.753846  0.749888\n",
      "3  0.75     4  0.630769   0.646978  0.630769  0.605351\n",
      "4  0.75     5  0.676923   0.677308  0.676923  0.673007\n",
      "5  0.75     6  0.892308   0.900769  0.892308  0.891002\n",
      "6  0.75     7  0.938462   0.939857  0.938462  0.938255\n",
      "7  0.75     8  0.707692   0.709231  0.707692  0.704149\n",
      "8  0.75     9  0.646154   0.697436  0.646154  0.633287\n",
      "9  0.75    10  0.656250   0.661397  0.656250  0.656250\n",
      "\n",
      "c =  1\n",
      "   c  fold  accuracy  precision    recall    fscore\n",
      "0  1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1  1     2  0.630769   0.725034  0.630769  0.568034\n",
      "2  1     3  0.738462   0.745819  0.738462  0.733078\n",
      "3  1     4  0.615385   0.630769  0.615385  0.585219\n",
      "4  1     5  0.676923   0.680045  0.676923  0.670273\n",
      "5  1     6  0.876923   0.888837  0.876923  0.874944\n",
      "6  1     7  0.923077   0.926226  0.923077  0.922633\n",
      "7  1     8  0.692308   0.698813  0.692308  0.684418\n",
      "8  1     9  0.692308   0.730530  0.692308  0.686118\n",
      "9  1    10  0.656250   0.661397  0.656250  0.656250\n",
      "\n",
      "Média dos resultados de cada teste:\n",
      "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0  0.001      0.705625       0.727910    0.705625    0.690632\n",
      "1  0.100      0.714880       0.739373    0.714880    0.700049\n",
      "2  0.250      0.711779       0.737785    0.711779    0.694484\n",
      "3  0.500      0.705625       0.733155    0.705625    0.686484\n",
      "4  0.750      0.710240       0.738662    0.710240    0.689247\n",
      "5  1.000      0.705625       0.732814    0.705625    0.682613\n",
      "\n",
      "Melhor resultado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All Features</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.71488</td>\n",
       "      <td>0.739373</td>\n",
       "      <td>0.71488</td>\n",
       "      <td>0.700049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "All Features  0.1       0.71488       0.739373     0.71488    0.700049"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-normalizado.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "result_NB_all, ic_NB_all = execute_NB(X, y, list_c, k=k_folds, dataSet='All Features')\n",
    "print(\"Melhor resultado:\")\n",
    "result_NB_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Índice de Confiança do melhor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_ic</th>\n",
       "      <th>precision_ic</th>\n",
       "      <th>recall_ic</th>\n",
       "      <th>fscore_ic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>0.647212</td>\n",
       "      <td>0.686647</td>\n",
       "      <td>0.647212</td>\n",
       "      <td>0.619341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>0.782547</td>\n",
       "      <td>0.792099</td>\n",
       "      <td>0.782547</td>\n",
       "      <td>0.780758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
       "inf     0.647212      0.686647   0.647212   0.619341\n",
       "sup     0.782547      0.792099   0.782547   0.780758"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic_NB_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Naive Bayes: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "\n",
      "c =  0.001\n",
      "       c  fold  accuracy  precision    recall    fscore\n",
      "0  0.001     1  0.600000   0.773333  0.600000  0.510875\n",
      "1  0.001     2  0.646154   0.686391  0.646154  0.610779\n",
      "2  0.001     3  0.815385   0.815711  0.815385  0.814766\n",
      "3  0.001     4  0.630769   0.639935  0.630769  0.611632\n",
      "4  0.001     5  0.646154   0.645447  0.646154  0.645647\n",
      "5  0.001     6  0.800000   0.800759  0.800000  0.800190\n",
      "6  0.001     7  0.815385   0.815385  0.815385  0.815385\n",
      "7  0.001     8  0.615385   0.633136  0.615385  0.612095\n",
      "8  0.001     9  0.646154   0.762443  0.646154  0.616199\n",
      "9  0.001    10  0.609375   0.651864  0.609375  0.593160\n",
      "\n",
      "c =  0.1\n",
      "     c  fold  accuracy  precision    recall    fscore\n",
      "0  0.1     1  0.553846   0.759219  0.553846  0.424502\n",
      "1  0.1     2  0.615385   0.676282  0.615385  0.556213\n",
      "2  0.1     3  0.800000   0.811594  0.800000  0.795883\n",
      "3  0.1     4  0.615385   0.640533  0.615385  0.576933\n",
      "4  0.1     5  0.600000   0.598309  0.600000  0.589744\n",
      "5  0.1     6  0.784615   0.784615  0.784615  0.784615\n",
      "6  0.1     7  0.830769   0.830681  0.830769  0.830527\n",
      "7  0.1     8  0.661538   0.663753  0.661538  0.662020\n",
      "8  0.1     9  0.661538   0.724344  0.661538  0.647024\n",
      "9  0.1    10  0.625000   0.645833  0.625000  0.619458\n",
      "\n",
      "c =  0.25\n",
      "      c  fold  accuracy  precision    recall    fscore\n",
      "0  0.25     1  0.538462   0.754808  0.538462  0.392759\n",
      "1  0.25     2  0.615385   0.711254  0.615385  0.543402\n",
      "2  0.25     3  0.784615   0.799317  0.784615  0.779093\n",
      "3  0.25     4  0.584615   0.615385  0.584615  0.520710\n",
      "4  0.25     5  0.615385   0.619257  0.615385  0.598329\n",
      "5  0.25     6  0.784615   0.791745  0.784615  0.781152\n",
      "6  0.25     7  0.830769   0.836923  0.830769  0.828718\n",
      "7  0.25     8  0.723077   0.723866  0.723077  0.720671\n",
      "8  0.25     9  0.692308   0.744755  0.692308  0.682952\n",
      "9  0.25    10  0.656250   0.658203  0.656250  0.656586\n",
      "\n",
      "c =  0.5\n",
      "     c  fold  accuracy  precision    recall    fscore\n",
      "0  0.5     1  0.538462   0.754808  0.538462  0.392759\n",
      "1  0.5     2  0.615385   0.711254  0.615385  0.543402\n",
      "2  0.5     3  0.738462   0.763246  0.738462  0.726864\n",
      "3  0.5     4  0.569231   0.608866  0.569231  0.480633\n",
      "4  0.5     5  0.646154   0.662330  0.646154  0.624929\n",
      "5  0.5     6  0.800000   0.821429  0.800000  0.793745\n",
      "6  0.5     7  0.861538   0.877369  0.861538  0.858688\n",
      "7  0.5     8  0.707692   0.718781  0.707692  0.698551\n",
      "8  0.5     9  0.723077   0.764931  0.723077  0.717507\n",
      "9  0.5    10  0.671875   0.672685  0.671875  0.672116\n",
      "\n",
      "c =  0.75\n",
      "      c  fold  accuracy  precision    recall    fscore\n",
      "0  0.75     1  0.523077   0.273609  0.523077  0.359285\n",
      "1  0.75     2  0.615385   0.711254  0.615385  0.543402\n",
      "2  0.75     3  0.723077   0.751227  0.723077  0.708724\n",
      "3  0.75     4  0.569231   0.608866  0.569231  0.480633\n",
      "4  0.75     5  0.646154   0.672308  0.646154  0.618401\n",
      "5  0.75     6  0.784615   0.810256  0.784615  0.776538\n",
      "6  0.75     7  0.861538   0.889860  0.861538  0.857208\n",
      "7  0.75     8  0.692308   0.705128  0.692308  0.680769\n",
      "8  0.75     9  0.738462   0.763314  0.738462  0.736225\n",
      "9  0.75    10  0.656250   0.656250  0.656250  0.656250\n",
      "\n",
      "c =  1\n",
      "   c  fold  accuracy  precision    recall    fscore\n",
      "0  1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1  1     2  0.615385   0.711254  0.615385  0.543402\n",
      "2  1     3  0.707692   0.739065  0.707692  0.690158\n",
      "3  1     4  0.553846   0.573077  0.553846  0.453210\n",
      "4  1     5  0.661538   0.700496  0.661538  0.631485\n",
      "5  1     6  0.753846   0.788325  0.753846  0.741088\n",
      "6  1     7  0.861538   0.889860  0.861538  0.857208\n",
      "7  1     8  0.661538   0.677032  0.661538  0.643996\n",
      "8  1     9  0.769231   0.778388  0.769231  0.769231\n",
      "9  1    10  0.671875   0.671398  0.671875  0.671472\n",
      "\n",
      "Média dos resultados de cada teste:\n",
      "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0  0.001      0.682476       0.722440    0.682476    0.663073\n",
      "1  0.100      0.674808       0.713516    0.674808    0.648692\n",
      "2  0.250      0.682548       0.725551    0.682548    0.650437\n",
      "3  0.500      0.687188       0.735570    0.687188    0.650919\n",
      "4  0.750      0.681010       0.684207    0.681010    0.641744\n",
      "5  1.000      0.677957       0.680250    0.677957    0.636054\n",
      "\n",
      "Melhor resultado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCA</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.687188</td>\n",
       "      <td>0.73557</td>\n",
       "      <td>0.687188</td>\n",
       "      <td>0.650919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "PCA  0.5      0.687188        0.73557    0.687188    0.650919"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-pca.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "result_NB_pca, ic_NB_pca = execute_NB(X, y, list_c, k=k_folds, dataSet='PCA')\n",
    "print(\"Melhor resultado:\")\n",
    "result_NB_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Índice de Confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_ic</th>\n",
       "      <th>precision_ic</th>\n",
       "      <th>recall_ic</th>\n",
       "      <th>fscore_ic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>0.615426</td>\n",
       "      <td>0.679282</td>\n",
       "      <td>0.615426</td>\n",
       "      <td>0.548533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.791858</td>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.753306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
       "inf     0.615426      0.679282   0.615426   0.548533\n",
       "sup     0.758949      0.791858   0.758949   0.753306"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic_NB_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Naive Bayes: Chi Squared (K-Best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "\n",
      "c =  0.001\n",
      "       c  fold  accuracy  precision    recall    fscore\n",
      "0  0.001     1  0.584615   0.690004  0.584615  0.500114\n",
      "1  0.001     2  0.692308   0.744021  0.692308  0.664986\n",
      "2  0.001     3  0.815385   0.815711  0.815385  0.814766\n",
      "3  0.001     4  0.723077   0.740171  0.723077  0.712692\n",
      "4  0.001     5  0.707692   0.707377  0.707692  0.706006\n",
      "5  0.001     6  0.861538   0.863698  0.861538  0.860740\n",
      "6  0.001     7  0.907692   0.913215  0.907692  0.906890\n",
      "7  0.001     8  0.723077   0.723077  0.723077  0.723077\n",
      "8  0.001     9  0.707692   0.793326  0.707692  0.693081\n",
      "9  0.001    10  0.687500   0.697917  0.687500  0.686584\n",
      "\n",
      "c =  0.1\n",
      "     c  fold  accuracy  precision    recall    fscore\n",
      "0  0.1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1  0.1     2  0.646154   0.686391  0.646154  0.610779\n",
      "2  0.1     3  0.753846   0.753638  0.753846  0.753021\n",
      "3  0.1     4  0.692308   0.705128  0.692308  0.680769\n",
      "4  0.1     5  0.707692   0.707377  0.707692  0.706006\n",
      "5  0.1     6  0.861538   0.863698  0.861538  0.860740\n",
      "6  0.1     7  0.969231   0.969231  0.969231  0.969231\n",
      "7  0.1     8  0.738462   0.742351  0.738462  0.738833\n",
      "8  0.1     9  0.676923   0.777963  0.676923  0.655593\n",
      "9  0.1    10  0.687500   0.697917  0.687500  0.686584\n",
      "\n",
      "c =  0.25\n",
      "      c  fold  accuracy  precision    recall    fscore\n",
      "0  0.25     1  0.553846   0.640668  0.553846  0.445159\n",
      "1  0.25     2  0.615385   0.654753  0.615385  0.567321\n",
      "2  0.25     3  0.753846   0.753638  0.753846  0.753021\n",
      "3  0.25     4  0.692308   0.705128  0.692308  0.680769\n",
      "4  0.25     5  0.707692   0.707377  0.707692  0.706006\n",
      "5  0.25     6  0.830769   0.832434  0.830769  0.829793\n",
      "6  0.25     7  0.969231   0.969231  0.969231  0.969231\n",
      "7  0.25     8  0.753846   0.755973  0.753846  0.754196\n",
      "8  0.25     9  0.692308   0.785633  0.692308  0.674556\n",
      "9  0.25    10  0.656250   0.665923  0.656250  0.655242\n",
      "\n",
      "c =  0.5\n",
      "     c  fold  accuracy  precision    recall    fscore\n",
      "0  0.5     1  0.553846   0.640668  0.553846  0.445159\n",
      "1  0.5     2  0.615385   0.654753  0.615385  0.567321\n",
      "2  0.5     3  0.753846   0.755424  0.753846  0.751708\n",
      "3  0.5     4  0.676923   0.700698  0.676923  0.657543\n",
      "4  0.5     5  0.692308   0.694653  0.692308  0.687359\n",
      "5  0.5     6  0.861538   0.868846  0.861538  0.859860\n",
      "6  0.5     7  0.969231   0.970894  0.969231  0.969128\n",
      "7  0.5     8  0.784615   0.786713  0.784615  0.784922\n",
      "8  0.5     9  0.692308   0.785633  0.692308  0.674556\n",
      "9  0.5    10  0.671875   0.679341  0.671875  0.671474\n",
      "\n",
      "c =  0.75\n",
      "      c  fold  accuracy  precision    recall    fscore\n",
      "0  0.75     1  0.553846   0.640668  0.553846  0.445159\n",
      "1  0.75     2  0.630769   0.692308  0.630769  0.579487\n",
      "2  0.75     3  0.738462   0.741154  0.738462  0.735291\n",
      "3  0.75     4  0.676923   0.700698  0.676923  0.657543\n",
      "4  0.75     5  0.676923   0.680045  0.676923  0.670273\n",
      "5  0.75     6  0.861538   0.868846  0.861538  0.859860\n",
      "6  0.75     7  0.953846   0.957490  0.953846  0.953580\n",
      "7  0.75     8  0.784615   0.784615  0.784615  0.784615\n",
      "8  0.75     9  0.692308   0.785633  0.692308  0.674556\n",
      "9  0.75    10  0.656250   0.661397  0.656250  0.656250\n",
      "\n",
      "c =  1\n",
      "   c  fold  accuracy  precision    recall    fscore\n",
      "0  1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1  1     2  0.630769   0.692308  0.630769  0.579487\n",
      "2  1     3  0.723077   0.727017  0.723077  0.718623\n",
      "3  1     4  0.646154   0.672308  0.646154  0.618401\n",
      "4  1     5  0.676923   0.680045  0.676923  0.670273\n",
      "5  1     6  0.861538   0.868846  0.861538  0.859860\n",
      "6  1     7  0.953846   0.957490  0.953846  0.953580\n",
      "7  1     8  0.784615   0.784675  0.784615  0.783893\n",
      "8  1     9  0.676923   0.753592  0.676923  0.660773\n",
      "9  1    10  0.656250   0.661397  0.656250  0.656250\n",
      "\n",
      "Média dos resultados de cada teste:\n",
      "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0  0.001      0.741058       0.768852    0.741058    0.726894\n",
      "1  0.100      0.728750       0.754436    0.728750    0.710671\n",
      "2  0.250      0.722548       0.747076    0.722548    0.703529\n",
      "3  0.500      0.727187       0.753762    0.727187    0.706903\n",
      "4  0.750      0.722548       0.751285    0.722548    0.701662\n",
      "5  1.000      0.716394       0.743834    0.716394    0.694630\n",
      "\n",
      "Melhor resultado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chi</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.741058</td>\n",
       "      <td>0.768852</td>\n",
       "      <td>0.741058</td>\n",
       "      <td>0.726894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "Chi  0.001      0.741058       0.768852    0.741058    0.726894"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-fs-chi-squared.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "result_NB_chi, ic_NB_chi = execute_NB(X, y, list_c, k=k_folds, dataSet='Chi')\n",
    "print(\"Melhor resultado:\")\n",
    "result_NB_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Índice de Confiança para o dataset Chi-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_ic</th>\n",
       "      <th>precision_ic</th>\n",
       "      <th>recall_ic</th>\n",
       "      <th>fscore_ic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>0.673445</td>\n",
       "      <td>0.714899</td>\n",
       "      <td>0.673445</td>\n",
       "      <td>0.645429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>0.808670</td>\n",
       "      <td>0.822804</td>\n",
       "      <td>0.808670</td>\n",
       "      <td>0.808358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
       "inf     0.673445      0.714899   0.673445   0.645429\n",
       "sup     0.808670      0.822804   0.808670   0.808358"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic_NB_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Naive Bayes: Recursive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "\n",
      "c =  0.001\n",
      "       c  fold  accuracy  precision    recall    fscore\n",
      "0  0.001     1  0.584615   0.768474  0.584615  0.483424\n",
      "1  0.001     2  0.676923   0.713846  0.676923  0.651584\n",
      "2  0.001     3  0.800000   0.811594  0.800000  0.795883\n",
      "3  0.001     4  0.646154   0.650350  0.646154  0.635088\n",
      "4  0.001     5  0.769231   0.787213  0.769231  0.762014\n",
      "5  0.001     6  0.800000   0.811594  0.800000  0.795883\n",
      "6  0.001     7  0.892308   0.900769  0.892308  0.891002\n",
      "7  0.001     8  0.661538   0.670085  0.661538  0.648846\n",
      "8  0.001     9  0.769231   0.785863  0.769231  0.768465\n",
      "9  0.001    10  0.718750   0.720703  0.718750  0.719025\n",
      "\n",
      "c =  0.1\n",
      "     c  fold  accuracy  precision    recall    fscore\n",
      "0  0.1     1  0.538462   0.596361  0.538462  0.415724\n",
      "1  0.1     2  0.676923   0.758612  0.676923  0.636550\n",
      "2  0.1     3  0.753846   0.775214  0.753846  0.744615\n",
      "3  0.1     4  0.676923   0.713846  0.676923  0.651584\n",
      "4  0.1     5  0.769231   0.778707  0.769231  0.764481\n",
      "5  0.1     6  0.830769   0.855644  0.830769  0.825477\n",
      "6  0.1     7  0.892308   0.900769  0.892308  0.891002\n",
      "7  0.1     8  0.676923   0.691252  0.676923  0.662597\n",
      "8  0.1     9  0.769231   0.808787  0.769231  0.765595\n",
      "9  0.1    10  0.703125   0.703904  0.703125  0.703343\n",
      "\n",
      "c =  0.25\n",
      "      c  fold  accuracy  precision    recall    fscore\n",
      "0  0.25     1  0.538462   0.596361  0.538462  0.415724\n",
      "1  0.25     2  0.630769   0.725034  0.630769  0.568034\n",
      "2  0.25     3  0.753846   0.775214  0.753846  0.744615\n",
      "3  0.25     4  0.676923   0.732249  0.676923  0.644624\n",
      "4  0.25     5  0.753846   0.775214  0.753846  0.744615\n",
      "5  0.25     6  0.815385   0.862520  0.815385  0.805816\n",
      "6  0.25     7  0.876923   0.888837  0.876923  0.874944\n",
      "7  0.25     8  0.707692   0.739065  0.707692  0.690158\n",
      "8  0.25     9  0.769231   0.795858  0.769231  0.767257\n",
      "9  0.25    10  0.718750   0.720703  0.718750  0.719025\n",
      "\n",
      "c =  0.5\n",
      "     c  fold  accuracy  precision    recall    fscore\n",
      "0  0.5     1  0.553846   0.759219  0.553846  0.424502\n",
      "1  0.5     2  0.600000   0.694915  0.600000  0.517730\n",
      "2  0.5     3  0.723077   0.766484  0.723077  0.704013\n",
      "3  0.5     4  0.646154   0.706682  0.646154  0.601935\n",
      "4  0.5     5  0.769231   0.815799  0.769231  0.755388\n",
      "5  0.5     6  0.815385   0.862520  0.815385  0.805816\n",
      "6  0.5     7  0.892308   0.910256  0.892308  0.890091\n",
      "7  0.5     8  0.707692   0.739065  0.707692  0.690158\n",
      "8  0.5     9  0.753846   0.766136  0.753846  0.753497\n",
      "9  0.5    10  0.703125   0.703904  0.703125  0.703343\n",
      "\n",
      "c =  0.75\n",
      "      c  fold  accuracy  precision    recall    fscore\n",
      "0  0.75     1  0.553846   0.759219  0.553846  0.424502\n",
      "1  0.75     2  0.600000   0.694915  0.600000  0.517730\n",
      "2  0.75     3  0.723077   0.787546  0.723077  0.698488\n",
      "3  0.75     4  0.646154   0.706682  0.646154  0.601935\n",
      "4  0.75     5  0.753846   0.806319  0.753846  0.736901\n",
      "5  0.75     6  0.800000   0.854167  0.800000  0.788003\n",
      "6  0.75     7  0.892308   0.910256  0.892308  0.890091\n",
      "7  0.75     8  0.692308   0.726648  0.692308  0.671126\n",
      "8  0.75     9  0.753846   0.760035  0.753846  0.754079\n",
      "9  0.75    10  0.687500   0.687500  0.687500  0.687500\n",
      "\n",
      "c =  1\n",
      "   c  fold  accuracy  precision    recall    fscore\n",
      "0  1     1  0.553846   0.759219  0.553846  0.424502\n",
      "1  1     2  0.600000   0.694915  0.600000  0.517730\n",
      "2  1     3  0.723077   0.817126  0.723077  0.692058\n",
      "3  1     4  0.630769   0.692308  0.630769  0.579487\n",
      "4  1     5  0.723077   0.787546  0.723077  0.698488\n",
      "5  1     6  0.800000   0.854167  0.800000  0.788003\n",
      "6  1     7  0.876923   0.899821  0.876923  0.873767\n",
      "7  1     8  0.676923   0.713846  0.676923  0.651584\n",
      "8  1     9  0.769231   0.770034  0.769231  0.769450\n",
      "9  1    10  0.671875   0.671398  0.671875  0.671472\n",
      "\n",
      "Média dos resultados de cada teste:\n",
      "       c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0  0.001      0.731875       0.762049    0.731875    0.715121\n",
      "1  0.100      0.728774       0.758309    0.728774    0.706097\n",
      "2  0.250      0.724183       0.761105    0.724183    0.697481\n",
      "3  0.500      0.716466       0.772498    0.716466    0.684647\n",
      "4  0.750      0.710288       0.769329    0.710288    0.677036\n",
      "5  1.000      0.702572       0.766038    0.702572    0.666654\n",
      "\n",
      "Melhor resultado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recursive</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.731875</td>\n",
       "      <td>0.762049</td>\n",
       "      <td>0.731875</td>\n",
       "      <td>0.715121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "Recursive  0.001      0.731875       0.762049    0.731875    0.715121"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-fs-recursive-feature.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "result_NB_rf, ic_NB_rf = execute_NB(X, y, list_c, k=k_folds, dataSet='Recursive')\n",
    "print(\"Melhor resultado:\")\n",
    "result_NB_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Índice de Confiança para dataset Recursive-Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_ic</th>\n",
       "      <th>precision_ic</th>\n",
       "      <th>recall_ic</th>\n",
       "      <th>fscore_ic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>0.666579</td>\n",
       "      <td>0.708537</td>\n",
       "      <td>0.666579</td>\n",
       "      <td>0.633364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>0.797171</td>\n",
       "      <td>0.815561</td>\n",
       "      <td>0.797171</td>\n",
       "      <td>0.796879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
       "inf     0.666579      0.708537   0.666579   0.633364\n",
       "sup     0.797171      0.815561   0.797171   0.796879"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic_NB_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parâmetros de execução do SVM\n",
    "\n",
    "* k_folds:     número de folds para a estratificação do dataset\n",
    "\n",
    "* list_c:      valores do parâmetro de ajuste de probabilidade \n",
    "\n",
    "* list_degree: valores do parâmetro degree utilizado no kernel poly\n",
    "\n",
    "* list_gamma:  valores do parâmetro gamma utilizado no kernel poly\n",
    "\n",
    "* list_coef:   valores do parâmetro coef utilizado no kernel rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Função que aplica o SVM para cada Kernel implementado\n",
    "* Em cada kernel é testado vários valores de cada parâmetro.\n",
    "* Com o resultado de cada parâmetro, verifica qual a melhor acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_SVM(X, y, k, list_c, list_degree, list_gamma, list_coef, dataSet):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------    \n",
    "              X: array-like, shape (n_samples, n_features)\n",
    "                 Training data, where n_samples is the number of samples\n",
    "                 and n_features is the number of features.\n",
    "              y: array-like, of length n_samples\n",
    "                 The target variable for supervised learning problems.\n",
    "              k: int\n",
    "                 Determines the number of folds.\n",
    "        dataSet: method selection (string)\n",
    "         list_c: values of parameter c\n",
    "    list_degree: values of parameter degree\n",
    "     list_gamma: values of parameter gamma\n",
    "      list_coef: values of parameter coef\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Resultados\n",
    "    result = []              # result:             melhor resultado geral do SVM\n",
    "    result_best_linear = []  # result_best_linear: melhor resultado do kernel linear\n",
    "    result_best_poly = []    # result_best_poly:   melhor resultado do kernel poly\n",
    "    result_best_rbf = []     # result_best_rbf:    melhor resultado do kernel rbf\n",
    "\n",
    "\n",
    "    ### Estratifica o dataset em k folds\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    describe_dataset(X, y, k)\n",
    "    get_classes_from_index(y, skf) \n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    # 1. KERNEL LINEAR\n",
    "    #################################################################################################################\n",
    "    result_linear = []\n",
    "    result_linear_ic = []\n",
    "    for C in list_c:\n",
    "        \n",
    "        ### Create a SVM Linear Classifier\n",
    "        model_linear = svm.SVC(kernel='linear', C=C)\n",
    "        kernel = model_linear.kernel\n",
    "        \n",
    "        ### resultado do fold-k\n",
    "        result_k = []\n",
    "        \n",
    "        fold_k = 1\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "            ### Train the model\n",
    "            model_linear.fit(X_train, y_train)\n",
    "    \n",
    "            ### Test the model\n",
    "            y_predicted = model_linear.predict(X_test)\n",
    "            \n",
    "            ### calculate metrics\n",
    "            report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
    "            report_str = metrics.classification_report(y_test, y_predicted)        \n",
    "            ### print(report_str)\n",
    "            \n",
    "            all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
    "            accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
    "            precision = all_metrics[0]\n",
    "            recall = all_metrics[1]\n",
    "            fscore = all_metrics[2]\n",
    "                        \n",
    "            ### Armazena o resultado do fold k\n",
    "            result_k.append([kernel, C, fold_k, accuracy, precision, recall, fscore])\n",
    "            \n",
    "            fold_k = fold_k + 1\n",
    "    \n",
    "        result_k = pd.DataFrame(result_k, columns=['kernel', 'c', 'fold', 'accuracy','precision','recall','fscore'])\n",
    "        print(result_k)\n",
    "        print(\"\")\n",
    "        \n",
    "        ### calcula a média das métricas dos k-folds      \n",
    "        accuracy_avg = result_k['accuracy'].mean()\n",
    "        precision_avg = result_k['precision'].mean()\n",
    "        recall_avg = result_k['recall'].mean()\n",
    "        fscore_avg = result_k['fscore'].mean()\n",
    "        \n",
    "        ### Calcula o índice de confiança dos k-folds\n",
    "        alpha = 0.05\n",
    "        ic_c = get_ic(result_k, alpha)\n",
    "        \n",
    "        ### Armazena a média dos resultados dos k-folds e o índice de confiança\n",
    "        result_linear.append([kernel, C, accuracy_avg, precision_avg, recall_avg, fscore_avg]) \n",
    "        result_linear_ic.append(ic_c)\n",
    "\n",
    "    \n",
    "    ### Exibe os resultados de cada valor c\n",
    "    result_linear = pd.DataFrame(result_linear, columns=['kernel', 'c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
    "    result_linear_ic = pd.DataFrame(result_linear_ic, columns=['accuracy_ic','precision_ic','recall_ic','fscore_ic'])\n",
    "    print(\"Média dos resultados do kernel linear\")\n",
    "    print(result_linear)\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    # 2.KERNEL POLY\n",
    "    #################################################################################################################\n",
    "    result_poly = []\n",
    "    result_poly_ic = []\n",
    "    for C in list_c:\n",
    "        for gamma in list_gamma:\n",
    "            for degree in list_degree:\n",
    "                \n",
    "                ### Create a SVM Linear Classifier\n",
    "                model_poly = svm.SVC(kernel='poly', degree=degree, gamma=gamma, C=C)\n",
    "                kernel = model_poly.kernel\n",
    "                \n",
    "                ### resultado do fold-k\n",
    "                result_k = []\n",
    "                \n",
    "                fold_k = 1\n",
    "                for train_index, test_index in skf.split(X, y):\n",
    "                    X_train, X_test = X[train_index], X[test_index]\n",
    "                    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                    ### Train the model\n",
    "                    model_poly.fit(X_train, y_train)\n",
    "\n",
    "                    ### Test the model\n",
    "                    y_predicted = model_poly.predict(X_test)\n",
    "\n",
    "                    ### calculate metrics\n",
    "                    report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
    "                    report_str = metrics.classification_report(y_test, y_predicted)        \n",
    "                    ### print(report_str)\n",
    "\n",
    "                    all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
    "                    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
    "                    precision = all_metrics[0]\n",
    "                    recall = all_metrics[1]\n",
    "                    fscore = all_metrics[2]\n",
    "\n",
    "                    ### Armazena o resultado do fold k\n",
    "                    result_k.append([kernel, C, gamma, degree, fold_k, accuracy, precision, recall, fscore])\n",
    "\n",
    "                    fold_k = fold_k + 1\n",
    "\n",
    "                result_k = pd.DataFrame(result_k, columns=['kernel', 'c', 'gamma', 'degree', 'fold', 'accuracy','precision','recall','fscore'])\n",
    "                print(result_k)\n",
    "                print(\"\")\n",
    "                \n",
    "                ### calcula a média das métricas dos k-folds      \n",
    "                accuracy_avg = result_k['accuracy'].mean()\n",
    "                precision_avg = result_k['precision'].mean()\n",
    "                recall_avg = result_k['recall'].mean()\n",
    "                fscore_avg = result_k['fscore'].mean()\n",
    "\n",
    "                ### Calcula o índice de confiança dos k-folds\n",
    "                alpha = 0.05\n",
    "                ic_c = get_ic(result_k, alpha)\n",
    "\n",
    "                ### Armazena a média dos resultados dos k-folds e o índice de confiança\n",
    "                result_poly.append([kernel, C, gamma, degree, accuracy_avg, precision_avg, recall_avg, fscore_avg]) \n",
    "                result_poly_ic.append(ic_c)\n",
    "    \n",
    "    ### Exibe os resultados de cada valor c\n",
    "    result_poly = pd.DataFrame(result_poly, columns=['kernel', 'c', 'gamma', 'degree', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
    "    result_poly_ic = pd.DataFrame(result_poly_ic, columns=['accuracy_ic','precision_ic','recall_ic','fscore_ic'])\n",
    "    print(\"Média dos resultados do kernel poly\")\n",
    "    print(result_poly)\n",
    "    print(\"\")            \n",
    "        \n",
    "        \n",
    "    #################################################################################################################\n",
    "    ### 3. KERNEL RBF\n",
    "    #################################################################################################################\n",
    "    result_rbf = []\n",
    "    result_rbf_ic = []\n",
    "    for C in list_c:\n",
    "        for gamma in list_gamma:\n",
    "            ### Create a SVM Linear Classifier\n",
    "            model_rbf = svm.SVC(kernel='rbf', gamma=gamma, C=C)   \n",
    "            kernel = model_rbf.kernel\n",
    "                \n",
    "            ### resultado do fold-k\n",
    "            result_k = []\n",
    "\n",
    "            fold_k = 1\n",
    "            \n",
    "            for train_index, test_index in skf.split(X, y):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                ### Train the model\n",
    "                model_rbf.fit(X_train, y_train)\n",
    "\n",
    "                ### Test the model\n",
    "                y_predicted = model_rbf.predict(X_test)\n",
    "\n",
    "                ### calculate metrics\n",
    "                report_dict = metrics.classification_report(y_test, y_predicted, output_dict=True)\n",
    "                report_str = metrics.classification_report(y_test, y_predicted)        \n",
    "                ### print(report_str)\n",
    "\n",
    "                all_metrics = precision_recall_fscore_support(y_true=y_test, y_pred=y_predicted, average='weighted')\n",
    "                accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)\n",
    "                precision = all_metrics[0]\n",
    "                recall = all_metrics[1]\n",
    "                fscore = all_metrics[2]\n",
    "\n",
    "                ### Armazena o resultado do fold k\n",
    "                result_k.append([kernel, C, gamma, fold_k, accuracy, precision, recall, fscore])\n",
    "\n",
    "                fold_k = fold_k + 1\n",
    "\n",
    "            result_k = pd.DataFrame(result_k, columns=['kernel', 'c', 'gamma', 'fold', 'accuracy','precision','recall','fscore'])\n",
    "            print(result_k)\n",
    "            print(\"\")           \n",
    "            \n",
    "            ### calcula a média das métricas dos k-folds      \n",
    "            accuracy_avg = result_k['accuracy'].mean()\n",
    "            precision_avg = result_k['precision'].mean()\n",
    "            recall_avg = result_k['recall'].mean()\n",
    "            fscore_avg = result_k['fscore'].mean()\n",
    "\n",
    "            ### Calcula o índice de confiança dos k-folds\n",
    "            alpha = 0.05\n",
    "            ic_c = get_ic(result_k, alpha)\n",
    "\n",
    "            ### Armazena a média dos resultados dos k-folds e o índice de confiança\n",
    "            result_rbf.append([kernel, C, gamma, accuracy_avg, precision_avg, recall_avg, fscore_avg]) \n",
    "            result_rbf_ic.append(ic_c)\n",
    "    \n",
    "    ### Exibe os resultados de cada valor c\n",
    "    result_rbf = pd.DataFrame(result_rbf, columns=['kernel', 'c', 'gamma', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
    "    result_rbf_ic = pd.DataFrame(result_rbf_ic, columns=['accuracy_ic','precision_ic','recall_ic','fscore_ic'])\n",
    "    print(\"Média dos resultados do kernel rbf\")\n",
    "    print(result_rbf)\n",
    "    print(\"\")            \n",
    "           \n",
    "    \n",
    "    \n",
    "    #################################################################################################################\n",
    "    ### ARMAZENA OS MELHORES RESULTADOS \n",
    "    #################################################################################################################\n",
    "    \n",
    "    ### Armazena apenas as métricas da melhor acurácia média do MODELO LINEAR e o seu indice de confiança\n",
    "    result_best_linear.append(result_linear.iloc[result_linear['accuracy_avg'].argmax()])\n",
    "    result_best_linear = pd.DataFrame(result_best_linear, columns=['kernel', 'c', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
    "    # print(result_best_linear)\n",
    "    print(\"\")\n",
    "    \n",
    "    ic = result_linear_ic.iloc[result_linear['accuracy_avg'].argmax()]\n",
    "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
    "    ic_best_linear = pd.DataFrame(ic, index=['inf','sup'])\n",
    "    \n",
    "    \n",
    "    ### Armazena apenas as métricas da melhor acurácia média do MODELO POLY e o seu respectivo indice de confiança\n",
    "    result_best_poly.append(result_poly.iloc[result_poly['accuracy_avg'].argmax()])\n",
    "    result_best_poly = pd.DataFrame(result_best_poly, columns=['kernel', 'c', 'gamma', 'degree', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
    "    # print(result_best_poly)\n",
    "    print(\"\")\n",
    "    \n",
    "    ic = result_poly_ic.iloc[result_poly['accuracy_avg'].argmax()]\n",
    "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
    "    ic_best_poly = pd.DataFrame(ic, index=['inf','sup'])\n",
    "    \n",
    "    \n",
    "    ### Armazena apenas as métricas da melhor acurácia média do MODELO RBF e seu índice de confiança\n",
    "    result_best_rbf.append(result_rbf.iloc[result_rbf['accuracy_avg'].argmax()])\n",
    "    result_best_rbf = pd.DataFrame(result_best_rbf, columns=['kernel', 'c', 'gamma', 'accuracy_avg', 'precision_avg', 'recall_avg', 'fscore_avg'])\n",
    "    # print(result_best_rbf)\n",
    "    print(\"\")\n",
    "    \n",
    "    ic = result_rbf_ic.iloc[result_rbf['accuracy_avg'].argmax()]\n",
    "    ic = {'accuracy_ic':ic['accuracy_ic'],'precision_ic':ic['precision_ic'],'recall_ic':ic['recall_ic'],'fscore_ic':ic['fscore_ic']}\n",
    "    ic_best_rbf = pd.DataFrame(ic, index=['inf','sup'])\n",
    "    \n",
    "    \n",
    "    ### Retorna o melhor resultado de cada kernel e seus respectivos índices de confiança \n",
    "    return result_best_linear, result_best_poly, result_best_rbf, ic_best_linear, ic_best_poly, ic_best_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_c = [0.001, 0.10, 0.25, 0.50, 0.75, 1]\n",
    "list_c = [0.001, 0.10]\n",
    "list_gamma = [0.001, 0.1, 0.5, 1]\n",
    "list_degree = [1, 2, 3, 4, 5]\n",
    "\n",
    "list_coef = [0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. SVM: all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[0.001, 0.1, 0.5, 1]\n",
      "[0.001, 0.1]\n",
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "\n",
      "   kernel      c  fold  accuracy  precision    recall    fscore\n",
      "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "   kernel    c  fold  accuracy  precision    recall    fscore\n",
      "0  linear  0.1     1  0.584615   0.768474  0.584615  0.483424\n",
      "1  linear  0.1     2  0.676923   0.758612  0.676923  0.636550\n",
      "2  linear  0.1     3  0.800000   0.805000  0.800000  0.797576\n",
      "3  linear  0.1     4  0.646154   0.686391  0.646154  0.610779\n",
      "4  linear  0.1     5  0.738462   0.752997  0.738462  0.730282\n",
      "5  linear  0.1     6  0.738462   0.745819  0.738462  0.733078\n",
      "6  linear  0.1     7  0.907692   0.908821  0.907692  0.907383\n",
      "7  linear  0.1     8  0.661538   0.660750  0.661538  0.658598\n",
      "8  linear  0.1     9  0.584615   0.781377  0.584615  0.518660\n",
      "9  linear  0.1    10  0.640625   0.677291  0.640625  0.630153\n",
      "\n",
      "Média dos resultados do kernel linear\n",
      "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "1  linear  0.100      0.697909       0.754553    0.697909    0.670648\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       2     2  0.538462   0.521368  0.538462  0.402473\n",
      "2   poly  0.001    0.5       2     3  0.600000   0.657895  0.600000  0.532037\n",
      "3   poly  0.001    0.5       2     4  0.553846   0.602978  0.553846  0.433422\n",
      "4   poly  0.001    0.5       2     5  0.584615   0.636036  0.584615  0.506874\n",
      "5   poly  0.001    0.5       2     6  0.676923   0.798077  0.676923  0.627219\n",
      "6   poly  0.001    0.5       2     7  0.723077   0.817126  0.723077  0.692058\n",
      "7   poly  0.001    0.5       2     8  0.615385   0.676282  0.615385  0.556213\n",
      "8   poly  0.001    0.5       2     9  0.815385   0.815385  0.815385  0.815385\n",
      "9   poly  0.001    0.5       2    10  0.656250   0.657813  0.656250  0.651089\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       3     1  0.538462   0.596361  0.538462  0.415724\n",
      "1   poly  0.001    0.5       3     2  0.646154   0.737179  0.646154  0.591716\n",
      "2   poly  0.001    0.5       3     3  0.738462   0.752997  0.738462  0.730282\n",
      "3   poly  0.001    0.5       3     4  0.630769   0.692308  0.630769  0.579487\n",
      "4   poly  0.001    0.5       3     5  0.707692   0.718781  0.707692  0.698551\n",
      "5   poly  0.001    0.5       3     6  0.800000   0.821429  0.800000  0.793745\n",
      "6   poly  0.001    0.5       3     7  0.876923   0.888837  0.876923  0.874944\n",
      "7   poly  0.001    0.5       3     8  0.676923   0.677308  0.676923  0.673007\n",
      "8   poly  0.001    0.5       3     9  0.584615   0.692550  0.584615  0.540532\n",
      "9   poly  0.001    0.5       3    10  0.687500   0.704706  0.687500  0.685049\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       4     1  0.569231   0.607509  0.569231  0.503419\n",
      "1   poly  0.001    0.5       4     2  0.692308   0.705128  0.692308  0.680769\n",
      "2   poly  0.001    0.5       4     3  0.769231   0.778707  0.769231  0.764481\n",
      "3   poly  0.001    0.5       4     4  0.615385   0.623963  0.615385  0.592314\n",
      "4   poly  0.001    0.5       4     5  0.692308   0.692308  0.692308  0.689635\n",
      "5   poly  0.001    0.5       4     6  0.815385   0.832818  0.815385  0.810651\n",
      "6   poly  0.001    0.5       4     7  0.861538   0.862210  0.861538  0.861670\n",
      "7   poly  0.001    0.5       4     8  0.630769   0.629492  0.630769  0.629531\n",
      "8   poly  0.001    0.5       4     9  0.584615   0.667421  0.584615  0.549451\n",
      "9   poly  0.001    0.5       4    10  0.671875   0.684904  0.671875  0.670189\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       5     1  0.538462   0.538462  0.538462  0.492356\n",
      "1   poly  0.001    0.5       5     2  0.707692   0.718781  0.707692  0.698551\n",
      "2   poly  0.001    0.5       5     3  0.723077   0.727017  0.723077  0.718623\n",
      "3   poly  0.001    0.5       5     4  0.538462   0.531306  0.538462  0.526627\n",
      "4   poly  0.001    0.5       5     5  0.707692   0.707377  0.707692  0.706006\n",
      "5   poly  0.001    0.5       5     6  0.738462   0.738064  0.738462  0.738087\n",
      "6   poly  0.001    0.5       5     7  0.769231   0.778388  0.769231  0.769231\n",
      "7   poly  0.001    0.5       5     8  0.553846   0.551057  0.553846  0.551273\n",
      "8   poly  0.001    0.5       5     9  0.600000   0.661765  0.600000  0.576923\n",
      "9   poly  0.001    0.5       5    10  0.671875   0.679341  0.671875  0.671474\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       2     1  0.538462   0.596361  0.538462  0.415724\n",
      "1   poly  0.001      1       2     2  0.646154   0.737179  0.646154  0.591716\n",
      "2   poly  0.001      1       2     3  0.753846   0.765816  0.753846  0.747535\n",
      "3   poly  0.001      1       2     4  0.600000   0.657895  0.600000  0.532037\n",
      "4   poly  0.001      1       2     5  0.661538   0.670085  0.661538  0.648846\n",
      "5   poly  0.001      1       2     6  0.815385   0.832818  0.815385  0.810651\n",
      "6   poly  0.001      1       2     7  0.907692   0.913215  0.907692  0.906890\n",
      "7   poly  0.001      1       2     8  0.707692   0.707377  0.707692  0.706006\n",
      "8   poly  0.001      1       2     9  0.630769   0.754438  0.630769  0.595685\n",
      "9   poly  0.001      1       2    10  0.671875   0.692212  0.671875  0.668248\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       3     1  0.600000   0.669841  0.600000  0.538889\n",
      "1   poly  0.001      1       3     2  0.738462   0.752997  0.738462  0.730282\n",
      "2   poly  0.001      1       3     3  0.784615   0.799317  0.784615  0.779093\n",
      "3   poly  0.001      1       3     4  0.646154   0.662330  0.646154  0.624929\n",
      "4   poly  0.001      1       3     5  0.692308   0.694653  0.692308  0.687359\n",
      "5   poly  0.001      1       3     6  0.846154   0.856473  0.846154  0.843680\n",
      "6   poly  0.001      1       3     7  0.907692   0.908821  0.907692  0.907383\n",
      "7   poly  0.001      1       3     8  0.630769   0.629492  0.630769  0.629531\n",
      "8   poly  0.001      1       3     9  0.600000   0.680000  0.600000  0.570000\n",
      "9   poly  0.001      1       3    10  0.656250   0.665923  0.656250  0.655242\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       4     1  0.553846   0.564417  0.553846  0.503995\n",
      "1   poly  0.001      1       4     2  0.692308   0.705128  0.692308  0.680769\n",
      "2   poly  0.001      1       4     3  0.676923   0.676113  0.676923  0.675060\n",
      "3   poly  0.001      1       4     4  0.538462   0.532833  0.538462  0.531039\n",
      "4   poly  0.001      1       4     5  0.692308   0.691565  0.692308  0.691276\n",
      "5   poly  0.001      1       4     6  0.707692   0.708583  0.707692  0.707970\n",
      "6   poly  0.001      1       4     7  0.784615   0.790979  0.784615  0.784819\n",
      "7   poly  0.001      1       4     8  0.553846   0.551057  0.553846  0.551273\n",
      "8   poly  0.001      1       4     9  0.600000   0.661765  0.600000  0.576923\n",
      "9   poly  0.001      1       4    10  0.640625   0.652559  0.640625  0.638778\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       5     1  0.538462   0.538462  0.538462  0.492356\n",
      "1   poly  0.001      1       5     2  0.692308   0.705128  0.692308  0.680769\n",
      "2   poly  0.001      1       5     3  0.738462   0.741154  0.738462  0.735291\n",
      "3   poly  0.001      1       5     4  0.523077   0.515608  0.523077  0.513260\n",
      "4   poly  0.001      1       5     5  0.707692   0.707377  0.707692  0.706006\n",
      "5   poly  0.001      1       5     6  0.738462   0.738064  0.738462  0.738087\n",
      "6   poly  0.001      1       5     7  0.769231   0.778388  0.769231  0.769231\n",
      "7   poly  0.001      1       5     8  0.553846   0.551057  0.553846  0.551273\n",
      "8   poly  0.001      1       5     9  0.600000   0.661765  0.600000  0.576923\n",
      "9   poly  0.001      1       5    10  0.671875   0.679341  0.671875  0.671474\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       1     1  0.553846   0.759219  0.553846  0.424502\n",
      "1   poly  0.1    0.1       1     2  0.615385   0.711254  0.615385  0.543402\n",
      "2   poly  0.1    0.1       1     3  0.738462   0.745819  0.738462  0.733078\n",
      "3   poly  0.1    0.1       1     4  0.615385   0.676282  0.615385  0.556213\n",
      "4   poly  0.1    0.1       1     5  0.646154   0.662330  0.646154  0.624929\n",
      "5   poly  0.1    0.1       1     6  0.846154   0.856473  0.846154  0.843680\n",
      "6   poly  0.1    0.1       1     7  0.907692   0.913215  0.907692  0.906890\n",
      "7   poly  0.1    0.1       1     8  0.676923   0.684565  0.676923  0.666819\n",
      "8   poly  0.1    0.1       1     9  0.661538   0.770256  0.661538  0.636154\n",
      "9   poly  0.1    0.1       1    10  0.640625   0.658942  0.640625  0.636653\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       2     1  0.538462   0.596361  0.538462  0.415724\n",
      "1   poly  0.1    0.1       2     2  0.646154   0.737179  0.646154  0.591716\n",
      "2   poly  0.1    0.1       2     3  0.753846   0.765816  0.753846  0.747535\n",
      "3   poly  0.1    0.1       2     4  0.600000   0.657895  0.600000  0.532037\n",
      "4   poly  0.1    0.1       2     5  0.661538   0.670085  0.661538  0.648846\n",
      "5   poly  0.1    0.1       2     6  0.815385   0.832818  0.815385  0.810651\n",
      "6   poly  0.1    0.1       2     7  0.907692   0.913215  0.907692  0.906890\n",
      "7   poly  0.1    0.1       2     8  0.707692   0.707377  0.707692  0.706006\n",
      "8   poly  0.1    0.1       2     9  0.630769   0.754438  0.630769  0.595685\n",
      "9   poly  0.1    0.1       2    10  0.671875   0.692212  0.671875  0.668248\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       3     1  0.538462   0.596361  0.538462  0.415724\n",
      "1   poly  0.1    0.1       3     2  0.646154   0.737179  0.646154  0.591716\n",
      "2   poly  0.1    0.1       3     3  0.753846   0.765816  0.753846  0.747535\n",
      "3   poly  0.1    0.1       3     4  0.630769   0.692308  0.630769  0.579487\n",
      "4   poly  0.1    0.1       3     5  0.707692   0.718781  0.707692  0.698551\n",
      "5   poly  0.1    0.1       3     6  0.800000   0.821429  0.800000  0.793745\n",
      "6   poly  0.1    0.1       3     7  0.876923   0.888837  0.876923  0.874944\n",
      "7   poly  0.1    0.1       3     8  0.692308   0.694653  0.692308  0.687359\n",
      "8   poly  0.1    0.1       3     9  0.584615   0.692550  0.584615  0.540532\n",
      "9   poly  0.1    0.1       3    10  0.687500   0.704706  0.687500  0.685049\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       4     1  0.553846   0.759219  0.553846  0.424502\n",
      "1   poly  0.1    0.1       4     2  0.646154   0.737179  0.646154  0.591716\n",
      "2   poly  0.1    0.1       4     3  0.753846   0.765816  0.753846  0.747535\n",
      "3   poly  0.1    0.1       4     4  0.630769   0.671263  0.630769  0.589411\n",
      "4   poly  0.1    0.1       4     5  0.692308   0.705128  0.692308  0.680769\n",
      "5   poly  0.1    0.1       4     6  0.800000   0.821429  0.800000  0.793745\n",
      "6   poly  0.1    0.1       4     7  0.846154   0.856473  0.846154  0.843680\n",
      "7   poly  0.1    0.1       4     8  0.646154   0.645385  0.646154  0.641865\n",
      "8   poly  0.1    0.1       4     9  0.630769   0.725128  0.630769  0.603077\n",
      "9   poly  0.1    0.1       4    10  0.687500   0.697917  0.687500  0.686584\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       5     1  0.553846   0.759219  0.553846  0.424502\n",
      "1   poly  0.1    0.1       5     2  0.661538   0.748252  0.661538  0.614530\n",
      "2   poly  0.1    0.1       5     3  0.738462   0.763246  0.738462  0.726864\n",
      "3   poly  0.1    0.1       5     4  0.615385   0.654753  0.615385  0.567321\n",
      "4   poly  0.1    0.1       5     5  0.692308   0.714130  0.692308  0.676360\n",
      "5   poly  0.1    0.1       5     6  0.784615   0.810256  0.784615  0.776538\n",
      "6   poly  0.1    0.1       5     7  0.830769   0.836923  0.830769  0.828718\n",
      "7   poly  0.1    0.1       5     8  0.630769   0.629925  0.630769  0.624831\n",
      "8   poly  0.1    0.1       5     9  0.615385   0.714932  0.615385  0.582825\n",
      "9   poly  0.1    0.1       5    10  0.671875   0.679341  0.671875  0.671474\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       1     1  0.584615   0.768474  0.584615  0.483424\n",
      "1   poly  0.1    0.5       1     2  0.646154   0.737179  0.646154  0.591716\n",
      "2   poly  0.1    0.5       1     3  0.769231   0.778707  0.769231  0.764481\n",
      "3   poly  0.1    0.5       1     4  0.630769   0.692308  0.630769  0.579487\n",
      "4   poly  0.1    0.5       1     5  0.738462   0.745819  0.738462  0.733078\n",
      "5   poly  0.1    0.5       1     6  0.815385   0.818540  0.815385  0.813781\n",
      "6   poly  0.1    0.5       1     7  0.907692   0.908821  0.907692  0.907383\n",
      "7   poly  0.1    0.5       1     8  0.661538   0.660750  0.661538  0.658598\n",
      "8   poly  0.1    0.5       1     9  0.600000   0.737374  0.600000  0.552795\n",
      "9   poly  0.1    0.5       1    10  0.640625   0.677291  0.640625  0.630153\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       2     1  0.584615   0.651350  0.584615  0.514624\n",
      "1   poly  0.1    0.5       2     2  0.738462   0.763246  0.738462  0.726864\n",
      "2   poly  0.1    0.5       2     3  0.800000   0.821429  0.800000  0.793745\n",
      "3   poly  0.1    0.5       2     4  0.661538   0.670085  0.661538  0.648846\n",
      "4   poly  0.1    0.5       2     5  0.692308   0.694653  0.692308  0.687359\n",
      "5   poly  0.1    0.5       2     6  0.846154   0.850099  0.846154  0.844817\n",
      "6   poly  0.1    0.5       2     7  0.907692   0.908821  0.907692  0.907383\n",
      "7   poly  0.1    0.5       2     8  0.600000   0.598456  0.600000  0.598659\n",
      "8   poly  0.1    0.5       2     9  0.615385   0.691817  0.615385  0.589992\n",
      "9   poly  0.1    0.5       2    10  0.640625   0.647629  0.640625  0.640186\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       3     1  0.569231   0.585207  0.569231  0.526199\n",
      "1   poly  0.1    0.5       3     2  0.707692   0.709231  0.707692  0.704149\n",
      "2   poly  0.1    0.5       3     3  0.707692   0.707191  0.707692  0.707274\n",
      "3   poly  0.1    0.5       3     4  0.569231   0.565197  0.569231  0.562303\n",
      "4   poly  0.1    0.5       3     5  0.723077   0.723866  0.723077  0.720671\n",
      "5   poly  0.1    0.5       3     6  0.676923   0.680726  0.676923  0.677382\n",
      "6   poly  0.1    0.5       3     7  0.769231   0.773164  0.769231  0.769559\n",
      "7   poly  0.1    0.5       3     8  0.553846   0.549615  0.553846  0.548438\n",
      "8   poly  0.1    0.5       3     9  0.630769   0.703054  0.630769  0.609467\n",
      "9   poly  0.1    0.5       3    10  0.609375   0.625673  0.609375  0.605057\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       4     1  0.553846   0.564417  0.553846  0.503995\n",
      "1   poly  0.1    0.5       4     2  0.692308   0.705128  0.692308  0.680769\n",
      "2   poly  0.1    0.5       4     3  0.692308   0.691565  0.692308  0.691276\n",
      "3   poly  0.1    0.5       4     4  0.538462   0.532833  0.538462  0.531039\n",
      "4   poly  0.1    0.5       4     5  0.692308   0.691565  0.692308  0.691276\n",
      "5   poly  0.1    0.5       4     6  0.707692   0.708583  0.707692  0.707970\n",
      "6   poly  0.1    0.5       4     7  0.784615   0.790979  0.784615  0.784819\n",
      "7   poly  0.1    0.5       4     8  0.553846   0.551057  0.553846  0.551273\n",
      "8   poly  0.1    0.5       4     9  0.600000   0.661765  0.600000  0.576923\n",
      "9   poly  0.1    0.5       4    10  0.656250   0.661397  0.656250  0.656250\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       5     1  0.538462   0.538462  0.538462  0.492356\n",
      "1   poly  0.1    0.5       5     2  0.692308   0.705128  0.692308  0.680769\n",
      "2   poly  0.1    0.5       5     3  0.738462   0.741154  0.738462  0.735291\n",
      "3   poly  0.1    0.5       5     4  0.523077   0.515608  0.523077  0.513260\n",
      "4   poly  0.1    0.5       5     5  0.707692   0.707377  0.707692  0.706006\n",
      "5   poly  0.1    0.5       5     6  0.738462   0.738064  0.738462  0.738087\n",
      "6   poly  0.1    0.5       5     7  0.769231   0.778388  0.769231  0.769231\n",
      "7   poly  0.1    0.5       5     8  0.553846   0.551057  0.553846  0.551273\n",
      "8   poly  0.1    0.5       5     9  0.600000   0.661765  0.600000  0.576923\n",
      "9   poly  0.1    0.5       5    10  0.671875   0.679341  0.671875  0.671474\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       1     1  0.584615   0.768474  0.584615  0.483424\n",
      "1   poly  0.1      1       1     2  0.676923   0.758612  0.676923  0.636550\n",
      "2   poly  0.1      1       1     3  0.800000   0.805000  0.800000  0.797576\n",
      "3   poly  0.1      1       1     4  0.646154   0.686391  0.646154  0.610779\n",
      "4   poly  0.1      1       1     5  0.738462   0.752997  0.738462  0.730282\n",
      "5   poly  0.1      1       1     6  0.738462   0.745819  0.738462  0.733078\n",
      "6   poly  0.1      1       1     7  0.907692   0.908821  0.907692  0.907383\n",
      "7   poly  0.1      1       1     8  0.661538   0.660750  0.661538  0.658598\n",
      "8   poly  0.1      1       1     9  0.584615   0.781377  0.584615  0.518660\n",
      "9   poly  0.1      1       1    10  0.640625   0.677291  0.640625  0.630153\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       2     1  0.538462   0.538462  0.538462  0.492356\n",
      "1   poly  0.1      1       2     2  0.723077   0.740171  0.723077  0.712692\n",
      "2   poly  0.1      1       2     3  0.615385   0.616406  0.615385  0.615750\n",
      "3   poly  0.1      1       2     4  0.630769   0.635043  0.630769  0.616923\n",
      "4   poly  0.1      1       2     5  0.661538   0.660529  0.661538  0.660404\n",
      "5   poly  0.1      1       2     6  0.753846   0.753846  0.753846  0.753846\n",
      "6   poly  0.1      1       2     7  0.830769   0.831484  0.830769  0.830930\n",
      "7   poly  0.1      1       2     8  0.630769   0.629492  0.630769  0.629531\n",
      "8   poly  0.1      1       2     9  0.584615   0.648744  0.584615  0.557191\n",
      "9   poly  0.1      1       2    10  0.656250   0.665923  0.656250  0.655242\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       3     1  0.584615   0.604029  0.584615  0.547692\n",
      "1   poly  0.1      1       3     2  0.753846   0.759381  0.753846  0.749888\n",
      "2   poly  0.1      1       3     3  0.692308   0.692308  0.692308  0.692308\n",
      "3   poly  0.1      1       3     4  0.523077   0.519793  0.523077  0.520326\n",
      "4   poly  0.1      1       3     5  0.676923   0.676113  0.676923  0.675060\n",
      "5   poly  0.1      1       3     6  0.676923   0.680726  0.676923  0.677382\n",
      "6   poly  0.1      1       3     7  0.815385   0.817453  0.815385  0.815647\n",
      "7   poly  0.1      1       3     8  0.553846   0.549615  0.553846  0.548438\n",
      "8   poly  0.1      1       3     9  0.630769   0.703054  0.630769  0.609467\n",
      "9   poly  0.1      1       3    10  0.593750   0.601935  0.593750  0.592559\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       4     1  0.553846   0.564417  0.553846  0.503995\n",
      "1   poly  0.1      1       4     2  0.692308   0.705128  0.692308  0.680769\n",
      "2   poly  0.1      1       4     3  0.692308   0.691565  0.692308  0.691276\n",
      "3   poly  0.1      1       4     4  0.538462   0.532833  0.538462  0.531039\n",
      "4   poly  0.1      1       4     5  0.692308   0.691565  0.692308  0.691276\n",
      "5   poly  0.1      1       4     6  0.707692   0.708583  0.707692  0.707970\n",
      "6   poly  0.1      1       4     7  0.784615   0.790979  0.784615  0.784819\n",
      "7   poly  0.1      1       4     8  0.553846   0.551057  0.553846  0.551273\n",
      "8   poly  0.1      1       4     9  0.600000   0.661765  0.600000  0.576923\n",
      "9   poly  0.1      1       4    10  0.656250   0.661397  0.656250  0.656250\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       5     1  0.538462   0.538462  0.538462  0.492356\n",
      "1   poly  0.1      1       5     2  0.692308   0.705128  0.692308  0.680769\n",
      "2   poly  0.1      1       5     3  0.738462   0.741154  0.738462  0.735291\n",
      "3   poly  0.1      1       5     4  0.523077   0.515608  0.523077  0.513260\n",
      "4   poly  0.1      1       5     5  0.707692   0.707377  0.707692  0.706006\n",
      "5   poly  0.1      1       5     6  0.738462   0.738064  0.738462  0.738087\n",
      "6   poly  0.1      1       5     7  0.769231   0.778388  0.769231  0.769231\n",
      "7   poly  0.1      1       5     8  0.553846   0.551057  0.553846  0.551273\n",
      "8   poly  0.1      1       5     9  0.600000   0.661765  0.600000  0.576923\n",
      "9   poly  0.1      1       5    10  0.671875   0.679341  0.671875  0.671474\n",
      "\n",
      "Média dos resultados do kernel poly\n",
      "   kernel      c  gamma  degree  accuracy_avg  precision_avg  recall_avg  \\\n",
      "0    poly  0.001  0.001       1      0.536202       0.287536    0.536202   \n",
      "1    poly  0.001  0.001       2      0.536202       0.287536    0.536202   \n",
      "2    poly  0.001  0.001       3      0.536202       0.287536    0.536202   \n",
      "3    poly  0.001  0.001       4      0.536202       0.287536    0.536202   \n",
      "4    poly  0.001  0.001       5      0.536202       0.287536    0.536202   \n",
      "5    poly  0.001  0.100       1      0.536202       0.287536    0.536202   \n",
      "6    poly  0.001  0.100       2      0.536202       0.287536    0.536202   \n",
      "7    poly  0.001  0.100       3      0.536202       0.287536    0.536202   \n",
      "8    poly  0.001  0.100       4      0.536202       0.287536    0.536202   \n",
      "9    poly  0.001  0.100       5      0.536202       0.287536    0.536202   \n",
      "10   poly  0.001  0.500       1      0.536202       0.287536    0.536202   \n",
      "11   poly  0.001  0.500       2      0.628702       0.645657    0.628702   \n",
      "12   poly  0.001  0.500       3      0.688750       0.728246    0.688750   \n",
      "13   poly  0.001  0.500       4      0.690264       0.708446    0.690264   \n",
      "14   poly  0.001  0.500       5      0.654880       0.663156    0.654880   \n",
      "15   poly  0.001  1.000       1      0.536202       0.287536    0.536202   \n",
      "16   poly  0.001  1.000       2      0.693341       0.732740    0.693341   \n",
      "17   poly  0.001  1.000       3      0.710240       0.731985    0.710240   \n",
      "18   poly  0.001  1.000       4      0.644062       0.653500    0.644062   \n",
      "19   poly  0.001  1.000       5      0.653341       0.661634    0.653341   \n",
      "20   poly  0.100  0.001       1      0.536202       0.287536    0.536202   \n",
      "21   poly  0.100  0.001       2      0.536202       0.287536    0.536202   \n",
      "22   poly  0.100  0.001       3      0.536202       0.287536    0.536202   \n",
      "23   poly  0.100  0.001       4      0.536202       0.287536    0.536202   \n",
      "24   poly  0.100  0.001       5      0.536202       0.287536    0.536202   \n",
      "25   poly  0.100  0.100       1      0.690216       0.743836    0.690216   \n",
      "26   poly  0.100  0.100       2      0.693341       0.732740    0.693341   \n",
      "27   poly  0.100  0.100       3      0.691827       0.731262    0.691827   \n",
      "28   poly  0.100  0.100       4      0.688750       0.738494    0.688750   \n",
      "29   poly  0.100  0.100       5      0.679495       0.731098    0.679495   \n",
      "30   poly  0.100  0.500       1      0.699447       0.752526    0.699447   \n",
      "31   poly  0.100  0.500       2      0.708678       0.729758    0.708678   \n",
      "32   poly  0.100  0.500       3      0.651707       0.662292    0.651707   \n",
      "33   poly  0.100  0.500       4      0.647163       0.655929    0.647163   \n",
      "34   poly  0.100  0.500       5      0.653341       0.661634    0.653341   \n",
      "35   poly  0.100  1.000       1      0.697909       0.754553    0.697909   \n",
      "36   poly  0.100  1.000       2      0.662548       0.672010    0.662548   \n",
      "37   poly  0.100  1.000       3      0.650144       0.660441    0.650144   \n",
      "38   poly  0.100  1.000       4      0.647163       0.655929    0.647163   \n",
      "39   poly  0.100  1.000       5      0.653341       0.661634    0.653341   \n",
      "\n",
      "    fscore_avg  \n",
      "0     0.374329  \n",
      "1     0.374329  \n",
      "2     0.374329  \n",
      "3     0.374329  \n",
      "4     0.374329  \n",
      "5     0.374329  \n",
      "6     0.374329  \n",
      "7     0.374329  \n",
      "8     0.374329  \n",
      "9     0.374329  \n",
      "10    0.374329  \n",
      "11    0.557605  \n",
      "12    0.658304  \n",
      "13    0.675211  \n",
      "14    0.644915  \n",
      "15    0.374329  \n",
      "16    0.662334  \n",
      "17    0.696639  \n",
      "18    0.634190  \n",
      "19    0.643467  \n",
      "20    0.374329  \n",
      "21    0.374329  \n",
      "22    0.374329  \n",
      "23    0.374329  \n",
      "24    0.374329  \n",
      "25    0.657232  \n",
      "26    0.662334  \n",
      "27    0.661464  \n",
      "28    0.660288  \n",
      "29    0.649396  \n",
      "30    0.671490  \n",
      "31    0.695248  \n",
      "32    0.643050  \n",
      "33    0.637559  \n",
      "34    0.643467  \n",
      "35    0.670648  \n",
      "36    0.652487  \n",
      "37    0.642877  \n",
      "38    0.637559  \n",
      "39    0.643467  \n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1    0.1     1  0.523077   0.512454  0.523077  0.384812\n",
      "1    rbf  0.1    0.1     2  0.615385   0.711254  0.615385  0.543402\n",
      "2    rbf  0.1    0.1     3  0.707692   0.755385  0.707692  0.684766\n",
      "3    rbf  0.1    0.1     4  0.584615   0.636036  0.584615  0.506874\n",
      "4    rbf  0.1    0.1     5  0.630769   0.646978  0.630769  0.605351\n",
      "5    rbf  0.1    0.1     6  0.815385   0.845299  0.815385  0.808462\n",
      "6    rbf  0.1    0.1     7  0.830769   0.871237  0.830769  0.823265\n",
      "7    rbf  0.1    0.1     8  0.661538   0.686813  0.661538  0.638239\n",
      "8    rbf  0.1    0.1     9  0.692308   0.744755  0.692308  0.682952\n",
      "9    rbf  0.1    0.1    10  0.671875   0.672685  0.671875  0.672116\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.1    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.1    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.1    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.1    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.1    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.1    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.1    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.1    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.1    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.1      1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.1      1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.1      1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.1      1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "Média dos resultados do kernel rbf\n",
      "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
      "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
      "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
      "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "5    rbf  0.100  0.100      0.673341       0.708290    0.673341    0.635024\n",
      "6    rbf  0.100  0.500      0.536202       0.287536    0.536202    0.374329\n",
      "7    rbf  0.100  1.000      0.536202       0.287536    0.536202    0.374329\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-normalizado.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "\n",
    "result_linear_all, result_poly_all, result_rbf_all, ic_linear_all, ic_poly_all, ic_rbf_all = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, list_coef, dataSet='All Features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.625931      0.702986   0.625931   0.580070\n",
      "sup     0.769886      0.806120   0.769886   0.761227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.697909</td>\n",
       "      <td>0.754553</td>\n",
       "      <td>0.697909</td>\n",
       "      <td>0.670648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "1  linear  0.1      0.697909       0.754553    0.697909    0.670648"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel Linear\n",
    "print(ic_linear_all)\n",
    "result_linear_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.634177      0.664784   0.634177   0.611885\n",
      "sup     0.786304      0.799185   0.786304   0.781393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>gamma</th>\n",
       "      <th>degree</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.71024</td>\n",
       "      <td>0.731985</td>\n",
       "      <td>0.71024</td>\n",
       "      <td>0.696639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel      c  gamma  degree  accuracy_avg  precision_avg  recall_avg  \\\n",
       "17   poly  0.001    1.0       3       0.71024       0.731985     0.71024   \n",
       "\n",
       "    fscore_avg  \n",
       "17    0.696639  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel Polynomial\n",
    "print(ic_poly_all)\n",
    "result_poly_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.604949      0.633665   0.604949   0.539650\n",
      "sup     0.741734      0.782914   0.741734   0.730398\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>gamma</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.673341</td>\n",
       "      <td>0.70829</td>\n",
       "      <td>0.673341</td>\n",
       "      <td>0.635024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel    c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "5    rbf  0.1    0.1      0.673341        0.70829    0.673341    0.635024"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do Kernel RBF\n",
    "print(ic_rbf_all)\n",
    "result_rbf_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. SVM: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[0.001, 0.1, 0.5, 1]\n",
      "[0.001, 0.1]\n",
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "\n",
      "   kernel      c  fold  accuracy  precision    recall    fscore\n",
      "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "   kernel    c  fold  accuracy  precision    recall    fscore\n",
      "0  linear  0.1     1  0.584615   0.768474  0.584615  0.483424\n",
      "1  linear  0.1     2  0.646154   0.706682  0.646154  0.601935\n",
      "2  linear  0.1     3  0.769231   0.773077  0.769231  0.766434\n",
      "3  linear  0.1     4  0.569231   0.569920  0.569231  0.530981\n",
      "4  linear  0.1     5  0.707692   0.712932  0.707692  0.701676\n",
      "5  linear  0.1     6  0.830769   0.830681  0.830769  0.830527\n",
      "6  linear  0.1     7  0.876923   0.876923  0.876923  0.876923\n",
      "7  linear  0.1     8  0.738462   0.738064  0.738462  0.738087\n",
      "8  linear  0.1     9  0.600000   0.704142  0.600000  0.561992\n",
      "9  linear  0.1    10  0.671875   0.701584  0.671875  0.665632\n",
      "\n",
      "Média dos resultados do kernel linear\n",
      "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "1  linear  0.100      0.699495       0.738248    0.699495    0.675761\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.5       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.5       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.5       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.5       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.5       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.5       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.5       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.5       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.5       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.5       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.5       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.5       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.5       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.5       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.5       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.5       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.5       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.5       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.5       5     4  0.553846   0.756010  0.553846  0.410507\n",
      "4   poly  0.001    0.5       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       5     6  0.569231   0.760684  0.569231  0.442308\n",
      "6   poly  0.001    0.5       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.5       5     8  0.553846   0.756010  0.553846  0.410507\n",
      "8   poly  0.001    0.5       5     9  0.507692   0.282051  0.507692  0.362637\n",
      "9   poly  0.001    0.5       5    10  0.546875   0.599898  0.546875  0.425897\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001      1       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001      1       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001      1       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001      1       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001      1       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001      1       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001      1       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001      1       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001      1       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       3     1  0.538462   0.754808  0.538462  0.392759\n",
      "1   poly  0.001      1       3     2  0.584615   0.765509  0.584615  0.472497\n",
      "2   poly  0.001      1       3     3  0.630769   0.725034  0.630769  0.568034\n",
      "3   poly  0.001      1       3     4  0.569231   0.646280  0.569231  0.462858\n",
      "4   poly  0.001      1       3     5  0.600000   0.657895  0.600000  0.532037\n",
      "5   poly  0.001      1       3     6  0.707692   0.778107  0.707692  0.678469\n",
      "6   poly  0.001      1       3     7  0.800000   0.854167  0.800000  0.788003\n",
      "7   poly  0.001      1       3     8  0.630769   0.671263  0.630769  0.589411\n",
      "8   poly  0.001      1       3     9  0.676923   0.676319  0.676923  0.676460\n",
      "9   poly  0.001      1       3    10  0.656250   0.657813  0.656250  0.651089\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       4     1  0.523077   0.512454  0.523077  0.384812\n",
      "1   poly  0.001      1       4     2  0.584615   0.674359  0.584615  0.490920\n",
      "2   poly  0.001      1       4     3  0.630769   0.639935  0.630769  0.611632\n",
      "3   poly  0.001      1       4     4  0.584615   0.615385  0.584615  0.520710\n",
      "4   poly  0.001      1       4     5  0.553846   0.547263  0.553846  0.534062\n",
      "5   poly  0.001      1       4     6  0.676923   0.713846  0.676923  0.651584\n",
      "6   poly  0.001      1       4     7  0.707692   0.712932  0.707692  0.701676\n",
      "7   poly  0.001      1       4     8  0.600000   0.607143  0.600000  0.572464\n",
      "8   poly  0.001      1       4     9  0.630769   0.640584  0.630769  0.630245\n",
      "9   poly  0.001      1       4    10  0.687500   0.695076  0.687500  0.679909\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       5     1  0.492308   0.444973  0.492308  0.406762\n",
      "1   poly  0.001      1       5     2  0.584615   0.636036  0.584615  0.506874\n",
      "2   poly  0.001      1       5     3  0.661538   0.665311  0.661538  0.652860\n",
      "3   poly  0.001      1       5     4  0.600000   0.636364  0.600000  0.544444\n",
      "4   poly  0.001      1       5     5  0.600000   0.597561  0.600000  0.593567\n",
      "5   poly  0.001      1       5     6  0.692308   0.691565  0.692308  0.691276\n",
      "6   poly  0.001      1       5     7  0.769231   0.770034  0.769231  0.769450\n",
      "7   poly  0.001      1       5     8  0.523077   0.511266  0.523077  0.501928\n",
      "8   poly  0.001      1       5     9  0.630769   0.685971  0.630769  0.614935\n",
      "9   poly  0.001      1       5    10  0.656250   0.658203  0.656250  0.656586\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       1     1  0.538462   0.596361  0.538462  0.415724\n",
      "1   poly  0.1    0.1       1     2  0.630769   0.725034  0.630769  0.568034\n",
      "2   poly  0.1    0.1       1     3  0.707692   0.718781  0.707692  0.698551\n",
      "3   poly  0.1    0.1       1     4  0.538462   0.523617  0.538462  0.460042\n",
      "4   poly  0.1    0.1       1     5  0.615385   0.623963  0.615385  0.592314\n",
      "5   poly  0.1    0.1       1     6  0.846154   0.856473  0.846154  0.843680\n",
      "6   poly  0.1    0.1       1     7  0.907692   0.913215  0.907692  0.906890\n",
      "7   poly  0.1    0.1       1     8  0.784615   0.786982  0.784615  0.782744\n",
      "8   poly  0.1    0.1       1     9  0.676923   0.753592  0.676923  0.660773\n",
      "9   poly  0.1    0.1       1    10  0.656250   0.671938  0.656250  0.653554\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1   poly  0.1    0.5       1     2  0.646154   0.737179  0.646154  0.591716\n",
      "2   poly  0.1    0.5       1     3  0.769231   0.773077  0.769231  0.766434\n",
      "3   poly  0.1    0.5       1     4  0.615385   0.630769  0.615385  0.585219\n",
      "4   poly  0.1    0.5       1     5  0.676923   0.680045  0.676923  0.670273\n",
      "5   poly  0.1    0.5       1     6  0.830769   0.830681  0.830769  0.830527\n",
      "6   poly  0.1    0.5       1     7  0.876923   0.877784  0.876923  0.876510\n",
      "7   poly  0.1    0.5       1     8  0.784615   0.784675  0.784615  0.783893\n",
      "8   poly  0.1    0.5       1     9  0.646154   0.762443  0.646154  0.616199\n",
      "9   poly  0.1    0.5       1    10  0.609375   0.632523  0.609375  0.601943\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       2     1  0.507692   0.488008  0.507692  0.446420\n",
      "1   poly  0.1    0.5       2     2  0.676923   0.732249  0.676923  0.644624\n",
      "2   poly  0.1    0.5       2     3  0.569231   0.564807  0.569231  0.558185\n",
      "3   poly  0.1    0.5       2     4  0.600000   0.607143  0.600000  0.572464\n",
      "4   poly  0.1    0.5       2     5  0.492308   0.493505  0.492308  0.492790\n",
      "5   poly  0.1    0.5       2     6  0.707692   0.707191  0.707692  0.707274\n",
      "6   poly  0.1    0.5       2     7  0.676923   0.677857  0.676923  0.677230\n",
      "7   poly  0.1    0.5       2     8  0.600000   0.605313  0.600000  0.600379\n",
      "8   poly  0.1    0.5       2     9  0.615385   0.622711  0.615385  0.615385\n",
      "9   poly  0.1    0.5       2    10  0.609375   0.608713  0.609375  0.608895\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       3     1  0.476923   0.420513  0.476923  0.397009\n",
      "1   poly  0.1    0.5       3     2  0.553846   0.554487  0.553846  0.485207\n",
      "2   poly  0.1    0.5       3     3  0.676923   0.677308  0.676923  0.673007\n",
      "3   poly  0.1    0.5       3     4  0.600000   0.600000  0.600000  0.585000\n",
      "4   poly  0.1    0.5       3     5  0.584615   0.582321  0.584615  0.582220\n",
      "5   poly  0.1    0.5       3     6  0.738462   0.738064  0.738462  0.738087\n",
      "6   poly  0.1    0.5       3     7  0.676923   0.690748  0.676923  0.675852\n",
      "7   poly  0.1    0.5       3     8  0.569231   0.567419  0.569231  0.567787\n",
      "8   poly  0.1    0.5       3     9  0.646154   0.713857  0.646154  0.628466\n",
      "9   poly  0.1    0.5       3    10  0.656250   0.661397  0.656250  0.656250\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       4     1  0.446154   0.398225  0.446154  0.390828\n",
      "1   poly  0.1    0.5       4     2  0.615385   0.630769  0.615385  0.585219\n",
      "2   poly  0.1    0.5       4     3  0.553846   0.547702  0.553846  0.539893\n",
      "3   poly  0.1    0.5       4     4  0.553846   0.548817  0.553846  0.509243\n",
      "4   poly  0.1    0.5       4     5  0.538462   0.536383  0.538462  0.536914\n",
      "5   poly  0.1    0.5       4     6  0.615385   0.613585  0.615385  0.613166\n",
      "6   poly  0.1    0.5       4     7  0.615385   0.619100  0.615385  0.615931\n",
      "7   poly  0.1    0.5       4     8  0.461538   0.449833  0.461538  0.450455\n",
      "8   poly  0.1    0.5       4     9  0.646154   0.674015  0.646154  0.640579\n",
      "9   poly  0.1    0.5       4    10  0.578125   0.584206  0.578125  0.577610\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       5     1  0.507692   0.482845  0.507692  0.432479\n",
      "1   poly  0.1    0.5       5     2  0.615385   0.676282  0.615385  0.556213\n",
      "2   poly  0.1    0.5       5     3  0.630769   0.629925  0.630769  0.624831\n",
      "3   poly  0.1    0.5       5     4  0.646154   0.686391  0.646154  0.610779\n",
      "4   poly  0.1    0.5       5     5  0.600000   0.597561  0.600000  0.593567\n",
      "5   poly  0.1    0.5       5     6  0.692308   0.691565  0.692308  0.691276\n",
      "6   poly  0.1    0.5       5     7  0.753846   0.755973  0.753846  0.754196\n",
      "7   poly  0.1    0.5       5     8  0.523077   0.511266  0.523077  0.501928\n",
      "8   poly  0.1    0.5       5     9  0.646154   0.697436  0.646154  0.633287\n",
      "9   poly  0.1    0.5       5    10  0.640625   0.647629  0.640625  0.640186\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       1     1  0.584615   0.768474  0.584615  0.483424\n",
      "1   poly  0.1      1       1     2  0.646154   0.706682  0.646154  0.601935\n",
      "2   poly  0.1      1       1     3  0.769231   0.773077  0.769231  0.766434\n",
      "3   poly  0.1      1       1     4  0.569231   0.569920  0.569231  0.530981\n",
      "4   poly  0.1      1       1     5  0.707692   0.712932  0.707692  0.701676\n",
      "5   poly  0.1      1       1     6  0.830769   0.830681  0.830769  0.830527\n",
      "6   poly  0.1      1       1     7  0.876923   0.876923  0.876923  0.876923\n",
      "7   poly  0.1      1       1     8  0.738462   0.738064  0.738462  0.738087\n",
      "8   poly  0.1      1       1     9  0.600000   0.704142  0.600000  0.561992\n",
      "9   poly  0.1      1       1    10  0.671875   0.701584  0.671875  0.665632\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       2     1  0.476923   0.452308  0.476923  0.435770\n",
      "1   poly  0.1      1       2     2  0.676923   0.700698  0.676923  0.657543\n",
      "2   poly  0.1      1       2     3  0.569231   0.565197  0.569231  0.562303\n",
      "3   poly  0.1      1       2     4  0.661538   0.662289  0.661538  0.656095\n",
      "4   poly  0.1      1       2     5  0.584615   0.585681  0.584615  0.585010\n",
      "5   poly  0.1      1       2     6  0.707692   0.716117  0.707692  0.707692\n",
      "6   poly  0.1      1       2     7  0.738462   0.738064  0.738462  0.738087\n",
      "7   poly  0.1      1       2     8  0.630769   0.636257  0.630769  0.631119\n",
      "8   poly  0.1      1       2     9  0.630769   0.646124  0.630769  0.628667\n",
      "9   poly  0.1      1       2    10  0.593750   0.598407  0.593750  0.593750\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       3     1  0.538462   0.536821  0.538462  0.502150\n",
      "1   poly  0.1      1       3     2  0.661538   0.686813  0.661538  0.638239\n",
      "2   poly  0.1      1       3     3  0.676923   0.676319  0.676923  0.676460\n",
      "3   poly  0.1      1       3     4  0.538462   0.529915  0.538462  0.521154\n",
      "4   poly  0.1      1       3     5  0.600000   0.598456  0.600000  0.598659\n",
      "5   poly  0.1      1       3     6  0.630769   0.640584  0.630769  0.630245\n",
      "6   poly  0.1      1       3     7  0.646154   0.653846  0.646154  0.646154\n",
      "7   poly  0.1      1       3     8  0.584615   0.582321  0.584615  0.582220\n",
      "8   poly  0.1      1       3     9  0.584615   0.667421  0.584615  0.549451\n",
      "9   poly  0.1      1       3    10  0.578125   0.587869  0.578125  0.575957\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       4     1  0.446154   0.398225  0.446154  0.390828\n",
      "1   poly  0.1      1       4     2  0.615385   0.623963  0.615385  0.592314\n",
      "2   poly  0.1      1       4     3  0.553846   0.547702  0.553846  0.539893\n",
      "3   poly  0.1      1       4     4  0.584615   0.589231  0.584615  0.552036\n",
      "4   poly  0.1      1       4     5  0.507692   0.505346  0.507692  0.506042\n",
      "5   poly  0.1      1       4     6  0.615385   0.614574  0.615385  0.614834\n",
      "6   poly  0.1      1       4     7  0.646154   0.653846  0.646154  0.646154\n",
      "7   poly  0.1      1       4     8  0.461538   0.449833  0.461538  0.450455\n",
      "8   poly  0.1      1       4     9  0.600000   0.636364  0.600000  0.587838\n",
      "9   poly  0.1      1       4    10  0.609375   0.612628  0.609375  0.609661\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       5     1  0.507692   0.482845  0.507692  0.432479\n",
      "1   poly  0.1      1       5     2  0.630769   0.692308  0.630769  0.579487\n",
      "2   poly  0.1      1       5     3  0.630769   0.629925  0.630769  0.624831\n",
      "3   poly  0.1      1       5     4  0.615385   0.640533  0.615385  0.576933\n",
      "4   poly  0.1      1       5     5  0.600000   0.597561  0.600000  0.593567\n",
      "5   poly  0.1      1       5     6  0.692308   0.691565  0.692308  0.691276\n",
      "6   poly  0.1      1       5     7  0.707692   0.711538  0.707692  0.708108\n",
      "7   poly  0.1      1       5     8  0.523077   0.511266  0.523077  0.501928\n",
      "8   poly  0.1      1       5     9  0.600000   0.647597  0.600000  0.582846\n",
      "9   poly  0.1      1       5    10  0.640625   0.647629  0.640625  0.640186\n",
      "\n",
      "Média dos resultados do kernel poly\n",
      "   kernel      c  gamma  degree  accuracy_avg  precision_avg  recall_avg  \\\n",
      "0    poly  0.001  0.001       1      0.536202       0.287536    0.536202   \n",
      "1    poly  0.001  0.001       2      0.536202       0.287536    0.536202   \n",
      "2    poly  0.001  0.001       3      0.536202       0.287536    0.536202   \n",
      "3    poly  0.001  0.001       4      0.536202       0.287536    0.536202   \n",
      "4    poly  0.001  0.001       5      0.536202       0.287536    0.536202   \n",
      "5    poly  0.001  0.100       1      0.536202       0.287536    0.536202   \n",
      "6    poly  0.001  0.100       2      0.536202       0.287536    0.536202   \n",
      "7    poly  0.001  0.100       3      0.536202       0.287536    0.536202   \n",
      "8    poly  0.001  0.100       4      0.536202       0.287536    0.536202   \n",
      "9    poly  0.001  0.100       5      0.536202       0.287536    0.536202   \n",
      "10   poly  0.001  0.500       1      0.536202       0.287536    0.536202   \n",
      "11   poly  0.001  0.500       2      0.536202       0.287536    0.536202   \n",
      "12   poly  0.001  0.500       3      0.536202       0.287536    0.536202   \n",
      "13   poly  0.001  0.500       4      0.536202       0.287536    0.536202   \n",
      "14   poly  0.001  0.500       5      0.540841       0.458802    0.540841   \n",
      "15   poly  0.001  1.000       1      0.536202       0.287536    0.536202   \n",
      "16   poly  0.001  1.000       2      0.536202       0.287536    0.536202   \n",
      "17   poly  0.001  1.000       3      0.639471       0.718719    0.639471   \n",
      "18   poly  0.001  1.000       4      0.617981       0.635898    0.617981   \n",
      "19   poly  0.001  1.000       5      0.621010       0.629728    0.621010   \n",
      "20   poly  0.100  0.001       1      0.536202       0.287536    0.536202   \n",
      "21   poly  0.100  0.001       2      0.536202       0.287536    0.536202   \n",
      "22   poly  0.100  0.001       3      0.536202       0.287536    0.536202   \n",
      "23   poly  0.100  0.001       4      0.536202       0.287536    0.536202   \n",
      "24   poly  0.100  0.001       5      0.536202       0.287536    0.536202   \n",
      "25   poly  0.100  0.100       1      0.690240       0.716996    0.690240   \n",
      "26   poly  0.100  0.100       2      0.536202       0.287536    0.536202   \n",
      "27   poly  0.100  0.100       3      0.536202       0.287536    0.536202   \n",
      "28   poly  0.100  0.100       4      0.536202       0.287536    0.536202   \n",
      "29   poly  0.100  0.100       5      0.536202       0.287536    0.536202   \n",
      "30   poly  0.100  0.500       1      0.700937       0.734984    0.700937   \n",
      "31   poly  0.100  0.500       2      0.605553       0.610750    0.605553   \n",
      "32   poly  0.100  0.500       3      0.617933       0.620611    0.617933   \n",
      "33   poly  0.100  0.500       4      0.562428       0.560263    0.562428   \n",
      "34   poly  0.100  0.500       5      0.625601       0.637687    0.625601   \n",
      "35   poly  0.100  1.000       1      0.699495       0.738248    0.699495   \n",
      "36   poly  0.100  1.000       2      0.627067       0.630114    0.627067   \n",
      "37   poly  0.100  1.000       3      0.603966       0.616036    0.603966   \n",
      "38   poly  0.100  1.000       4      0.564014       0.563171    0.564014   \n",
      "39   poly  0.100  1.000       5      0.614832       0.625277    0.614832   \n",
      "\n",
      "    fscore_avg  \n",
      "0     0.374329  \n",
      "1     0.374329  \n",
      "2     0.374329  \n",
      "3     0.374329  \n",
      "4     0.374329  \n",
      "5     0.374329  \n",
      "6     0.374329  \n",
      "7     0.374329  \n",
      "8     0.374329  \n",
      "9     0.374329  \n",
      "10    0.374329  \n",
      "11    0.374329  \n",
      "12    0.374329  \n",
      "13    0.374329  \n",
      "14    0.391883  \n",
      "15    0.374329  \n",
      "16    0.374329  \n",
      "17    0.581162  \n",
      "18    0.577801  \n",
      "19    0.593868  \n",
      "20    0.374329  \n",
      "21    0.374329  \n",
      "22    0.374329  \n",
      "23    0.374329  \n",
      "24    0.374329  \n",
      "25    0.658231  \n",
      "26    0.374329  \n",
      "27    0.374329  \n",
      "28    0.374329  \n",
      "29    0.374329  \n",
      "30    0.676787  \n",
      "31    0.592365  \n",
      "32    0.598888  \n",
      "33    0.545984  \n",
      "34    0.603874  \n",
      "35    0.675761  \n",
      "36    0.619604  \n",
      "37    0.592069  \n",
      "38    0.549005  \n",
      "39    0.593164  \n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1    0.1     1  0.523077   0.512454  0.523077  0.384812\n",
      "1    rbf  0.1    0.1     2  0.661538   0.748252  0.661538  0.614530\n",
      "2    rbf  0.1    0.1     3  0.692308   0.705128  0.692308  0.680769\n",
      "3    rbf  0.1    0.1     4  0.553846   0.550894  0.553846  0.498092\n",
      "4    rbf  0.1    0.1     5  0.600000   0.600000  0.600000  0.585000\n",
      "5    rbf  0.1    0.1     6  0.830769   0.844482  0.830769  0.827286\n",
      "6    rbf  0.1    0.1     7  0.892308   0.910256  0.892308  0.890091\n",
      "7    rbf  0.1    0.1     8  0.738462   0.745819  0.738462  0.733078\n",
      "8    rbf  0.1    0.1     9  0.676923   0.734615  0.676923  0.665175\n",
      "9    rbf  0.1    0.1    10  0.671875   0.684904  0.671875  0.670189\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.1    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.1    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.1    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.1    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.1    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.1    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.1    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.1    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.1    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.1      1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.1      1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.1      1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.1      1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "Média dos resultados do kernel rbf\n",
      "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
      "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
      "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
      "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "5    rbf  0.100  0.100      0.684111       0.703680    0.684111    0.654902\n",
      "6    rbf  0.100  0.500      0.536202       0.287536    0.536202    0.374329\n",
      "7    rbf  0.100  1.000      0.536202       0.287536    0.536202    0.374329\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-pca.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "\n",
    "result_linear_pca, result_poly_pca, result_rbf_pca, ic_linear_pca, ic_poly_pca, ic_rbf_pca = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, list_coef, dataSet='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf      0.62453      0.678692    0.62453   0.582293\n",
      "sup      0.77446      0.797804    0.77446   0.769229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.699495</td>\n",
       "      <td>0.738248</td>\n",
       "      <td>0.699495</td>\n",
       "      <td>0.675761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "1  linear  0.1      0.699495       0.738248    0.699495    0.675761"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel Linear\n",
    "print(ic_linear_pca)\n",
    "result_linear_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.624257      0.673032   0.624257   0.580924\n",
      "sup     0.777618      0.796937   0.777618   0.772650\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>gamma</th>\n",
       "      <th>degree</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700937</td>\n",
       "      <td>0.734984</td>\n",
       "      <td>0.700937</td>\n",
       "      <td>0.676787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel    c  gamma  degree  accuracy_avg  precision_avg  recall_avg  \\\n",
       "30   poly  0.1    0.5       1      0.700937       0.734984    0.700937   \n",
       "\n",
       "    fscore_avg  \n",
       "30    0.676787  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel poly\n",
    "print(ic_poly_pca)\n",
    "result_poly_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.602005      0.615024   0.602005   0.549280\n",
      "sup     0.766217      0.792336   0.766217   0.760524\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>gamma</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.684111</td>\n",
       "      <td>0.70368</td>\n",
       "      <td>0.684111</td>\n",
       "      <td>0.654902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel    c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "5    rbf  0.1    0.1      0.684111        0.70368    0.684111    0.654902"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel rbf\n",
    "print(ic_rbf_pca)\n",
    "result_rbf_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. SVM: Chi Squared (k-Best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[0.001, 0.1, 0.5, 1]\n",
      "[0.001, 0.1]\n",
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "\n",
      "   kernel      c  fold  accuracy  precision    recall    fscore\n",
      "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "   kernel    c  fold  accuracy  precision    recall    fscore\n",
      "0  linear  0.1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1  linear  0.1     2  0.646154   0.706682  0.646154  0.601935\n",
      "2  linear  0.1     3  0.815385   0.824109  0.815385  0.812416\n",
      "3  linear  0.1     4  0.646154   0.686391  0.646154  0.610779\n",
      "4  linear  0.1     5  0.723077   0.740171  0.723077  0.712692\n",
      "5  linear  0.1     6  0.830769   0.844482  0.830769  0.827286\n",
      "6  linear  0.1     7  0.938462   0.939857  0.938462  0.938255\n",
      "7  linear  0.1     8  0.630769   0.629925  0.630769  0.624831\n",
      "8  linear  0.1     9  0.569231   0.717643  0.569231  0.507074\n",
      "9  linear  0.1    10  0.656250   0.717844  0.656250  0.639550\n",
      "\n",
      "Média dos resultados do kernel linear\n",
      "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "1  linear  0.100      0.701010       0.744777    0.701010    0.671998\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.5       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.5       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.5       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.5       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.5       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.5       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       3     3  0.553846   0.756010  0.553846  0.410507\n",
      "3   poly  0.001    0.5       3     4  0.553846   0.756010  0.553846  0.410507\n",
      "4   poly  0.001    0.5       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       3     6  0.615385   0.775641  0.615385  0.528629\n",
      "6   poly  0.001    0.5       3     7  0.584615   0.765509  0.584615  0.472497\n",
      "7   poly  0.001    0.5       3     8  0.584615   0.765509  0.584615  0.472497\n",
      "8   poly  0.001    0.5       3     9  0.600000   0.622642  0.600000  0.555195\n",
      "9   poly  0.001    0.5       3    10  0.578125   0.633067  0.578125  0.500316\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       4     2  0.538462   0.521368  0.538462  0.402473\n",
      "2   poly  0.001    0.5       4     3  0.600000   0.770492  0.600000  0.501225\n",
      "3   poly  0.001    0.5       4     4  0.538462   0.521368  0.538462  0.402473\n",
      "4   poly  0.001    0.5       4     5  0.553846   0.602978  0.553846  0.433422\n",
      "5   poly  0.001    0.5       4     6  0.676923   0.798077  0.676923  0.627219\n",
      "6   poly  0.001    0.5       4     7  0.692308   0.804196  0.692308  0.649573\n",
      "7   poly  0.001    0.5       4     8  0.615385   0.676282  0.615385  0.556213\n",
      "8   poly  0.001    0.5       4     9  0.646154   0.647157  0.646154  0.638871\n",
      "9   poly  0.001    0.5       4    10  0.640625   0.658675  0.640625  0.619763\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       5     2  0.569231   0.646280  0.569231  0.462858\n",
      "2   poly  0.001    0.5       5     3  0.600000   0.770492  0.600000  0.501225\n",
      "3   poly  0.001    0.5       5     4  0.538462   0.521368  0.538462  0.402473\n",
      "4   poly  0.001    0.5       5     5  0.538462   0.522068  0.538462  0.424491\n",
      "5   poly  0.001    0.5       5     6  0.723077   0.817126  0.723077  0.692058\n",
      "6   poly  0.001    0.5       5     7  0.753846   0.831071  0.753846  0.731989\n",
      "7   poly  0.001    0.5       5     8  0.646154   0.706682  0.646154  0.601935\n",
      "8   poly  0.001    0.5       5     9  0.661538   0.660529  0.661538  0.660404\n",
      "9   poly  0.001    0.5       5    10  0.703125   0.709272  0.703125  0.697374\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001      1       2     2  0.553846   0.602978  0.553846  0.433422\n",
      "2   poly  0.001      1       2     3  0.600000   0.694915  0.600000  0.517730\n",
      "3   poly  0.001      1       2     4  0.538462   0.521368  0.538462  0.402473\n",
      "4   poly  0.001      1       2     5  0.553846   0.560818  0.553846  0.470346\n",
      "5   poly  0.001      1       2     6  0.723077   0.817126  0.723077  0.692058\n",
      "6   poly  0.001      1       2     7  0.738462   0.823964  0.738462  0.712315\n",
      "7   poly  0.001      1       2     8  0.630769   0.692308  0.630769  0.579487\n",
      "8   poly  0.001      1       2     9  0.753846   0.753638  0.753846  0.753021\n",
      "9   poly  0.001      1       2    10  0.671875   0.671453  0.671875  0.670172\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       3     1  0.538462   0.754808  0.538462  0.392759\n",
      "1   poly  0.001      1       3     2  0.584615   0.674359  0.584615  0.490920\n",
      "2   poly  0.001      1       3     3  0.646154   0.686391  0.646154  0.610779\n",
      "3   poly  0.001      1       3     4  0.569231   0.646280  0.569231  0.462858\n",
      "4   poly  0.001      1       3     5  0.569231   0.608866  0.569231  0.480633\n",
      "5   poly  0.001      1       3     6  0.800000   0.854167  0.800000  0.788003\n",
      "6   poly  0.001      1       3     7  0.846154   0.880342  0.846154  0.840385\n",
      "7   poly  0.001      1       3     8  0.630769   0.635043  0.630769  0.616923\n",
      "8   poly  0.001      1       3     9  0.707692   0.754838  0.707692  0.700386\n",
      "9   poly  0.001      1       3    10  0.703125   0.706653  0.703125  0.703342\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       4     1  0.523077   0.512454  0.523077  0.384812\n",
      "1   poly  0.001      1       4     2  0.600000   0.694915  0.600000  0.517730\n",
      "2   poly  0.001      1       4     3  0.753846   0.806319  0.753846  0.736901\n",
      "3   poly  0.001      1       4     4  0.553846   0.573077  0.553846  0.453210\n",
      "4   poly  0.001      1       4     5  0.584615   0.615385  0.584615  0.520710\n",
      "5   poly  0.001      1       4     6  0.769231   0.787213  0.769231  0.762014\n",
      "6   poly  0.001      1       4     7  0.846154   0.856473  0.846154  0.843680\n",
      "7   poly  0.001      1       4     8  0.630769   0.639935  0.630769  0.611632\n",
      "8   poly  0.001      1       4     9  0.661538   0.708625  0.661538  0.651247\n",
      "9   poly  0.001      1       4    10  0.656250   0.661397  0.656250  0.656250\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       5     1  0.553846   0.601651  0.553846  0.463085\n",
      "1   poly  0.001      1       5     2  0.646154   0.706682  0.646154  0.601935\n",
      "2   poly  0.001      1       5     3  0.723077   0.727017  0.723077  0.718623\n",
      "3   poly  0.001      1       5     4  0.553846   0.573077  0.553846  0.453210\n",
      "4   poly  0.001      1       5     5  0.507692   0.487637  0.507692  0.473802\n",
      "5   poly  0.001      1       5     6  0.738462   0.741154  0.738462  0.735291\n",
      "6   poly  0.001      1       5     7  0.800000   0.801170  0.800000  0.798846\n",
      "7   poly  0.001      1       5     8  0.615385   0.613585  0.615385  0.613166\n",
      "8   poly  0.001      1       5     9  0.676923   0.734615  0.676923  0.665175\n",
      "9   poly  0.001      1       5    10  0.671875   0.675312  0.671875  0.672115\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1   poly  0.1    0.1       1     2  0.630769   0.725034  0.630769  0.568034\n",
      "2   poly  0.1    0.1       1     3  0.738462   0.777432  0.738462  0.722773\n",
      "3   poly  0.1    0.1       1     4  0.600000   0.657895  0.600000  0.532037\n",
      "4   poly  0.1    0.1       1     5  0.615385   0.619257  0.615385  0.598329\n",
      "5   poly  0.1    0.1       1     6  0.815385   0.845299  0.815385  0.808462\n",
      "6   poly  0.1    0.1       1     7  0.892308   0.910256  0.892308  0.890091\n",
      "7   poly  0.1    0.1       1     8  0.738462   0.738641  0.738462  0.736953\n",
      "8   poly  0.1    0.1       1     9  0.676923   0.753592  0.676923  0.660773\n",
      "9   poly  0.1    0.1       1    10  0.687500   0.692892  0.687500  0.687500\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       2     2  0.553846   0.602978  0.553846  0.433422\n",
      "2   poly  0.1    0.1       2     3  0.600000   0.694915  0.600000  0.517730\n",
      "3   poly  0.1    0.1       2     4  0.538462   0.521368  0.538462  0.402473\n",
      "4   poly  0.1    0.1       2     5  0.553846   0.560818  0.553846  0.470346\n",
      "5   poly  0.1    0.1       2     6  0.723077   0.817126  0.723077  0.692058\n",
      "6   poly  0.1    0.1       2     7  0.738462   0.823964  0.738462  0.712315\n",
      "7   poly  0.1    0.1       2     8  0.630769   0.692308  0.630769  0.579487\n",
      "8   poly  0.1    0.1       2     9  0.753846   0.753638  0.753846  0.753021\n",
      "9   poly  0.1    0.1       2    10  0.671875   0.671453  0.671875  0.670172\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1    0.1       3     3  0.553846   0.756010  0.553846  0.410507\n",
      "3   poly  0.1    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1    0.1       3     6  0.600000   0.770492  0.600000  0.501225\n",
      "6   poly  0.1    0.1       3     7  0.553846   0.756010  0.553846  0.410507\n",
      "7   poly  0.1    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1    0.1       3     9  0.553846   0.573077  0.553846  0.453210\n",
      "9   poly  0.1    0.1       3    10  0.546875   0.599898  0.546875  0.425897\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1    0.1       4     9  0.553846   0.756010  0.553846  0.410507\n",
      "9   poly  0.1    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1   poly  0.1    0.5       1     2  0.630769   0.725034  0.630769  0.568034\n",
      "2   poly  0.1    0.5       1     3  0.800000   0.811594  0.800000  0.795883\n",
      "3   poly  0.1    0.5       1     4  0.630769   0.671263  0.630769  0.589411\n",
      "4   poly  0.1    0.5       1     5  0.723077   0.740171  0.723077  0.712692\n",
      "5   poly  0.1    0.5       1     6  0.846154   0.856473  0.846154  0.843680\n",
      "6   poly  0.1    0.5       1     7  0.907692   0.913215  0.907692  0.906890\n",
      "7   poly  0.1    0.5       1     8  0.676923   0.676113  0.676923  0.675060\n",
      "8   poly  0.1    0.5       1     9  0.584615   0.727972  0.584615  0.530317\n",
      "9   poly  0.1    0.5       1    10  0.625000   0.678140  0.625000  0.606781\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       2     1  0.553846   0.759219  0.553846  0.424502\n",
      "1   poly  0.1    0.5       2     2  0.630769   0.725034  0.630769  0.568034\n",
      "2   poly  0.1    0.5       2     3  0.753846   0.775214  0.753846  0.744615\n",
      "3   poly  0.1    0.5       2     4  0.615385   0.676282  0.615385  0.556213\n",
      "4   poly  0.1    0.5       2     5  0.676923   0.700698  0.676923  0.657543\n",
      "5   poly  0.1    0.5       2     6  0.861538   0.877369  0.861538  0.858688\n",
      "6   poly  0.1    0.5       2     7  0.892308   0.900769  0.892308  0.891002\n",
      "7   poly  0.1    0.5       2     8  0.661538   0.662289  0.661538  0.656095\n",
      "8   poly  0.1    0.5       2     9  0.569231   0.717643  0.569231  0.507074\n",
      "9   poly  0.1    0.5       2    10  0.656250   0.671938  0.656250  0.653554\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       3     1  0.553846   0.640668  0.553846  0.445159\n",
      "1   poly  0.1    0.5       3     2  0.646154   0.737179  0.646154  0.591716\n",
      "2   poly  0.1    0.5       3     3  0.769231   0.778707  0.769231  0.764481\n",
      "3   poly  0.1    0.5       3     4  0.600000   0.657895  0.600000  0.532037\n",
      "4   poly  0.1    0.5       3     5  0.584615   0.585596  0.584615  0.559699\n",
      "5   poly  0.1    0.5       3     6  0.800000   0.805000  0.800000  0.797576\n",
      "6   poly  0.1    0.5       3     7  0.846154   0.846748  0.846154  0.845638\n",
      "7   poly  0.1    0.5       3     8  0.615385   0.614270  0.615385  0.607468\n",
      "8   poly  0.1    0.5       3     9  0.661538   0.770256  0.661538  0.636154\n",
      "9   poly  0.1    0.5       3    10  0.671875   0.675312  0.671875  0.672115\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       4     1  0.553846   0.601651  0.553846  0.463085\n",
      "1   poly  0.1    0.5       4     2  0.661538   0.748252  0.661538  0.614530\n",
      "2   poly  0.1    0.5       4     3  0.738462   0.738064  0.738462  0.738087\n",
      "3   poly  0.1    0.5       4     4  0.569231   0.590756  0.569231  0.496039\n",
      "4   poly  0.1    0.5       4     5  0.569231   0.565739  0.569231  0.546904\n",
      "5   poly  0.1    0.5       4     6  0.707692   0.709231  0.707692  0.704149\n",
      "6   poly  0.1    0.5       4     7  0.846154   0.846748  0.846154  0.845638\n",
      "7   poly  0.1    0.5       4     8  0.661538   0.661538  0.661538  0.661538\n",
      "8   poly  0.1    0.5       4     9  0.707692   0.754838  0.707692  0.700386\n",
      "9   poly  0.1    0.5       4    10  0.687500   0.692892  0.687500  0.687500\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       5     1  0.569231   0.594095  0.569231  0.515618\n",
      "1   poly  0.1    0.5       5     2  0.661538   0.719884  0.661538  0.623626\n",
      "2   poly  0.1    0.5       5     3  0.738462   0.738064  0.738462  0.738087\n",
      "3   poly  0.1    0.5       5     4  0.584615   0.602823  0.584615  0.532707\n",
      "4   poly  0.1    0.5       5     5  0.492308   0.479271  0.492308  0.476430\n",
      "5   poly  0.1    0.5       5     6  0.707692   0.709231  0.707692  0.704149\n",
      "6   poly  0.1    0.5       5     7  0.784615   0.791745  0.784615  0.781152\n",
      "7   poly  0.1    0.5       5     8  0.661538   0.660750  0.661538  0.658598\n",
      "8   poly  0.1    0.5       5     9  0.646154   0.684420  0.646154  0.637310\n",
      "9   poly  0.1    0.5       5    10  0.656250   0.658203  0.656250  0.656586\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1   poly  0.1      1       1     2  0.646154   0.706682  0.646154  0.601935\n",
      "2   poly  0.1      1       1     3  0.815385   0.824109  0.815385  0.812416\n",
      "3   poly  0.1      1       1     4  0.646154   0.686391  0.646154  0.610779\n",
      "4   poly  0.1      1       1     5  0.723077   0.740171  0.723077  0.712692\n",
      "5   poly  0.1      1       1     6  0.830769   0.844482  0.830769  0.827286\n",
      "6   poly  0.1      1       1     7  0.938462   0.939857  0.938462  0.938255\n",
      "7   poly  0.1      1       1     8  0.630769   0.629925  0.630769  0.624831\n",
      "8   poly  0.1      1       1     9  0.569231   0.717643  0.569231  0.507074\n",
      "9   poly  0.1      1       1    10  0.656250   0.717844  0.656250  0.639550\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       2     1  0.553846   0.640668  0.553846  0.445159\n",
      "1   poly  0.1      1       2     2  0.646154   0.737179  0.646154  0.591716\n",
      "2   poly  0.1      1       2     3  0.800000   0.821429  0.800000  0.793745\n",
      "3   poly  0.1      1       2     4  0.646154   0.706682  0.646154  0.601935\n",
      "4   poly  0.1      1       2     5  0.692308   0.698813  0.692308  0.684418\n",
      "5   poly  0.1      1       2     6  0.830769   0.844482  0.830769  0.827286\n",
      "6   poly  0.1      1       2     7  0.923077   0.923298  0.923077  0.922967\n",
      "7   poly  0.1      1       2     8  0.676923   0.684565  0.676923  0.666819\n",
      "8   poly  0.1      1       2     9  0.646154   0.762443  0.646154  0.616199\n",
      "9   poly  0.1      1       2    10  0.671875   0.679341  0.671875  0.671474\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       3     1  0.538462   0.545177  0.538462  0.467949\n",
      "1   poly  0.1      1       3     2  0.676923   0.732249  0.676923  0.644624\n",
      "2   poly  0.1      1       3     3  0.738462   0.742351  0.738462  0.738833\n",
      "3   poly  0.1      1       3     4  0.600000   0.613445  0.600000  0.564482\n",
      "4   poly  0.1      1       3     5  0.630769   0.629191  0.630769  0.627562\n",
      "5   poly  0.1      1       3     6  0.676923   0.677308  0.676923  0.673007\n",
      "6   poly  0.1      1       3     7  0.861538   0.861553  0.861538  0.861340\n",
      "7   poly  0.1      1       3     8  0.661538   0.661538  0.661538  0.661538\n",
      "8   poly  0.1      1       3     9  0.692308   0.744755  0.692308  0.682952\n",
      "9   poly  0.1      1       3    10  0.671875   0.675312  0.671875  0.672115\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       4     1  0.615385   0.629569  0.615385  0.595228\n",
      "1   poly  0.1      1       4     2  0.646154   0.662330  0.646154  0.624929\n",
      "2   poly  0.1      1       4     3  0.753846   0.766136  0.753846  0.753497\n",
      "3   poly  0.1      1       4     4  0.584615   0.585596  0.584615  0.559699\n",
      "4   poly  0.1      1       4     5  0.661538   0.663753  0.661538  0.662020\n",
      "5   poly  0.1      1       4     6  0.661538   0.660750  0.661538  0.658598\n",
      "6   poly  0.1      1       4     7  0.723077   0.723077  0.723077  0.723077\n",
      "7   poly  0.1      1       4     8  0.523077   0.524230  0.523077  0.523530\n",
      "8   poly  0.1      1       4     9  0.676923   0.734615  0.676923  0.665175\n",
      "9   poly  0.1      1       4    10  0.750000   0.752024  0.750000  0.748016\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       5     1  0.600000   0.613725  0.600000  0.575813\n",
      "1   poly  0.1      1       5     2  0.615385   0.616134  0.615385  0.603356\n",
      "2   poly  0.1      1       5     3  0.661538   0.667202  0.661538  0.661859\n",
      "3   poly  0.1      1       5     4  0.569231   0.564957  0.569231  0.553077\n",
      "4   poly  0.1      1       5     5  0.692308   0.694493  0.692308  0.692746\n",
      "5   poly  0.1      1       5     6  0.630769   0.630769  0.630769  0.630769\n",
      "6   poly  0.1      1       5     7  0.769231   0.773164  0.769231  0.769559\n",
      "7   poly  0.1      1       5     8  0.492308   0.493505  0.492308  0.492790\n",
      "8   poly  0.1      1       5     9  0.707692   0.754838  0.707692  0.700386\n",
      "9   poly  0.1      1       5    10  0.703125   0.705288  0.703125  0.699798\n",
      "\n",
      "Média dos resultados do kernel poly\n",
      "   kernel      c  gamma  degree  accuracy_avg  precision_avg  recall_avg  \\\n",
      "0    poly  0.001  0.001       1      0.536202       0.287536    0.536202   \n",
      "1    poly  0.001  0.001       2      0.536202       0.287536    0.536202   \n",
      "2    poly  0.001  0.001       3      0.536202       0.287536    0.536202   \n",
      "3    poly  0.001  0.001       4      0.536202       0.287536    0.536202   \n",
      "4    poly  0.001  0.001       5      0.536202       0.287536    0.536202   \n",
      "5    poly  0.001  0.100       1      0.536202       0.287536    0.536202   \n",
      "6    poly  0.001  0.100       2      0.536202       0.287536    0.536202   \n",
      "7    poly  0.001  0.100       3      0.536202       0.287536    0.536202   \n",
      "8    poly  0.001  0.100       4      0.536202       0.287536    0.536202   \n",
      "9    poly  0.001  0.100       5      0.536202       0.287536    0.536202   \n",
      "10   poly  0.001  0.500       1      0.536202       0.287536    0.536202   \n",
      "11   poly  0.001  0.500       2      0.536202       0.287536    0.536202   \n",
      "12   poly  0.001  0.500       3      0.567043       0.592788    0.567043   \n",
      "13   poly  0.001  0.500       4      0.602524       0.627420    0.602524   \n",
      "14   poly  0.001  0.500       5      0.625697       0.645850    0.625697   \n",
      "15   poly  0.001  1.000       1      0.536202       0.287536    0.536202   \n",
      "16   poly  0.001  1.000       2      0.628726       0.641218    0.628726   \n",
      "17   poly  0.001  1.000       3      0.659543       0.720175    0.659543   \n",
      "18   poly  0.001  1.000       4      0.657933       0.685579    0.657933   \n",
      "19   poly  0.001  1.000       5      0.648726       0.666190    0.648726   \n",
      "20   poly  0.100  0.001       1      0.536202       0.287536    0.536202   \n",
      "21   poly  0.100  0.001       2      0.536202       0.287536    0.536202   \n",
      "22   poly  0.100  0.001       3      0.536202       0.287536    0.536202   \n",
      "23   poly  0.100  0.001       4      0.536202       0.287536    0.536202   \n",
      "24   poly  0.100  0.001       5      0.536202       0.287536    0.536202   \n",
      "25   poly  0.100  0.100       1      0.694904       0.736097    0.694904   \n",
      "26   poly  0.100  0.100       2      0.628726       0.641218    0.628726   \n",
      "27   poly  0.100  0.100       3      0.548534       0.488886    0.548534   \n",
      "28   poly  0.100  0.100       4      0.537740       0.334143    0.537740   \n",
      "29   poly  0.100  0.100       5      0.536202       0.287536    0.536202   \n",
      "30   poly  0.100  0.500       1      0.697885       0.744064    0.697885   \n",
      "31   poly  0.100  0.500       2      0.687163       0.746645    0.687163   \n",
      "32   poly  0.100  0.500       3      0.674880       0.711163    0.674880   \n",
      "33   poly  0.100  0.500       4      0.670288       0.690971    0.670288   \n",
      "34   poly  0.100  0.500       5      0.650240       0.663848    0.650240   \n",
      "35   poly  0.100  1.000       1      0.701010       0.744777    0.701010   \n",
      "36   poly  0.100  1.000       2      0.708726       0.749890    0.708726   \n",
      "37   poly  0.100  1.000       3      0.674880       0.688288    0.674880   \n",
      "38   poly  0.100  1.000       4      0.659615       0.670208    0.659615   \n",
      "39   poly  0.100  1.000       5      0.644159       0.651408    0.644159   \n",
      "\n",
      "    fscore_avg  \n",
      "0     0.374329  \n",
      "1     0.374329  \n",
      "2     0.374329  \n",
      "3     0.374329  \n",
      "4     0.374329  \n",
      "5     0.374329  \n",
      "6     0.374329  \n",
      "7     0.374329  \n",
      "8     0.374329  \n",
      "9     0.374329  \n",
      "10    0.374329  \n",
      "11    0.374329  \n",
      "12    0.446328  \n",
      "13    0.519052  \n",
      "14    0.553409  \n",
      "15    0.374329  \n",
      "16    0.559031  \n",
      "17    0.608699  \n",
      "18    0.613819  \n",
      "19    0.619525  \n",
      "20    0.374329  \n",
      "21    0.374329  \n",
      "22    0.374329  \n",
      "23    0.374329  \n",
      "24    0.374329  \n",
      "25    0.665011  \n",
      "26    0.559031  \n",
      "27    0.406832  \n",
      "28    0.377688  \n",
      "29    0.374329  \n",
      "30    0.667391  \n",
      "31    0.651732  \n",
      "32    0.645204  \n",
      "33    0.645786  \n",
      "34    0.632426  \n",
      "35    0.671998  \n",
      "36    0.682172  \n",
      "37    0.659440  \n",
      "38    0.651377  \n",
      "39    0.638015  \n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1    0.1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1    rbf  0.1    0.1     2  0.630769   0.725034  0.630769  0.568034\n",
      "2    rbf  0.1    0.1     3  0.723077   0.740171  0.723077  0.712692\n",
      "3    rbf  0.1    0.1     4  0.646154   0.706682  0.646154  0.601935\n",
      "4    rbf  0.1    0.1     5  0.646154   0.650350  0.646154  0.635088\n",
      "5    rbf  0.1    0.1     6  0.876923   0.888837  0.876923  0.874944\n",
      "6    rbf  0.1    0.1     7  0.969231   0.970894  0.969231  0.969128\n",
      "7    rbf  0.1    0.1     8  0.784615   0.784615  0.784615  0.784615\n",
      "8    rbf  0.1    0.1     9  0.615385   0.746130  0.615385  0.574567\n",
      "9    rbf  0.1    0.1    10  0.671875   0.701584  0.671875  0.665632\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1    0.5     1  0.553846   0.640668  0.553846  0.445159\n",
      "1    rbf  0.1    0.5     2  0.661538   0.748252  0.661538  0.614530\n",
      "2    rbf  0.1    0.5     3  0.738462   0.741154  0.738462  0.735291\n",
      "3    rbf  0.1    0.5     4  0.661538   0.686813  0.661538  0.638239\n",
      "4    rbf  0.1    0.5     5  0.676923   0.680045  0.676923  0.670273\n",
      "5    rbf  0.1    0.5     6  0.907692   0.913215  0.907692  0.906890\n",
      "6    rbf  0.1    0.5     7  0.938462   0.939857  0.938462  0.938255\n",
      "7    rbf  0.1    0.5     8  0.753846   0.755973  0.753846  0.754196\n",
      "8    rbf  0.1    0.5     9  0.569231   0.717643  0.569231  0.507074\n",
      "9    rbf  0.1    0.5    10  0.656250   0.717844  0.656250  0.639550\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.1      1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.1      1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.1      1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.1      1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "Média dos resultados do kernel rbf\n",
      "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
      "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
      "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
      "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "5    rbf  0.100  0.100      0.711803       0.755496    0.711803    0.683179\n",
      "6    rbf  0.100  0.500      0.711779       0.754147    0.711779    0.684946\n",
      "7    rbf  0.100  1.000      0.536202       0.287536    0.536202    0.374329\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-fs-chi-squared.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "\n",
    "result_linear_chi, result_poly_chi, result_rbf_chi, ic_linear_chi, ic_poly_chi, ic_rbf_chi = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, list_coef, dataSet='chi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.612182      0.675395   0.612182   0.563516\n",
      "sup     0.789837      0.814160   0.789837   0.780479\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.70101</td>\n",
       "      <td>0.744777</td>\n",
       "      <td>0.70101</td>\n",
       "      <td>0.671998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "1  linear  0.1       0.70101       0.744777     0.70101    0.671998"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel Linear\n",
    "print(ic_linear_chi)\n",
    "result_linear_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.630528      0.686755   0.630528   0.584729\n",
      "sup     0.786924      0.813026   0.786924   0.779615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>gamma</th>\n",
       "      <th>degree</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.708726</td>\n",
       "      <td>0.74989</td>\n",
       "      <td>0.708726</td>\n",
       "      <td>0.682172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel    c  gamma  degree  accuracy_avg  precision_avg  recall_avg  \\\n",
       "36   poly  0.1    1.0       2      0.708726        0.74989    0.708726   \n",
       "\n",
       "    fscore_avg  \n",
       "36    0.682172  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel Poly\n",
    "print(ic_poly_chi)\n",
    "result_poly_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.619454      0.681690   0.619454   0.571175\n",
      "sup     0.804152      0.829303   0.804152   0.795184\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>gamma</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.711803</td>\n",
       "      <td>0.755496</td>\n",
       "      <td>0.711803</td>\n",
       "      <td>0.683179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel    c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "5    rbf  0.1    0.1      0.711803       0.755496    0.711803    0.683179"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel RBF\n",
    "print(ic_rbf_chi)\n",
    "result_rbf_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. SVM: Recursive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[0.001, 0.1, 0.5, 1]\n",
      "[0.001, 0.1]\n",
      "k = 10, Dataset: 348 positivas, 301 negativas (53% x 46%)\n",
      "\n",
      "Fold 0: Pos: 34, Neg: 31, Total: 65, Proporção: 52% x 47%\n",
      "Fold 1: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 2: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 3: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 4: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 5: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 6: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 7: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 8: Pos: 35, Neg: 30, Total: 65, Proporção: 53% x 46%\n",
      "Fold 9: Pos: 34, Neg: 30, Total: 64, Proporção: 53% x 46%\n",
      "\n",
      "   kernel      c  fold  accuracy  precision    recall    fscore\n",
      "0  linear  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1  linear  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2  linear  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3  linear  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4  linear  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5  linear  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6  linear  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7  linear  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8  linear  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9  linear  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "   kernel    c  fold  accuracy  precision    recall    fscore\n",
      "0  linear  0.1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1  linear  0.1     2  0.676923   0.758612  0.676923  0.636550\n",
      "2  linear  0.1     3  0.769231   0.799243  0.769231  0.758998\n",
      "3  linear  0.1     4  0.661538   0.700496  0.661538  0.631485\n",
      "4  linear  0.1     5  0.784615   0.810256  0.784615  0.776538\n",
      "5  linear  0.1     6  0.876923   0.881657  0.876923  0.875854\n",
      "6  linear  0.1     7  0.938462   0.939857  0.938462  0.938255\n",
      "7  linear  0.1     8  0.738462   0.741154  0.738462  0.735291\n",
      "8  linear  0.1     9  0.569231   0.777188  0.569231  0.494172\n",
      "9  linear  0.1    10  0.625000   0.654221  0.625000  0.616071\n",
      "\n",
      "Média dos resultados do kernel linear\n",
      "   kernel      c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0  linear  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "1  linear  0.100      0.719423       0.770335    0.719423    0.690837\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.1       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.1       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.5       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.5       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.5       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.5       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.5       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.5       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001    0.5       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001    0.5       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001    0.5       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001    0.5       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001    0.5       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001    0.5       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001    0.5       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001    0.5       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001    0.5       3     3  0.615385   0.775641  0.615385  0.528629\n",
      "3   poly  0.001    0.5       3     4  0.569231   0.760684  0.569231  0.442308\n",
      "4   poly  0.001    0.5       3     5  0.584615   0.765509  0.584615  0.472497\n",
      "5   poly  0.001    0.5       3     6  0.630769   0.780965  0.630769  0.554828\n",
      "6   poly  0.001    0.5       3     7  0.630769   0.780965  0.630769  0.554828\n",
      "7   poly  0.001    0.5       3     8  0.676923   0.798077  0.676923  0.627219\n",
      "8   poly  0.001    0.5       3     9  0.769231   0.773077  0.769231  0.766434\n",
      "9   poly  0.001    0.5       3    10  0.718750   0.748641  0.718750  0.704688\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       4     1  0.553846   0.759219  0.553846  0.424502\n",
      "1   poly  0.001    0.5       4     2  0.584615   0.674359  0.584615  0.490920\n",
      "2   poly  0.001    0.5       4     3  0.661538   0.792173  0.661538  0.604031\n",
      "3   poly  0.001    0.5       4     4  0.569231   0.646280  0.569231  0.462858\n",
      "4   poly  0.001    0.5       4     5  0.615385   0.711254  0.615385  0.543402\n",
      "5   poly  0.001    0.5       4     6  0.723077   0.787546  0.723077  0.698488\n",
      "6   poly  0.001    0.5       4     7  0.784615   0.846154  0.784615  0.769788\n",
      "7   poly  0.001    0.5       4     8  0.738462   0.777432  0.738462  0.722773\n",
      "8   poly  0.001    0.5       4     9  0.738462   0.763314  0.738462  0.736225\n",
      "9   poly  0.001    0.5       4    10  0.640625   0.639733  0.640625  0.638760\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001    0.5       5     1  0.569231   0.763772  0.569231  0.454676\n",
      "1   poly  0.001    0.5       5     2  0.630769   0.725034  0.630769  0.568034\n",
      "2   poly  0.001    0.5       5     3  0.692308   0.804196  0.692308  0.649573\n",
      "3   poly  0.001    0.5       5     4  0.569231   0.646280  0.569231  0.462858\n",
      "4   poly  0.001    0.5       5     5  0.630769   0.692308  0.630769  0.579487\n",
      "5   poly  0.001    0.5       5     6  0.769231   0.838462  0.769231  0.751131\n",
      "6   poly  0.001    0.5       5     7  0.784615   0.825423  0.784615  0.773452\n",
      "7   poly  0.001    0.5       5     8  0.723077   0.766484  0.723077  0.704013\n",
      "8   poly  0.001    0.5       5     9  0.723077   0.752308  0.723077  0.719780\n",
      "9   poly  0.001    0.5       5    10  0.640625   0.640055  0.640625  0.640184\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.001      1       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.001      1       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.001      1       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.001      1       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.001      1       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.001      1       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.001      1       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.001      1       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.001      1       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       2     1  0.553846   0.759219  0.553846  0.424502\n",
      "1   poly  0.001      1       2     2  0.569231   0.760684  0.569231  0.442308\n",
      "2   poly  0.001      1       2     3  0.630769   0.780965  0.630769  0.554828\n",
      "3   poly  0.001      1       2     4  0.569231   0.760684  0.569231  0.442308\n",
      "4   poly  0.001      1       2     5  0.600000   0.770492  0.600000  0.501225\n",
      "5   poly  0.001      1       2     6  0.723077   0.817126  0.723077  0.692058\n",
      "6   poly  0.001      1       2     7  0.753846   0.831071  0.753846  0.731989\n",
      "7   poly  0.001      1       2     8  0.661538   0.719884  0.661538  0.623626\n",
      "8   poly  0.001      1       2     9  0.769231   0.773164  0.769231  0.769559\n",
      "9   poly  0.001      1       2    10  0.671875   0.671453  0.671875  0.670172\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       3     1  0.569231   0.763772  0.569231  0.454676\n",
      "1   poly  0.001      1       3     2  0.646154   0.737179  0.646154  0.591716\n",
      "2   poly  0.001      1       3     3  0.738462   0.796923  0.738462  0.717949\n",
      "3   poly  0.001      1       3     4  0.600000   0.694915  0.600000  0.517730\n",
      "4   poly  0.001      1       3     5  0.676923   0.732249  0.676923  0.644624\n",
      "5   poly  0.001      1       3     6  0.830769   0.855644  0.830769  0.825477\n",
      "6   poly  0.001      1       3     7  0.830769   0.855644  0.830769  0.825477\n",
      "7   poly  0.001      1       3     8  0.723077   0.740171  0.723077  0.712692\n",
      "8   poly  0.001      1       3     9  0.676923   0.809955  0.676923  0.649573\n",
      "9   poly  0.001      1       3    10  0.640625   0.647629  0.640625  0.640186\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       4     1  0.538462   0.565128  0.538462  0.435625\n",
      "1   poly  0.001      1       4     2  0.676923   0.758612  0.676923  0.636550\n",
      "2   poly  0.001      1       4     3  0.769231   0.787213  0.769231  0.762014\n",
      "3   poly  0.001      1       4     4  0.615385   0.654753  0.615385  0.567321\n",
      "4   poly  0.001      1       4     5  0.707692   0.755385  0.707692  0.684766\n",
      "5   poly  0.001      1       4     6  0.769231   0.799243  0.769231  0.758998\n",
      "6   poly  0.001      1       4     7  0.815385   0.832818  0.815385  0.810651\n",
      "7   poly  0.001      1       4     8  0.676923   0.691252  0.676923  0.662597\n",
      "8   poly  0.001      1       4     9  0.630769   0.754438  0.630769  0.595685\n",
      "9   poly  0.001      1       4    10  0.671875   0.675312  0.671875  0.672115\n",
      "\n",
      "  kernel      c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.001      1       5     1  0.538462   0.536821  0.538462  0.502150\n",
      "1   poly  0.001      1       5     2  0.692308   0.726648  0.692308  0.671126\n",
      "2   poly  0.001      1       5     3  0.753846   0.775214  0.753846  0.744615\n",
      "3   poly  0.001      1       5     4  0.584615   0.615385  0.584615  0.520710\n",
      "4   poly  0.001      1       5     5  0.692308   0.694653  0.692308  0.687359\n",
      "5   poly  0.001      1       5     6  0.661538   0.670085  0.661538  0.648846\n",
      "6   poly  0.001      1       5     7  0.769231   0.787213  0.769231  0.762014\n",
      "7   poly  0.001      1       5     8  0.661538   0.665311  0.661538  0.652860\n",
      "8   poly  0.001      1       5     9  0.630769   0.685971  0.630769  0.614935\n",
      "9   poly  0.001      1       5    10  0.578125   0.604893  0.578125  0.565831\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       2     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       2     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       2     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       2     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       2     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       2     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       2     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       2     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       2     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       2    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       3     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       3     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       3     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       3     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       3     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       3     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       3     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       3    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       4     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       4     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       4     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       4     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       4    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1  0.001       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1  0.001       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1  0.001       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1  0.001       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1  0.001       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1  0.001       5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6   poly  0.1  0.001       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1  0.001       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1  0.001       5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9   poly  0.1  0.001       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       1     1  0.538462   0.754808  0.538462  0.392759\n",
      "1   poly  0.1    0.1       1     2  0.584615   0.674359  0.584615  0.490920\n",
      "2   poly  0.1    0.1       1     3  0.692308   0.804196  0.692308  0.649573\n",
      "3   poly  0.1    0.1       1     4  0.569231   0.608866  0.569231  0.480633\n",
      "4   poly  0.1    0.1       1     5  0.692308   0.804196  0.692308  0.649573\n",
      "5   poly  0.1    0.1       1     6  0.800000   0.854167  0.800000  0.788003\n",
      "6   poly  0.1    0.1       1     7  0.907692   0.921201  0.907692  0.906208\n",
      "7   poly  0.1    0.1       1     8  0.738462   0.777432  0.738462  0.722773\n",
      "8   poly  0.1    0.1       1     9  0.646154   0.713857  0.646154  0.628466\n",
      "9   poly  0.1    0.1       1    10  0.671875   0.675312  0.671875  0.672115\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       2     1  0.553846   0.759219  0.553846  0.424502\n",
      "1   poly  0.1    0.1       2     2  0.569231   0.760684  0.569231  0.442308\n",
      "2   poly  0.1    0.1       2     3  0.630769   0.780965  0.630769  0.554828\n",
      "3   poly  0.1    0.1       2     4  0.569231   0.760684  0.569231  0.442308\n",
      "4   poly  0.1    0.1       2     5  0.600000   0.770492  0.600000  0.501225\n",
      "5   poly  0.1    0.1       2     6  0.723077   0.817126  0.723077  0.692058\n",
      "6   poly  0.1    0.1       2     7  0.753846   0.831071  0.753846  0.731989\n",
      "7   poly  0.1    0.1       2     8  0.661538   0.719884  0.661538  0.623626\n",
      "8   poly  0.1    0.1       2     9  0.769231   0.773164  0.769231  0.769559\n",
      "9   poly  0.1    0.1       2    10  0.671875   0.671453  0.671875  0.670172\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       3     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       3     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1    0.1       3     3  0.553846   0.756010  0.553846  0.410507\n",
      "3   poly  0.1    0.1       3     4  0.569231   0.760684  0.569231  0.442308\n",
      "4   poly  0.1    0.1       3     5  0.553846   0.756010  0.553846  0.410507\n",
      "5   poly  0.1    0.1       3     6  0.630769   0.780965  0.630769  0.554828\n",
      "6   poly  0.1    0.1       3     7  0.615385   0.775641  0.615385  0.528629\n",
      "7   poly  0.1    0.1       3     8  0.630769   0.780965  0.630769  0.554828\n",
      "8   poly  0.1    0.1       3     9  0.661538   0.700496  0.661538  0.631485\n",
      "9   poly  0.1    0.1       3    10  0.609375   0.709352  0.609375  0.537329\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       4     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       4     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1    0.1       4     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1    0.1       4     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1    0.1       4     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1    0.1       4     6  0.600000   0.770492  0.600000  0.501225\n",
      "6   poly  0.1    0.1       4     7  0.569231   0.760684  0.569231  0.442308\n",
      "7   poly  0.1    0.1       4     8  0.553846   0.756010  0.553846  0.410507\n",
      "8   poly  0.1    0.1       4     9  0.584615   0.765509  0.584615  0.472497\n",
      "9   poly  0.1    0.1       4    10  0.546875   0.755456  0.546875  0.402665\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.1       5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1   poly  0.1    0.1       5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2   poly  0.1    0.1       5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3   poly  0.1    0.1       5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4   poly  0.1    0.1       5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5   poly  0.1    0.1       5     6  0.584615   0.765509  0.584615  0.472497\n",
      "6   poly  0.1    0.1       5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7   poly  0.1    0.1       5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8   poly  0.1    0.1       5     9  0.569231   0.760684  0.569231  0.442308\n",
      "9   poly  0.1    0.1       5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1   poly  0.1    0.5       1     2  0.661538   0.748252  0.661538  0.614530\n",
      "2   poly  0.1    0.5       1     3  0.769231   0.799243  0.769231  0.758998\n",
      "3   poly  0.1    0.5       1     4  0.615385   0.654753  0.615385  0.567321\n",
      "4   poly  0.1    0.5       1     5  0.753846   0.788325  0.753846  0.741088\n",
      "5   poly  0.1    0.5       1     6  0.892308   0.900769  0.892308  0.891002\n",
      "6   poly  0.1    0.5       1     7  0.923077   0.926226  0.923077  0.922633\n",
      "7   poly  0.1    0.5       1     8  0.738462   0.741154  0.738462  0.735291\n",
      "8   poly  0.1    0.5       1     9  0.584615   0.781377  0.584615  0.518660\n",
      "9   poly  0.1    0.5       1    10  0.640625   0.690241  0.640625  0.625708\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       2     1  0.553846   0.640668  0.553846  0.445159\n",
      "1   poly  0.1    0.5       2     2  0.676923   0.758612  0.676923  0.636550\n",
      "2   poly  0.1    0.5       2     3  0.784615   0.810256  0.784615  0.776538\n",
      "3   poly  0.1    0.5       2     4  0.661538   0.686813  0.661538  0.638239\n",
      "4   poly  0.1    0.5       2     5  0.769231   0.799243  0.769231  0.758998\n",
      "5   poly  0.1    0.5       2     6  0.846154   0.856473  0.846154  0.843680\n",
      "6   poly  0.1    0.5       2     7  0.923077   0.926226  0.923077  0.922633\n",
      "7   poly  0.1    0.5       2     8  0.707692   0.718781  0.707692  0.698551\n",
      "8   poly  0.1    0.5       2     9  0.630769   0.794872  0.630769  0.587195\n",
      "9   poly  0.1    0.5       2    10  0.625000   0.645833  0.625000  0.619458\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       3     1  0.569231   0.629254  0.569231  0.489386\n",
      "1   poly  0.1    0.5       3     2  0.676923   0.758612  0.676923  0.636550\n",
      "2   poly  0.1    0.5       3     3  0.800000   0.821429  0.800000  0.793745\n",
      "3   poly  0.1    0.5       3     4  0.646154   0.672308  0.646154  0.618401\n",
      "4   poly  0.1    0.5       3     5  0.784615   0.825423  0.784615  0.773452\n",
      "5   poly  0.1    0.5       3     6  0.753846   0.775214  0.753846  0.744615\n",
      "6   poly  0.1    0.5       3     7  0.876923   0.888837  0.876923  0.874944\n",
      "7   poly  0.1    0.5       3     8  0.692308   0.714130  0.692308  0.676360\n",
      "8   poly  0.1    0.5       3     9  0.615385   0.714932  0.615385  0.582825\n",
      "9   poly  0.1    0.5       3    10  0.640625   0.652559  0.640625  0.638778\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       4     1  0.538462   0.538462  0.538462  0.492356\n",
      "1   poly  0.1    0.5       4     2  0.661538   0.686813  0.661538  0.638239\n",
      "2   poly  0.1    0.5       4     3  0.753846   0.765816  0.753846  0.747535\n",
      "3   poly  0.1    0.5       4     4  0.584615   0.594675  0.584615  0.543088\n",
      "4   poly  0.1    0.5       4     5  0.676923   0.680045  0.676923  0.670273\n",
      "5   poly  0.1    0.5       4     6  0.723077   0.740171  0.723077  0.712692\n",
      "6   poly  0.1    0.5       4     7  0.815385   0.832818  0.815385  0.810651\n",
      "7   poly  0.1    0.5       4     8  0.661538   0.665311  0.661538  0.652860\n",
      "8   poly  0.1    0.5       4     9  0.600000   0.680000  0.600000  0.570000\n",
      "9   poly  0.1    0.5       4    10  0.562500   0.578125  0.562500  0.556034\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1    0.5       5     1  0.523077   0.516694  0.523077  0.498083\n",
      "1   poly  0.1    0.5       5     2  0.630769   0.635043  0.630769  0.616923\n",
      "2   poly  0.1    0.5       5     3  0.723077   0.723866  0.723077  0.720671\n",
      "3   poly  0.1    0.5       5     4  0.538462   0.526395  0.538462  0.497479\n",
      "4   poly  0.1    0.5       5     5  0.692308   0.698813  0.692308  0.684418\n",
      "5   poly  0.1    0.5       5     6  0.661538   0.660750  0.661538  0.658598\n",
      "6   poly  0.1    0.5       5     7  0.753846   0.765816  0.753846  0.747535\n",
      "7   poly  0.1    0.5       5     8  0.630769   0.629191  0.630769  0.627562\n",
      "8   poly  0.1    0.5       5     9  0.661538   0.724344  0.661538  0.647024\n",
      "9   poly  0.1    0.5       5    10  0.531250   0.553125  0.531250  0.514827\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       1     1  0.553846   0.640668  0.553846  0.445159\n",
      "1   poly  0.1      1       1     2  0.676923   0.758612  0.676923  0.636550\n",
      "2   poly  0.1      1       1     3  0.769231   0.799243  0.769231  0.758998\n",
      "3   poly  0.1      1       1     4  0.661538   0.700496  0.661538  0.631485\n",
      "4   poly  0.1      1       1     5  0.784615   0.810256  0.784615  0.776538\n",
      "5   poly  0.1      1       1     6  0.876923   0.881657  0.876923  0.875854\n",
      "6   poly  0.1      1       1     7  0.938462   0.939857  0.938462  0.938255\n",
      "7   poly  0.1      1       1     8  0.738462   0.741154  0.738462  0.735291\n",
      "8   poly  0.1      1       1     9  0.569231   0.777188  0.569231  0.494172\n",
      "9   poly  0.1      1       1    10  0.625000   0.654221  0.625000  0.616071\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       2     1  0.553846   0.601651  0.553846  0.463085\n",
      "1   poly  0.1      1       2     2  0.707692   0.778107  0.707692  0.678469\n",
      "2   poly  0.1      1       2     3  0.830769   0.855644  0.830769  0.825477\n",
      "3   poly  0.1      1       2     4  0.661538   0.686813  0.661538  0.638239\n",
      "4   poly  0.1      1       2     5  0.769231   0.799243  0.769231  0.758998\n",
      "5   poly  0.1      1       2     6  0.784615   0.791745  0.784615  0.781152\n",
      "6   poly  0.1      1       2     7  0.923077   0.926226  0.923077  0.922633\n",
      "7   poly  0.1      1       2     8  0.661538   0.665311  0.661538  0.652860\n",
      "8   poly  0.1      1       2     9  0.630769   0.794872  0.630769  0.587195\n",
      "9   poly  0.1      1       2    10  0.656250   0.665923  0.656250  0.655242\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       3     1  0.553846   0.559707  0.553846  0.514188\n",
      "1   poly  0.1      1       3     2  0.646154   0.662330  0.646154  0.624929\n",
      "2   poly  0.1      1       3     3  0.723077   0.727017  0.723077  0.718623\n",
      "3   poly  0.1      1       3     4  0.569231   0.565739  0.569231  0.546904\n",
      "4   poly  0.1      1       3     5  0.692308   0.694653  0.692308  0.687359\n",
      "5   poly  0.1      1       3     6  0.707692   0.707377  0.707692  0.706006\n",
      "6   poly  0.1      1       3     7  0.815385   0.824109  0.815385  0.812416\n",
      "7   poly  0.1      1       3     8  0.630769   0.629925  0.630769  0.624831\n",
      "8   poly  0.1      1       3     9  0.646154   0.713857  0.646154  0.628466\n",
      "9   poly  0.1      1       3    10  0.593750   0.611979  0.593750  0.587746\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       4     1  0.569231   0.571766  0.569231  0.549846\n",
      "1   poly  0.1      1       4     2  0.646154   0.645385  0.646154  0.641865\n",
      "2   poly  0.1      1       4     3  0.738462   0.738064  0.738462  0.738087\n",
      "3   poly  0.1      1       4     4  0.553846   0.547702  0.553846  0.539893\n",
      "4   poly  0.1      1       4     5  0.646154   0.647157  0.646154  0.638871\n",
      "5   poly  0.1      1       4     6  0.584615   0.582321  0.584615  0.582220\n",
      "6   poly  0.1      1       4     7  0.738462   0.741154  0.738462  0.735291\n",
      "7   poly  0.1      1       4     8  0.600000   0.598456  0.600000  0.598659\n",
      "8   poly  0.1      1       4     9  0.646154   0.713857  0.646154  0.628466\n",
      "9   poly  0.1      1       4    10  0.484375   0.494400  0.484375  0.474564\n",
      "\n",
      "  kernel    c  gamma  degree  fold  accuracy  precision    recall    fscore\n",
      "0   poly  0.1      1       5     1  0.492308   0.481966  0.492308  0.472902\n",
      "1   poly  0.1      1       5     2  0.600000   0.597633  0.600000  0.596525\n",
      "2   poly  0.1      1       5     3  0.753846   0.753638  0.753846  0.753021\n",
      "3   poly  0.1      1       5     4  0.584615   0.581538  0.584615  0.579580\n",
      "4   poly  0.1      1       5     5  0.661538   0.660529  0.661538  0.660404\n",
      "5   poly  0.1      1       5     6  0.646154   0.645447  0.646154  0.645647\n",
      "6   poly  0.1      1       5     7  0.753846   0.753846  0.753846  0.753846\n",
      "7   poly  0.1      1       5     8  0.538462   0.540793  0.538462  0.539118\n",
      "8   poly  0.1      1       5     9  0.646154   0.684420  0.646154  0.637310\n",
      "9   poly  0.1      1       5    10  0.515625   0.520782  0.515625  0.515034\n",
      "\n",
      "Média dos resultados do kernel poly\n",
      "   kernel      c  gamma  degree  accuracy_avg  precision_avg  recall_avg  \\\n",
      "0    poly  0.001  0.001       1      0.536202       0.287536    0.536202   \n",
      "1    poly  0.001  0.001       2      0.536202       0.287536    0.536202   \n",
      "2    poly  0.001  0.001       3      0.536202       0.287536    0.536202   \n",
      "3    poly  0.001  0.001       4      0.536202       0.287536    0.536202   \n",
      "4    poly  0.001  0.001       5      0.536202       0.287536    0.536202   \n",
      "5    poly  0.001  0.100       1      0.536202       0.287536    0.536202   \n",
      "6    poly  0.001  0.100       2      0.536202       0.287536    0.536202   \n",
      "7    poly  0.001  0.100       3      0.536202       0.287536    0.536202   \n",
      "8    poly  0.001  0.100       4      0.536202       0.287536    0.536202   \n",
      "9    poly  0.001  0.100       5      0.536202       0.287536    0.536202   \n",
      "10   poly  0.001  0.500       1      0.536202       0.287536    0.536202   \n",
      "11   poly  0.001  0.500       2      0.536202       0.287536    0.536202   \n",
      "12   poly  0.001  0.500       3      0.625721       0.674711    0.625721   \n",
      "13   poly  0.001  0.500       4      0.660986       0.739746    0.660986   \n",
      "14   poly  0.001  0.500       5      0.673293       0.745432    0.673293   \n",
      "15   poly  0.001  1.000       1      0.536202       0.287536    0.536202   \n",
      "16   poly  0.001  1.000       2      0.650264       0.764474    0.650264   \n",
      "17   poly  0.001  1.000       3      0.693293       0.763408    0.693293   \n",
      "18   poly  0.001  1.000       4      0.687188       0.727415    0.687188   \n",
      "19   poly  0.001  1.000       5      0.656274       0.676219    0.656274   \n",
      "20   poly  0.100  0.001       1      0.536202       0.287536    0.536202   \n",
      "21   poly  0.100  0.001       2      0.536202       0.287536    0.536202   \n",
      "22   poly  0.100  0.001       3      0.536202       0.287536    0.536202   \n",
      "23   poly  0.100  0.001       4      0.536202       0.287536    0.536202   \n",
      "24   poly  0.100  0.001       5      0.536202       0.287536    0.536202   \n",
      "25   poly  0.100  0.100       1      0.684111       0.758839    0.684111   \n",
      "26   poly  0.100  0.100       2      0.650264       0.764474    0.650264   \n",
      "27   poly  0.100  0.100       3      0.588630       0.658367    0.588630   \n",
      "28   poly  0.100  0.100       4      0.553149       0.524152    0.553149   \n",
      "29   poly  0.100  0.100       5      0.543894       0.382167    0.543894   \n",
      "30   poly  0.100  0.500       1      0.713293       0.767101    0.713293   \n",
      "31   poly  0.100  0.500       2      0.717885       0.763778    0.717885   \n",
      "32   poly  0.100  0.500       3      0.705601       0.745270    0.705601   \n",
      "33   poly  0.100  0.500       4      0.657788       0.676224    0.657788   \n",
      "34   poly  0.100  0.500       5      0.634663       0.643404    0.634663   \n",
      "35   poly  0.100  1.000       1      0.719423       0.770335    0.719423   \n",
      "36   poly  0.100  1.000       2      0.717933       0.756554    0.717933   \n",
      "37   poly  0.100  1.000       3      0.657837       0.669669    0.657837   \n",
      "38   poly  0.100  1.000       4      0.620745       0.628026    0.620745   \n",
      "39   poly  0.100  1.000       5      0.619255       0.622059    0.619255   \n",
      "\n",
      "    fscore_avg  \n",
      "0     0.374329  \n",
      "1     0.374329  \n",
      "2     0.374329  \n",
      "3     0.374329  \n",
      "4     0.374329  \n",
      "5     0.374329  \n",
      "6     0.374329  \n",
      "7     0.374329  \n",
      "8     0.374329  \n",
      "9     0.374329  \n",
      "10    0.374329  \n",
      "11    0.374329  \n",
      "12    0.538764  \n",
      "13    0.609175  \n",
      "14    0.630319  \n",
      "15    0.374329  \n",
      "16    0.585258  \n",
      "17    0.658010  \n",
      "18    0.658632  \n",
      "19    0.637045  \n",
      "20    0.374329  \n",
      "21    0.374329  \n",
      "22    0.374329  \n",
      "23    0.374329  \n",
      "24    0.374329  \n",
      "25    0.638102  \n",
      "26    0.585258  \n",
      "27    0.480663  \n",
      "28    0.409618  \n",
      "29    0.390425  \n",
      "30    0.682039  \n",
      "31    0.692700  \n",
      "32    0.682906  \n",
      "33    0.639373  \n",
      "34    0.621312  \n",
      "35    0.690837  \n",
      "36    0.696335  \n",
      "37    0.645147  \n",
      "38    0.612776  \n",
      "39    0.615339  \n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001    0.1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001    0.1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001    0.1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001    0.1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001    0.1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001    0.1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001    0.1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001    0.1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001    0.1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001    0.1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001    0.5     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001    0.5     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001    0.5     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001    0.5     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001    0.5     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001    0.5     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001    0.5     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001    0.5     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001    0.5     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001    0.5    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kernel      c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.001      1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.001      1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.001      1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.001      1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.001      1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.001      1     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.001      1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.001      1     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.001      1     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.001      1    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1  0.001     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.1  0.001     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.1  0.001     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.1  0.001     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.1  0.001     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.1  0.001     6  0.538462   0.289941  0.538462  0.376923\n",
      "6    rbf  0.1  0.001     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.1  0.001     8  0.538462   0.289941  0.538462  0.376923\n",
      "8    rbf  0.1  0.001     9  0.538462   0.289941  0.538462  0.376923\n",
      "9    rbf  0.1  0.001    10  0.531250   0.282227  0.531250  0.368622\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1    0.1     1  0.553846   0.759219  0.553846  0.424502\n",
      "1    rbf  0.1    0.1     2  0.615385   0.711254  0.615385  0.543402\n",
      "2    rbf  0.1    0.1     3  0.738462   0.823964  0.738462  0.712315\n",
      "3    rbf  0.1    0.1     4  0.600000   0.657895  0.600000  0.532037\n",
      "4    rbf  0.1    0.1     5  0.738462   0.777432  0.738462  0.722773\n",
      "5    rbf  0.1    0.1     6  0.876923   0.899821  0.876923  0.873767\n",
      "6    rbf  0.1    0.1     7  0.923077   0.932692  0.923077  0.922145\n",
      "7    rbf  0.1    0.1     8  0.738462   0.752997  0.738462  0.730282\n",
      "8    rbf  0.1    0.1     9  0.630769   0.754438  0.630769  0.595685\n",
      "9    rbf  0.1    0.1    10  0.609375   0.625673  0.609375  0.605057\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1    0.5     1  0.553846   0.640668  0.553846  0.445159\n",
      "1    rbf  0.1    0.5     2  0.676923   0.758612  0.676923  0.636550\n",
      "2    rbf  0.1    0.5     3  0.753846   0.775214  0.753846  0.744615\n",
      "3    rbf  0.1    0.5     4  0.646154   0.706682  0.646154  0.601935\n",
      "4    rbf  0.1    0.5     5  0.753846   0.765816  0.753846  0.747535\n",
      "5    rbf  0.1    0.5     6  0.892308   0.894962  0.892308  0.891687\n",
      "6    rbf  0.1    0.5     7  0.907692   0.913215  0.907692  0.906890\n",
      "7    rbf  0.1    0.5     8  0.753846   0.753638  0.753846  0.753021\n",
      "8    rbf  0.1    0.5     9  0.523077   0.765448  0.523077  0.414765\n",
      "9    rbf  0.1    0.5    10  0.578125   0.719381  0.578125  0.517527\n",
      "\n",
      "  kernel    c  gamma  fold  accuracy  precision    recall    fscore\n",
      "0    rbf  0.1      1     1  0.523077   0.273609  0.523077  0.359285\n",
      "1    rbf  0.1      1     2  0.538462   0.289941  0.538462  0.376923\n",
      "2    rbf  0.1      1     3  0.538462   0.289941  0.538462  0.376923\n",
      "3    rbf  0.1      1     4  0.538462   0.289941  0.538462  0.376923\n",
      "4    rbf  0.1      1     5  0.538462   0.289941  0.538462  0.376923\n",
      "5    rbf  0.1      1     6  0.553846   0.756010  0.553846  0.410507\n",
      "6    rbf  0.1      1     7  0.538462   0.289941  0.538462  0.376923\n",
      "7    rbf  0.1      1     8  0.569231   0.760684  0.569231  0.442308\n",
      "8    rbf  0.1      1     9  0.707692   0.708583  0.707692  0.707970\n",
      "9    rbf  0.1      1    10  0.671875   0.680752  0.671875  0.662099\n",
      "\n",
      "Média dos resultados do kernel rbf\n",
      "  kernel      c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
      "0    rbf  0.001  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "1    rbf  0.001  0.100      0.536202       0.287536    0.536202    0.374329\n",
      "2    rbf  0.001  0.500      0.536202       0.287536    0.536202    0.374329\n",
      "3    rbf  0.001  1.000      0.536202       0.287536    0.536202    0.374329\n",
      "4    rbf  0.100  0.001      0.536202       0.287536    0.536202    0.374329\n",
      "5    rbf  0.100  0.100      0.702476       0.769539    0.702476    0.666196\n",
      "6    rbf  0.100  0.500      0.703966       0.769364    0.703966    0.665968\n",
      "7    rbf  0.100  1.000      0.571803       0.462934    0.571803    0.446678\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset-fs-recursive-feature.csv', header = 0)\n",
    "X = df.drop('is_approved', axis=1).to_numpy() # DATASET\n",
    "y = df['is_approved'].to_numpy() # target\n",
    "\n",
    "result_linear_rf, result_poly_rf, result_rbf_rf, ic_linear_rf, ic_poly_rf, ic_rbf_rf = execute_SVM(X, y, k_folds, list_c, list_degree, list_gamma, \n",
    "                                                                 list_coef, dataSet='recursive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.628961      0.702988   0.628961   0.578864\n",
      "sup     0.809885      0.837682   0.809885   0.802811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.719423</td>\n",
       "      <td>0.770335</td>\n",
       "      <td>0.719423</td>\n",
       "      <td>0.690837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel    c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "1  linear  0.1      0.719423       0.770335    0.719423    0.690837"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel Linear\n",
    "print(ic_linear_rf)\n",
    "result_linear_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.628961      0.702988   0.628961   0.578864\n",
      "sup     0.809885      0.837682   0.809885   0.802811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>gamma</th>\n",
       "      <th>degree</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719423</td>\n",
       "      <td>0.770335</td>\n",
       "      <td>0.719423</td>\n",
       "      <td>0.690837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel    c  gamma  degree  accuracy_avg  precision_avg  recall_avg  \\\n",
       "35   poly  0.1    1.0       1      0.719423       0.770335    0.719423   \n",
       "\n",
       "    fscore_avg  \n",
       "35    0.690837  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel Poly\n",
    "print(ic_poly_rf)\n",
    "result_poly_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     accuracy_ic  precision_ic  recall_ic  fscore_ic\n",
      "inf     0.608703      0.711012   0.608703   0.542463\n",
      "sup     0.799230      0.827715   0.799230   0.789474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>c</th>\n",
       "      <th>gamma</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.703966</td>\n",
       "      <td>0.769364</td>\n",
       "      <td>0.703966</td>\n",
       "      <td>0.665968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel    c  gamma  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "6    rbf  0.1    0.5      0.703966       0.769364    0.703966    0.665968"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe o resultado do kernel RBF\n",
    "print(ic_rbf_rf)\n",
    "result_rbf_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados do Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>fscore_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All Features</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.714880</td>\n",
       "      <td>0.739373</td>\n",
       "      <td>0.714880</td>\n",
       "      <td>0.700049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.687188</td>\n",
       "      <td>0.735570</td>\n",
       "      <td>0.687188</td>\n",
       "      <td>0.650919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.741058</td>\n",
       "      <td>0.768852</td>\n",
       "      <td>0.741058</td>\n",
       "      <td>0.726894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recursive</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.731875</td>\n",
       "      <td>0.762049</td>\n",
       "      <td>0.731875</td>\n",
       "      <td>0.715121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  c  accuracy_avg  precision_avg  recall_avg  fscore_avg\n",
       "All Features  0.100      0.714880       0.739373    0.714880    0.700049\n",
       "PCA           0.500      0.687188       0.735570    0.687188    0.650919\n",
       "Chi           0.001      0.741058       0.768852    0.741058    0.726894\n",
       "Recursive     0.001      0.731875       0.762049    0.731875    0.715121"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_NB = pd.concat([result_NB_all, result_NB_pca, result_NB_chi, result_NB_rf])\n",
    "result_NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Índice de Confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IC das métricas geradas pelo processamento de cada dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_ic</th>\n",
       "      <th>precision_ic</th>\n",
       "      <th>recall_ic</th>\n",
       "      <th>fscore_ic</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>0.647212</td>\n",
       "      <td>0.686647</td>\n",
       "      <td>0.647212</td>\n",
       "      <td>0.619341</td>\n",
       "      <td>All_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>0.782547</td>\n",
       "      <td>0.792099</td>\n",
       "      <td>0.782547</td>\n",
       "      <td>0.780758</td>\n",
       "      <td>All_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>0.615426</td>\n",
       "      <td>0.679282</td>\n",
       "      <td>0.615426</td>\n",
       "      <td>0.548533</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.791858</td>\n",
       "      <td>0.758949</td>\n",
       "      <td>0.753306</td>\n",
       "      <td>PCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>0.673445</td>\n",
       "      <td>0.714899</td>\n",
       "      <td>0.673445</td>\n",
       "      <td>0.645429</td>\n",
       "      <td>Chi Squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>0.808670</td>\n",
       "      <td>0.822804</td>\n",
       "      <td>0.808670</td>\n",
       "      <td>0.808358</td>\n",
       "      <td>Chi Squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inf</th>\n",
       "      <td>0.666579</td>\n",
       "      <td>0.708537</td>\n",
       "      <td>0.666579</td>\n",
       "      <td>0.633364</td>\n",
       "      <td>Recursive Feature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>0.797171</td>\n",
       "      <td>0.815561</td>\n",
       "      <td>0.797171</td>\n",
       "      <td>0.796879</td>\n",
       "      <td>Recursive Feature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy_ic  precision_ic  recall_ic  fscore_ic            Dataset\n",
       "inf     0.647212      0.686647   0.647212   0.619341       All_features\n",
       "sup     0.782547      0.792099   0.782547   0.780758       All_features\n",
       "inf     0.615426      0.679282   0.615426   0.548533                PCA\n",
       "sup     0.758949      0.791858   0.758949   0.753306                PCA\n",
       "inf     0.673445      0.714899   0.673445   0.645429        Chi Squared\n",
       "sup     0.808670      0.822804   0.808670   0.808358        Chi Squared\n",
       "inf     0.666579      0.708537   0.666579   0.633364  Recursive Feature\n",
       "sup     0.797171      0.815561   0.797171   0.796879  Recursive Feature"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic_NB_all['Dataset'] = 'All_features'\n",
    "ic_NB_pca['Dataset'] = 'PCA'\n",
    "ic_NB_chi['Dataset'] = 'Chi Squared'\n",
    "ic_NB_rf['Dataset'] = 'Recursive Feature'\n",
    "\n",
    "ic_nb = pd.concat([ic_NB_all, ic_NB_pca, ic_NB_chi, ic_NB_rf],axis=0)\n",
    "print(\"IC das métricas geradas pelo processamento de cada dataset\")\n",
    "ic_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados do SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5nPWiXY29cEu"
   },
   "source": [
    "# Gerar Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CFhU-Fp2yVbw",
    "outputId": "e45c5b59-4402-4a66-9420-de770840daa5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = result_all_features_g +  result_pca_g + result_chi_g + result_recursive_g\n",
    "\n",
    "tips = pd.concat(frames)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "fig, ax = plt.subplots(3,1,figsize=[10,25])\n",
    "\n",
    "g = sns.barplot(ax=ax[0], x=\"method\", y=\"accuracy\", hue=\"Param(c)\", data=tips,capsize=.05)\n",
    "g.set(ylim=(0,1),yticks=np.arange(0,1.1,0.1).tolist())\n",
    "g.set_ylabel(\"Accuracy\",fontsize=30)\n",
    "g.set_title('Classificador Naive Bayes',fontsize=30)\n",
    "g = sns.barplot(ax=ax[1], x=\"method\", y=\"recall\", hue=\"Param(c)\", data=tips,capsize=.05);\n",
    "g.set(ylim=(0,1),yticks=np.arange(0,1.1,0.1).tolist())\n",
    "g.set_ylabel(\"Recall\",fontsize=30)\n",
    "g = sns.barplot(ax=ax[2], x=\"method\", y=\"precision\", hue=\"Param(c)\", data=tips,capsize=.05);\n",
    "g.set(ylim=(0,1),yticks=np.arange(0,1.1,0.1).tolist())\n",
    "g.set_ylabel(\"Precision\",fontsize=30)\n",
    "plt.close(2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of 06 - k-fold cross validation + naive Bayes v03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
